{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbdd887b",
   "metadata": {},
   "source": [
    "# String matching and NLP for variant extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83670bcd",
   "metadata": {},
   "source": [
    "# 1) Set up libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d977552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the working directory and file paths\n",
    "working_directory = \"WORKING_DIRECTORY\"\n",
    "output_directory = \"OUTPUT_DIRECTORY\"\n",
    "articles_file = \"BioBERT_file.csv\"\n",
    "\n",
    "os.chdir(output_directory)\n",
    "if \"full_articles\" not in globals():\n",
    "    full_articles = pd.read_csv(articles_file)\n",
    "    print(f\"Loaded {len(full_articles)} articles from CSV.\")\n",
    "else:\n",
    "    print(\"Using preloaded full_articles from memory.\")\n",
    "articles = full_articles\n",
    "print(\"Article import successful!\")\n",
    "print(f\"\\nImported {len(articles):,} articles with {len(articles.columns):,} selected columns.\")\n",
    "\n",
    "# Get the number of rows and columns\n",
    "num_rows = articles.shape[0]\n",
    "num_columns = articles.shape[1]\n",
    "os.chdir(working_directory)\n",
    "print(\"\\nCurrent Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a983aa8c",
   "metadata": {},
   "source": [
    "# 2) Run string-matching for variant extration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acace99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CIViC GraphQL endpoint\n",
    "url = \"https://civicdb.org/api/graphql\"\n",
    "\n",
    "def run_query(query, variables=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "    response = requests.post(url, json={'query': query, 'variables': variables}, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Query failed with status code {response.status_code}\")\n",
    "\n",
    "all_features = []\n",
    "end_cursor = None\n",
    "\n",
    "browse_features_query = \"\"\"\n",
    "query ($after: String) {\n",
    "  browseFeatures(first: 100, after: $after) {\n",
    "    edges {\n",
    "      node {\n",
    "        id\n",
    "        name\n",
    "        fullName\n",
    "        featureInstanceType\n",
    "        featureAliases\n",
    "        deprecated\n",
    "      }\n",
    "    }\n",
    "    pageInfo {\n",
    "      hasNextPage\n",
    "      endCursor\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "while True:\n",
    "    variables = {\"after\": end_cursor}\n",
    "    result = run_query(browse_features_query, variables)\n",
    "    edges = result['data']['browseFeatures']['edges']\n",
    "    all_features.extend([edge['node'] for edge in edges])\n",
    "    \n",
    "    page_info = result['data']['browseFeatures']['pageInfo']\n",
    "    if page_info['hasNextPage']:\n",
    "        end_cursor = page_info['endCursor']\n",
    "    else:\n",
    "        break\n",
    "\n",
    "search_term = \"ATM\"\n",
    "matching_features = []\n",
    "\n",
    "for feature in all_features:\n",
    "    name = feature.get(\"name\", \"\").lower()\n",
    "    aliases = [alias.lower() for alias in feature.get(\"featureAliases\", [])]\n",
    "    if search_term.lower() in name or search_term.lower() in aliases:\n",
    "        matching_features.append(feature)\n",
    "\n",
    "print(f\"\\nFound {len(matching_features)} matching feature(s) for '{search_term}':\\n\")\n",
    "for f in matching_features:\n",
    "    for key, val in f.items():\n",
    "        print(f\"{key}: {val}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "variant_query = \"\"\"\n",
    "query ($id: Int!) {\n",
    "  feature(id: $id) {\n",
    "    id\n",
    "    name\n",
    "    variants {\n",
    "      id\n",
    "      name\n",
    "      description\n",
    "      hgvsDescriptions\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "for feature in matching_features:\n",
    "    feature_id = feature[\"id\"]\n",
    "    feature_name = feature[\"name\"]\n",
    "    print(f\"\\nFetching variants for feature '{feature_name}' (ID: {feature_id})...\\n\")\n",
    "\n",
    "    result = run_query(variant_query, {\"id\": feature_id})\n",
    "    variants = result.get(\"data\", {}).get(\"feature\", {}).get(\"variants\", [])\n",
    "\n",
    "    if not variants:\n",
    "        print(\"No variants found.\")\n",
    "    else:\n",
    "        for v in variants:\n",
    "            print(f\"- Variant ID: {v['id']}\")\n",
    "            print(f\"  Name: {v['name']}\")\n",
    "            print(f\"  Description: {v.get('description', 'N/A')}\")\n",
    "            print(f\"  HGVS Descriptions: {v.get('hgvsDescriptions', [])}\")\n",
    "            print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b9d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_df = pd.read_csv(\"civic_gene_variants.csv\", header=0)\n",
    "print(variants_df)\n",
    "print(articles)\n",
    "\n",
    "# Manually define the terms for string match\n",
    "custom_variant_terms = [\"BRCA1\"]\n",
    "custom_variant_terms = [term.lower() for term in custom_variant_terms]\n",
    "def has_custom_variant_match(row):\n",
    "    title = str(row.get(\"PaperTitle\", \"\")).lower()\n",
    "    abstract = str(row.get(\"Abstract\", \"\")).lower()\n",
    "    return any(term in title or term in abstract for term in custom_variant_terms)\n",
    "\n",
    "# Apply function and filter rows\n",
    "articles_stringmatching_custom = articles[articles.apply(has_custom_variant_match, axis=1)]\n",
    "num_matched_custom = len(articles_stringmatching_custom)\n",
    "print(f\"Number of matched articles (custom terms): {num_matched_custom}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and clean variant terms, skipping NaNs\n",
    "variant_terms = set()\n",
    "for variants in variants_df[\"Variant\"].dropna():\n",
    "    split_variants = [v.strip().lower() for v in variants.split(\",\") if v.strip()]\n",
    "    variant_terms.update(split_variants)\n",
    "\n",
    "# Function to check for matches in PaperTitle or Abstract\n",
    "def has_variant_match(row):\n",
    "    title = str(row.get(\"PaperTitle\", \"\")).lower()\n",
    "    abstract = str(row.get(\"Abstract\", \"\")).lower()\n",
    "    return any(variant in title or variant in abstract for variant in variant_terms)\n",
    "\n",
    "# Apply function and filter rows\n",
    "articles_stringmatching_variants = articles[articles.apply(has_variant_match, axis=1)]\n",
    "\n",
    "# Print how many matched\n",
    "num_matched = len(articles_stringmatching_variants)\n",
    "print(f\"Number of matched articles: {num_matched}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
