{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de96b78a",
   "metadata": {},
   "source": [
    "# Extraction of cancer types\n",
    "- Extract cancer types from PaperTitles and Abstracts using NER-based SciSpaCy approach\n",
    "- Connect to CIIVC API and match against the extarcted cancer types\n",
    "- Create a binary matrix cancer matrix\n",
    "- Create output statistics and figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c191c05",
   "metadata": {},
   "source": [
    "# 1) Set up libraries and datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc47e7b",
   "metadata": {},
   "source": [
    "## 1.1) Import libraries and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d33868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import unicodedata\n",
    "import swifter\n",
    "from fuzzywuzzy import fuzz\n",
    "from rapidfuzz import process\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a5780",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!pip install scispacy\n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz \n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7de8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import scispacy\n",
    "print(spacy.__version__)\n",
    "\n",
    "# Load SciSpaCy model for cancer entity recognition\n",
    "nlp_cancer_1 = spacy.load(\"en_ner_bionlp13cg_md\")  # Stronger for cancer extraction\n",
    "nlp_cancer_2 = spacy.load(\"en_ner_bc5cdr_md\")  # Good for diseases extraction\n",
    "\n",
    "# Stopwords to filter out non-relevant mentions\n",
    "EXCLUDE_TERMS = {\"anticancer\", \"cancerous\", \"non-cancerous\", \"precancerous\", \"cancer-related\"}\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156ff2e3",
   "metadata": {},
   "source": [
    "## 1.2) Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory and file paths\n",
    "input_directory = \"INPUT_DIRECTORY\"\n",
    "output_directory = \"OUTPUT_DIRECTORY\"\n",
    "gene_matrix = \"filtered_gene_binary_matrix.csv\"\n",
    "full_dataset = \"cleaned_BioBERT_data.csv\"\n",
    "print(\"Success!\")\n",
    "\n",
    "# Load full dataset\n",
    "os.chdir(output_directory)\n",
    "print(\"Current work directory:\",os.getcwd())\n",
    "full_df = pd.read_csv(full_dataset)\n",
    "full_df = full_df.copy()\n",
    "print(f\"Length of full dataset: {len(full_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567379f4",
   "metadata": {},
   "source": [
    "# 2) Connect to CIVIC API for cancer types and extract DOID and MONDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f01470",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ======== All following steps are needed ! =============== ######\n",
    "###### CIVIC disease extraction with synonyms from DOID ######\n",
    "###### ======================================================== ######\n",
    "# Define the GraphQL endpoint\n",
    "url = \"https://civicdb.org/api/graphql\"\n",
    "\n",
    "# Function to execute GraphQL queries\n",
    "def run_query(query, variables=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "    response = requests.post(url, json={'query': query, 'variables': variables}, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Query failed with status code {response.status_code}\")\n",
    "\n",
    "# Fetch all disease IDs\n",
    "all_disease_ids = []\n",
    "end_cursor = None\n",
    "while True:\n",
    "    browse_query = \"\"\"\n",
    "    query ($after: String) {\n",
    "      browseDiseases(first: 100, after: $after) {\n",
    "        edges {\n",
    "          node {\n",
    "            id\n",
    "          }\n",
    "        }\n",
    "        pageInfo {\n",
    "          hasNextPage\n",
    "          endCursor\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    variables = {\"after\": end_cursor}\n",
    "    result = run_query(browse_query, variables)\n",
    "    edges = result['data']['browseDiseases']['edges']\n",
    "    all_disease_ids.extend([edge['node']['id'] for edge in edges])\n",
    "    page_info = result['data']['browseDiseases']['pageInfo']\n",
    "    if page_info['hasNextPage']:\n",
    "        end_cursor = page_info['endCursor']\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Retrieve synonyms for each disease with a progress bar\n",
    "diseases_data = []\n",
    "disease_query = \"\"\"\n",
    "query ($id: Int!) {\n",
    "  disease(id: $id) {\n",
    "    id\n",
    "    name\n",
    "    doid\n",
    "    diseaseAliases\n",
    "    diseaseUrl\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "print(\"\\nFetching synonyms for each disease...\")\n",
    "\n",
    "for disease_id in tqdm(all_disease_ids, desc=\"Processing Diseases\", unit=\"disease\"):\n",
    "    variables = {\"id\": disease_id}\n",
    "    result = run_query(disease_query, variables)\n",
    "    disease = result.get('data', {}).get('disease', {})\n",
    "    if not disease:\n",
    "        continue\n",
    "\n",
    "    diseases_data.append({\n",
    "        \"id\": disease.get(\"id\", \"N/A\"),\n",
    "        \"name\": disease.get(\"name\", \"N/A\"),\n",
    "        \"doid\": disease.get(\"doid\", \"N/A\"),\n",
    "        \"synonyms\": \", \".join(disease.get(\"diseaseAliases\", [])) if disease.get(\"diseaseAliases\") else \"None\",\n",
    "        \"diseaseUrl\": disease.get(\"diseaseUrl\", \"N/A\"),\n",
    "    })\n",
    "CIVIC_cancer_synonyms = pd.DataFrame(diseases_data)\n",
    "CIVIC_cancer_synonyms.to_csv(\"CIVIC_cancer_synonyms.csv\", index=False)\n",
    "print(\"\\n CSV file saved successfully: CIVIC_cancer_synonyms.csv\")\n",
    "print(f\"\\nTotal cancer types in CIViC: {CIVIC_cancer_synonyms.shape[0]}\")\n",
    "print(CIVIC_cancer_synonyms.head())\n",
    "print(\"Length of dataset:\",len(CIVIC_cancer_synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbfe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ======================================================================== ######\n",
    "###### CIVIC disease extraction with MONDO synonyms fron CIVIC MyDiseaseInfo    ######\n",
    "###### ======================================================================== ######\n",
    "\n",
    "if \"CIVIC_cancer_synonyms\" in globals():\n",
    "    civic_df = CIVIC_cancer_synonyms.copy()\n",
    "    print(\"civic_df loaded from globals\")\n",
    "else:\n",
    "    os.chdir(output_directory)\n",
    "    print(\"Loading dataset from file...\")\n",
    "    civic_df = pd.read_csv(output_directory + \"/CIVIC_cancer_synonyms.csv\")\n",
    "    \n",
    "# Define the CIViC GraphQL API endpoint\n",
    "CIVIC_API_URL = \"https://civicdb.org/api/graphql\"\n",
    "cancer_types = civic_df[\"name\"].str.strip().str.lower().unique()  # Clean and case-insensitive\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each cancer type with a progress bar\n",
    "for cancer in tqdm(cancer_types, desc=\"Processing Cancer Types\"):\n",
    "    try:\n",
    "        # Get Disease ID\n",
    "        typeahead_query = f\"\"\"\n",
    "        query {{\n",
    "          diseaseTypeahead(queryTerm: \"{cancer}\") {{\n",
    "            id\n",
    "            name\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "        response = requests.post(CIVIC_API_URL, json={\"query\": typeahead_query})\n",
    "        # Initialize default entry in case of failure\n",
    "        entry = {\n",
    "            \"query_name\": cancer,\n",
    "            \"name\": \"N/A\",\n",
    "            \"doid\": \"N/A\",\n",
    "            \"aliases\": \"N/A\",\n",
    "            \"mondoId\": \"N/A\",\n",
    "            \"mondoDef\": \"N/A\",\n",
    "            \"diseaseOntologyExactSynonyms\": \"N/A\",\n",
    "            \"diseaseOntologyRelatedSynonyms\": \"N/A\",\n",
    "            \"doDef\": \"N/A\",\n",
    "            \"doDefCitations\": \"N/A\",\n",
    "            \"icd10\": \"N/A\",\n",
    "            \"icdo\": \"N/A\",\n",
    "            \"mesh\": \"N/A\",\n",
    "            \"ncit\": \"N/A\",\n",
    "            \"omim\": \"N/A\"\n",
    "        }\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            diseases = data.get(\"data\", {}).get(\"diseaseTypeahead\", [])\n",
    "\n",
    "            if diseases:\n",
    "                # Select the first matching disease ID\n",
    "                disease_id = diseases[0][\"id\"]\n",
    "                # Query MyDiseaseInfo for details\n",
    "                disease_query = f\"\"\"\n",
    "                query {{\n",
    "                  disease(id: {disease_id}) {{\n",
    "                    name\n",
    "                    doid\n",
    "                    diseaseAliases\n",
    "                    myDiseaseInfo {{\n",
    "                      mondoId\n",
    "                      mondoDef\n",
    "                      diseaseOntologyExactSynonyms\n",
    "                      diseaseOntologyRelatedSynonyms\n",
    "                      doDef\n",
    "                      doDefCitations\n",
    "                      icd10\n",
    "                      icdo\n",
    "                      mesh\n",
    "                      ncit\n",
    "                      omim\n",
    "                    }}\n",
    "                  }}\n",
    "                }}\n",
    "                \"\"\"\n",
    "                response = requests.post(CIVIC_API_URL, json={\"query\": disease_query})\n",
    "                if response.status_code == 200:\n",
    "                    disease_data = response.json().get(\"data\", {}).get(\"disease\", {})\n",
    "\n",
    "                    if disease_data:\n",
    "                        entry[\"name\"] = disease_data.get(\"name\", \"N/A\")\n",
    "                        entry[\"doid\"] = disease_data.get(\"doid\", \"N/A\")\n",
    "                        entry[\"aliases\"] = \", \".join(disease_data.get(\"diseaseAliases\", [])) if disease_data.get(\"diseaseAliases\") else \"N/A\"\n",
    "                        if disease_data.get(\"myDiseaseInfo\"):\n",
    "                            my_disease_info = disease_data[\"myDiseaseInfo\"]\n",
    "                            entry.update({\n",
    "                                \"mondoId\": my_disease_info.get(\"mondoId\", \"N/A\"),\n",
    "                                \"mondoDef\": my_disease_info.get(\"mondoDef\", \"N/A\"),\n",
    "                                \"diseaseOntologyExactSynonyms\": \", \".join(my_disease_info.get(\"diseaseOntologyExactSynonyms\", [])) if my_disease_info.get(\"diseaseOntologyExactSynonyms\") else \"N/A\",\n",
    "                                \"diseaseOntologyRelatedSynonyms\": \", \".join(my_disease_info.get(\"diseaseOntologyRelatedSynonyms\", [])) if my_disease_info.get(\"diseaseOntologyRelatedSynonyms\") else \"N/A\",\n",
    "                                \"doDef\": my_disease_info.get(\"doDef\", \"N/A\"),\n",
    "                                \"doDefCitations\": \", \".join(my_disease_info.get(\"doDefCitations\", [])) if my_disease_info.get(\"doDefCitations\") else \"N/A\",\n",
    "                                \"icd10\": my_disease_info.get(\"icd10\", \"N/A\"),\n",
    "                                \"icdo\": my_disease_info.get(\"icdo\", \"N/A\"),\n",
    "                                \"mesh\": my_disease_info.get(\"mesh\", \"N/A\"),\n",
    "                                \"ncit\": \", \".join(my_disease_info.get(\"ncit\", [])) if my_disease_info.get(\"ncit\") else \"N/A\",\n",
    "                                \"omim\": my_disease_info.get(\"omim\", \"N/A\")\n",
    "                            })\n",
    "        results.append(entry)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {cancer} due to an error: {e}\")\n",
    "MONDO_df = pd.DataFrame(results)\n",
    "MONDO_df.to_csv(\"CIVIC_cancers_with_MONDO.csv\", index=False)\n",
    "print(\"CSV file saved successfully: CIVIC_cancers_with_MONDO.csv\")\n",
    "print(\"Length of dataset:\",len(MONDO_df))\n",
    "if len(MONDO_df) == len(CIVIC_cancer_synonyms):\n",
    "    print(\"Same length of CIVIC DOID and MONDO dataset\")\n",
    "else:\n",
    "    print(\"Different lengths of datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ======================================================================== ######\n",
    "###### CIVIC disease extraction with MONDO synonyms from MONDO EMBL API.        ######\n",
    "###### ======================================================================== ######\n",
    "# Load ALL synonyms directly using the MONDO API, as MyDiseaseInfo on CIVIC is not comprehensive enough\n",
    "# Remove commas and spaces of the MONDO derived synonyms!\n",
    "def clean_individual_cancer_name(name):\n",
    "    \"\"\"\n",
    "    Cleans an individual cancer name by:\n",
    "    - Removing internal commas and hyphens while keeping spaces intact.\n",
    "    \"\"\"\n",
    "    cleaned_name = re.sub(r\"[,|-]+\", \" \", name)\n",
    "    return \" \".join(cleaned_name.split()) \n",
    "\n",
    "def fetch_synonyms(mondo_id):\n",
    "    \"\"\"\n",
    "    Fetch synonyms for a given MONDO ID using the OLS API.\n",
    "    Cleans the names directly while fetching.\n",
    "    \"\"\"\n",
    "    # Handle missing or non-string values\n",
    "    if pd.isna(mondo_id) or not isinstance(mondo_id, str):\n",
    "        return \"N/A\"\n",
    "    # Format the MONDO ID correctly (replace \":\" with \"_\")\n",
    "    mondo_id = mondo_id.replace(\":\", \"_\")\n",
    "    # API endpoint\n",
    "    url = f\"https://www.ebi.ac.uk/ols/api/ontologies/mondo/terms?iri=http://purl.obolibrary.org/obo/{mondo_id}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            term_info = data[\"_embedded\"][\"terms\"][0]\n",
    "            synonyms = term_info.get(\"synonyms\", [])\n",
    "\n",
    "            # Clean each cancer name\n",
    "            cleaned_synonyms = [clean_individual_cancer_name(name) for name in synonyms]\n",
    "\n",
    "            # Join them back with commas\n",
    "            return \", \".join(cleaned_synonyms) if cleaned_synonyms else \"N/A\"\n",
    "        \n",
    "        elif response.status_code == 404:\n",
    "            return \"N/A\"\n",
    "        else:\n",
    "            return f\"Error {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "MONDO_df2 = MONDO_df.copy()  # Ensure MONDO ID is treated as a string\n",
    "MONDO_df2[\"mondoId\"] = MONDO_df2[\"mondoId\"].astype(str)  \n",
    "tqdm.pandas(desc=\"Fetching and cleaning synonyms from MONDO\")\n",
    "MONDO_df2[\"new_synonyms\"] = MONDO_df2[\"mondoId\"].progress_apply(fetch_synonyms)\n",
    "MONDO_df2.to_csv(\"CIVIC_MONDO_df_with_cleaned_synonyms.csv\", index=False)\n",
    "print(\"\\n CSV file saved successfully: CIVIC_MONDO_df_with_cleaned_synonyms.csv\")\n",
    "print(MONDO_df2.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba3a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and filter for cancers in the \"name\" column\n",
    "cancer_row = MONDO_df2[MONDO_df2[\"name\"].str.lower() == \"prostate cancer\"]\n",
    "\n",
    "if not cancer_row.empty:\n",
    "    # Extract and print the synonyms\n",
    "    synonyms = cancer_row[\"new_synonyms\"].values[0] if \"new_synonyms\" in cancer_row else \"No synonyms available\"\n",
    "    aliases = cancer_row[\"aliases\"].values[0] if \"aliases\" in cancer_row else \"No aliases available\"\n",
    "    print(\"Synonyms for 'Cancer'\")\n",
    "    print(synonyms)\n",
    "    print(\"\\n Aliases for 'Cancer'\")\n",
    "    print(aliases)\n",
    "else:\n",
    "    print(\"'Cancer' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75be5ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### ===================================================================== ######\n",
    "###### Display full CIVIC and MONDO dataset and merge alisases and synonyms  ######\n",
    "###### ===================================================================== ######\n",
    "# Load ALL synonyms directly using the MONDO API (as MyDiseaseInfo on CIVIC is not comprehensive enough)\n",
    "if \"MONDO_df2\" in globals():\n",
    "    CIVIC_DOID_MONDO_merged = MONDO_df2.copy()\n",
    "    print(\"MONDO_df loaded from globals\")\n",
    "else:\n",
    "    os.chdir(output_directory)\n",
    "    print(\"Loading dataset from file...\")\n",
    "    CIVIC_DOID_MONDO_merged = pd.read_csv(output_directory + \"/CIVIC_MONDO_df_with_new_synonyms.csv\")\n",
    "\n",
    "# Ensure all values are consistently lists\n",
    "def ensure_list(x):\n",
    "    \"\"\"Ensures the value is a list. Converts NaN, empty lists, and strings to a proper list.\"\"\"\n",
    "    if isinstance(x, float) and pd.isna(x):\n",
    "        return []\n",
    "    elif isinstance(x, str):\n",
    "        return [syn.strip() for syn in x.split(\",\") if syn.strip()]\n",
    "    elif isinstance(x, list): \n",
    "        return [syn.strip() for syn in x if isinstance(syn, str) and syn.strip()]\n",
    "    else:\n",
    "        return [] \n",
    "\n",
    "# Apply ensure_list to each column\n",
    "for col in ['aliases', 'new_synonyms']:\n",
    "    CIVIC_DOID_MONDO_merged[col] = CIVIC_DOID_MONDO_merged[col].map(ensure_list, na_action='ignore')\n",
    "\n",
    "# Function to merge and clean synonyms\n",
    "def merge_synonyms(row):\n",
    "    \"\"\"Merges synonyms from multiple columns, removes duplicates, and ignores empty values.\"\"\"\n",
    "    all_synonyms = set() \n",
    "    for col in ['aliases', 'new_synonyms']:\n",
    "        all_synonyms.update(row[col]) \n",
    "    return \", \".join(sorted(all_synonyms)) if all_synonyms else None \n",
    "\n",
    "# Apply the function to create the new \"synonyms\" column\n",
    "CIVIC_DOID_MONDO_merged[\"synonyms\"] = CIVIC_DOID_MONDO_merged.apply(merge_synonyms, axis=1)\n",
    "CIVIC_DOID_MONDO_merged.to_csv(\"CIVIC_MONDO_with_synonyms.csv\", index=False)\n",
    "print(\"CSV file saved successfully: CIVIC_MONDO_with_synonyms.csv\")\n",
    "print(\"Length of dataset:\",len(CIVIC_DOID_MONDO_merged))\n",
    "print(CIVIC_DOID_MONDO_merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4407780",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = [\"synonyms\", \"aliases\", \"new_synonyms\"]\n",
    "# Calculate lengths and display results\n",
    "lengths_df = CIVIC_DOID_MONDO_merged[columns_to_check].astype(str).applymap(len)\n",
    "print(lengths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning: Remove N/As and short, general abbreviations \n",
    "def clean_individual_cancer_name(name):\n",
    "    \"\"\"\n",
    "    Cleans an individual cancer name by:\n",
    "    - Removing internal hyphens (\"-\").\n",
    "    - Removing text inside parentheses \"(...)\".\n",
    "    - Ensuring proper spacing.\n",
    "    \"\"\"\n",
    "    name = re.sub(r\"[-]+\", \" \", name)  # Replace hyphens with spaces\n",
    "    name = re.sub(r\"\\(.*?\\)\", \"\", name)  # Remove text inside parentheses\n",
    "    return \" \".join(name.split())  # Remove extra spaces\n",
    "\n",
    "def clean_synonyms(synonyms):\n",
    "    \"\"\"\n",
    "    Cleans the synonyms string by:\n",
    "    - Removing \"N/A\"\n",
    "    - Removing the standalone word \"familial\"\n",
    "    - Removing internal hyphens (\"-\")\n",
    "    - Removing text inside parentheses \"(...)\"\n",
    "    - Removing duplicate entries (case-insensitive)\n",
    "    \"\"\"\n",
    "    if pd.isna(synonyms) or not isinstance(synonyms, str):\n",
    "        return \"N/A\" \n",
    "    # Split synonyms into a list\n",
    "    cancer_names = [word.strip() for word in synonyms.split(\",\")]\n",
    "    # Clean each cancer name\n",
    "    cleaned_names = [\n",
    "        clean_individual_cancer_name(name) for name in cancer_names\n",
    "        if name.lower() != \"familial\" and name.lower() != \"n/a\"\n",
    "    ]\n",
    "\n",
    "    # Remove duplicates (case-insensitive while preserving original casing)\n",
    "    seen = set()\n",
    "    unique_names = []\n",
    "    for name in cleaned_names:\n",
    "        lower_name = name.lower()\n",
    "        if lower_name not in seen:\n",
    "            seen.add(lower_name)\n",
    "            unique_names.append(name)\n",
    "    # Join back into a comma-separated string\n",
    "    return \", \".join(unique_names)\n",
    "\n",
    "# Create a new cleaned dataset instead of modifying the original\n",
    "CIVIC_cancer_final = CIVIC_DOID_MONDO_merged.copy()\n",
    "CIVIC_cancer_final[\"synonyms\"] = CIVIC_cancer_final[\"synonyms\"].apply(clean_synonyms)\n",
    "print(\"Successfully cleaned synonyms (case-insensitive duplicates removed, parentheses removed)!\")\n",
    "\n",
    "CIVIC_cancer_final.to_csv(\"CIVIC_cancer_final.csv\", index=False)\n",
    "print(\"\\nCSV file saved successfully: CIVIC_cancer_final.csv\")\n",
    "print(\"Length of dataset:\", len(CIVIC_cancer_final))\n",
    "\n",
    "print(\"\\nSample of cleaned synonyms:\")\n",
    "print(CIVIC_cancer_final.head(10)[[\"synonyms\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c501ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ======================================================= ######\n",
    "###### Display and investigate the final CIVIC cancer dataset  ######\n",
    "###### ======================================================= ######\n",
    "if \"CIVIC_cancer_final\" in globals():\n",
    "    CIVIC_cancer_final = CIVIC_cancer_final.copy()\n",
    "    print(\"Dataset loaded from globals\")\n",
    "else:\n",
    "    os.chdir(output_directory)\n",
    "    print(\"Loading dataset from file...\")\n",
    "    CIVIC_cancer_final = pd.read_csv(output_directory + \"/CIVIC_cancer_final.csv\")\n",
    "total_cancers = CIVIC_cancer_final['name'].nunique()\n",
    "print(f\"Total unique cancer types: {total_cancers}\")\n",
    "print(\"\\nSummary of Cancer Types:\")\n",
    "print(CIVIC_cancer_final['name'].value_counts())\n",
    "prostate_cancer_df_syn = CIVIC_cancer_final[CIVIC_cancer_final['name'].str.contains(\"prostate\", case=False, na=False)]\n",
    "print(\"\\nFiltered List of Prostate Cancer Types:\")\n",
    "print(prostate_cancer_df_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b2dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ======================================================= ######\n",
    "###### Display and investigate the final CIVIC cancer dataset  ######\n",
    "###### ======================================================= ######\n",
    "if \"CIVIC_cancer_final\" in globals():\n",
    "    CIVIC_cancer_final = CIVIC_cancer_final.copy()\n",
    "    print(\"Dataset loaded from globals\")\n",
    "else:\n",
    "    os.chdir(output_directory)\n",
    "    print(\"Loading dataset from file...\")\n",
    "    CIVIC_cancer_final = pd.read_csv(output_directory + \"/CIVIC_cancer_final.csv\")\n",
    "total_cancers = CIVIC_cancer_final['name'].nunique()\n",
    "print(f\"Total unique cancer types: {total_cancers}\")\n",
    "print(\"\\nSummary of Cancer Types:\")\n",
    "print(CIVIC_cancer_final['name'].value_counts())\n",
    "prostate_cancer_df_syn = CIVIC_cancer_final[CIVIC_cancer_final['name'].str.contains(\"prostate\", case=False, na=False)]\n",
    "print(\"\\nFiltered List of Prostate Cancer Types:\")\n",
    "print(prostate_cancer_df_syn)\n",
    "CIVIC_cancer_final[\"name\"] = CIVIC_cancer_final[\"name\"].str.strip()\n",
    "CIVIC_cancer_final.loc[CIVIC_cancer_final[\"name\"].str.lower() == \"doid:0080202\", \"name\"] = \"Adenoid Cystic Carcinoma\"\n",
    "CIVIC_cancer_final[\"name\"] = CIVIC_cancer_final[\"name\"].apply(lambda x: x.title() if isinstance(x, str) else x)\n",
    "CIVIC_cancer_final.to_csv(\"CIVIC_cancer_final.csv\", index=False)\n",
    "print(\"\\nUpdated CIVIC_cancer_final.csv has been saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e6e6c",
   "metadata": {},
   "source": [
    "# 3) Extract cancer mentions using SciScpyCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee235ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SciSpaCy models en_ner_bionlp13cg_md and en_ner_bc5cdr_md, refined for \"tags\"\n",
    "#nlp_cancer_1 = spacy.load(\"en_ner_bionlp13cg_md\")  # Recognizes 'CANCER'\n",
    "#nlp_cancer_2 = spacy.load(\"en_ner_bc5cdr_md\")  # Recognizes 'DISEASE'\n",
    "\n",
    "# Stopwords to filter out false positives\n",
    "EXCLUDE_TERMS = {\"anticancer\", \"anti cancer\", \"anti-cancer\", \"anti-tumor\",\n",
    "                 \"antitumor\", \"anti tumor\", \"cancerous\", \"non-cancerous\", \"precancerous\", \"cancer-related\"}\n",
    "\n",
    "# Function to clean extracted terms\n",
    "def clean_term(term):\n",
    "    \"\"\"Cleans extracted terms by normalizing Unicode and standardizing hyphens.\"\"\"\n",
    "    term = term.lower().strip()\n",
    "    term = unicodedata.normalize(\"NFKC\", term) \n",
    "    term = re.sub(r'[-‐–—]', ' ', term)  \n",
    "    return term\n",
    "\n",
    "def extract_cancer_mentions(text):\n",
    "    \"\"\"Extracts cancer-related mentions by first filtering entity labels before applying text filtering.\"\"\"\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return []\n",
    "    extracted_terms = set()  # Remove duplicates\n",
    "    # SciSpaCy model 1 (en_ner_bionlp13cg_md) - Only extract entities labeled as CANCER\n",
    "    doc1 = nlp_cancer_1(text)\n",
    "    for ent in doc1.ents:\n",
    "        if ent.label_ == \"CANCER\":  # Only consider \"CANCER\" labeled entities\n",
    "            extracted_terms.add(clean_term(ent.text))\n",
    "    # SciSpaCy model 2 (en_ner_bc5cdr_md) - Only extract entities labeled as DISEASE\n",
    "    doc2 = nlp_cancer_2(text)\n",
    "    for ent in doc2.ents:\n",
    "        if ent.label_ == \"DISEASE\": \n",
    "            term = clean_term(ent.text)\n",
    "            if \"cancer\" in term or \"tumor\" in term: \n",
    "                extracted_terms.add(term)\n",
    "    # Remove false positives\n",
    "    filtered_terms = {term for term in extracted_terms if term not in EXCLUDE_TERMS}\n",
    "    return list(filtered_terms)\n",
    "tqdm.pandas()\n",
    "def apply_cancer_extraction(df):\n",
    "    \"\"\"Apply cancer extraction to the 'PaperTitle' and 'Abstract' columns using a progress bar.\"\"\"\n",
    "    df[\"Extracted_Cancer_Terms\"] = (\n",
    "        df[\"PaperTitle\"].astype(str) + \" \" + df[\"Abstract\"].astype(str)\n",
    "    ).progress_apply(extract_cancer_mentions)\n",
    "    return df\n",
    "\n",
    "# ===========================\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "df = full_df.copy()\n",
    "print(f\"Processing {len(df)} rows...\")\n",
    "df = apply_cancer_extraction(df)\n",
    "\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "\n",
    "output_path = os.path.join(output_directory, \"Extracted_Cancer_Terms.csv\")\n",
    "df.to_csv(output_path, index=False)\n",
    "runtime_log_path = os.path.join(output_directory, \"running_time_cancer_extraction.txt\")\n",
    "with open(runtime_log_path, \"w\") as f:\n",
    "    f.write(f\"Total execution time: {runtime:.2f} seconds\\n\")\n",
    "print(f\"File saved successfully: {output_path}\")\n",
    "print(f\"Execution time logged in: {runtime_log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3dd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Investigate dataset of cancers\n",
    "print(len(df))\n",
    "print(f\"File saved successfully: {output_path}\")\n",
    "print(f\"Execution time logged in: {runtime_log_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea937e24",
   "metadata": {},
   "source": [
    "# ============================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8213134c",
   "metadata": {},
   "source": [
    "# 4) Match extracted cancers with CIVIC for binary matrix creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d256e99",
   "metadata": {},
   "source": [
    "## 4.1)  Load synonym dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d462b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIVIC cancer synonyms dataset\n",
    "os.chdir(output_directory)\n",
    "print(\"Loading dataset from file...\")\n",
    "CIVIC_cancer_final = pd.read_csv(output_directory + \"/CIVIC_cancer_final.csv\")\n",
    "\n",
    "# Make a copy instead of overwriting the original dataset\n",
    "CIVIC_cancer_synonyms_expanded = CIVIC_cancer_final.copy() #for further MONDO expansion\n",
    "print(\"Original count of cancer types:\", len(CIVIC_cancer_synonyms))\n",
    "\n",
    "# Remove rows where \"name\" is exactly \"cancer\"\n",
    "CIVIC_cancer_synonyms_expanded = CIVIC_cancer_synonyms_expanded[\n",
    "    ~CIVIC_cancer_synonyms_expanded[\"name\"].str.lower().isin([\"cancer\", \"carcinoma\", \"tumor\", \"tumour\",\"solid tumors, advanced\",\"solid tumor\"])\n",
    "]\n",
    "print(\"Original count of cancer types after 'cancer' removal:\", len(CIVIC_cancer_synonyms_expanded))\n",
    "\n",
    "new_cancers = pd.DataFrame([\n",
    "    {\n",
    "        \"id\": \"new1\",\n",
    "        \"name\": \"metastatic castration-resistant prostate cancer\",\n",
    "        \"doid\": \"N/A\",\n",
    "        \"synonyms\": [\"mCRPC\", \"advanced prostate cancer\", \"CRPC\", \"castration-resistant PC\",\n",
    "                     \"advanced-stage prostate cancer\", \n",
    "                     \"androgen-independent prostate cancer\",\n",
    "                     \"androgen independent prostate cancer\",\n",
    "                     \"metastatic castrate resistant prostate cancer\",\n",
    "                     \"metastatic castrate,resistant prostate cancer\",\n",
    "                     \"hormone-refractory prostate cancer\",\n",
    "                     \"bone metastatic castration resistant prostate cancer\",\n",
    "                     \"bone metastatic castration-resistant prostate cancer\",\n",
    "                     \"metastatic prostate cancer castration resistant\",\n",
    "                     \"bone metastatic crpc\",\n",
    "                     \"metastatic prostate cancer castration-resistant\",\n",
    "                     \"metastatic castration-resistance prostate cancer\", \"androgen-independent prostate cancer\",\n",
    "                     \"metastatic castrate-resistant prostate cancer\",\n",
    "                     \"brca1 mutated metastatic castration resistant prostate cancer\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"new2\",\n",
    "        \"name\": \"metastatic hormone-sensitive prostate cancer\",\n",
    "        \"doid\": \"N/A\",\n",
    "        \"synonyms\": [\"mHSPC\", \"castrationsensitive prostate cancer\", \n",
    "                     \"hormone-sensitive metastatic prostate cancer\", \"HSPC\",\n",
    "                     \"hormone sensitive prostate cancer\", \n",
    "                     \"androgen-dependent prostate cancer\",\n",
    "                     \"androgen dependent prostate cancer\",\n",
    "                     \"metastatic castration-sensitive prostate cancer\",\n",
    "                     \"androgen-dependent metastatic prostate cancer\", \"hormone-naïve prostate cancer\"]\n",
    "    }\n",
    "])\n",
    "\n",
    "CIVIC_cancer_synonyms_expanded = pd.concat([CIVIC_cancer_synonyms_expanded, new_cancers], ignore_index=True)\n",
    "CIVIC_cancer_synonyms_expanded[\"synonyms\"] = CIVIC_cancer_synonyms_expanded[\"synonyms\"].apply(\n",
    "    lambda x: [syn.strip() for syn in x.replace(\";\", \",\").split(\",\") if syn.strip()] if isinstance(x, str) else x\n",
    ")\n",
    "print(\"Updated count of cancer types:\", len(CIVIC_cancer_synonyms_expanded))\n",
    "print(\"Successful exection!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db947714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns \"name\" and \"synonyms\"\n",
    "CIVIC_cancer_synonyms_expanded2 = CIVIC_cancer_synonyms_expanded[[\"name\", \"synonyms\"]]\n",
    "CIVIC_cancer_synonyms_expanded2.to_csv(\"CIVIC_cancer_synonyms_expanded2.csv\", index=False)\n",
    "print(\"\\nThe file 'CIVIC_cancer_synonyms_expanded2.csv' has been saved successfully.\")\n",
    "print(CIVIC_cancer_synonyms_expanded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check CIVIC dataframe\n",
    "print(\"Is 'carcinoma' still in the dataset?\", any(CIVIC_cancer_synonyms_expanded[\"name\"].str.lower() == \"carcinoma\"))\n",
    "print(\"Is 'cancer' still in the dataset?\", any(CIVIC_cancer_synonyms_expanded[\"name\"].str.lower() == \"cancer\"))\n",
    "print(\"Is 'tumor' still in the dataset?\", any(CIVIC_cancer_synonyms_expanded[\"name\"].str.lower() == \"tumor\"))\n",
    "print(\"Is 'solid tumors, advanced' still in the dataset?\", any(CIVIC_cancer_synonyms_expanded[\"name\"].str.lower() == \"solid tumors, advanced\"))\n",
    "print(\"Is 'solid tumor' still in the dataset?\", any(CIVIC_cancer_synonyms_expanded[\"name\"].str.lower() == \"solid tumor\"))\n",
    "sorted_names = sorted(CIVIC_cancer_synonyms_expanded[\"name\"].unique(), key=len)\n",
    "print(CIVIC_cancer_synonyms_expanded2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96edd35b",
   "metadata": {},
   "source": [
    "## 4.2) Define function and clean extracted cancer terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e7d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Load Dataset with extracted cancer terms from SciSpyCy\n",
    "# ======================================================================\n",
    "print(\"Loading dataset from file...\")\n",
    "cancer_mapping_df = pd.read_csv(output_directory + \"/Extracted_Cancer_Terms.csv\")\n",
    "print(\"Dataset loaded from csv.\")\n",
    "print(f\"Length of dataset copy: {len(cancer_mapping_df):,}\")\n",
    "\n",
    "# Ensure \"Extracted_Cancer_Terms\" is in list format\n",
    "cancer_mapping_df[\"Extracted_Cancer_Terms\"] = cancer_mapping_df[\"Extracted_Cancer_Terms\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "original_length = len(cancer_mapping_df)\n",
    "print(cancer_mapping_df.columns)\n",
    "print(\"Original length:\",original_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c742cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ==================================================== ###\n",
    "### CLEANING OF EXTRACTED CANCER FOR BETTER MATCHING     ###\n",
    "### ==================================================== ###\n",
    "tqdm.pandas()\n",
    "cancer_mapping_df_cleaning = cancer_mapping_df.copy()\n",
    "\n",
    "# List of prefixes to remove\n",
    "prefixes_to_remove = [\n",
    "    \"age\", \n",
    "    \"aggressive\", \n",
    "    \"advance\", \"advanced\",\n",
    "    \"alk positive\", \n",
    "    \"alk+\", \n",
    "    \"ampullary\", \n",
    "    \"anti\", \n",
    "    \"antitumor\",\n",
    "    \"brca associated\",\n",
    "    \"brca1 associated\",\n",
    "    \"brca2 associated\",\n",
    "    \"brca1\", \n",
    "    \"brca2\", \n",
    "    \"brca 1\", \n",
    "    \"brca 2\", \n",
    "    \"brca-mutated\", \n",
    "    \"brca-positive\", \n",
    "    \"braf\", \n",
    "    \"brca1-mutated\",\n",
    "    \"brca mutant\", \"brca1 mutant\",\"brca2 mutant\",\n",
    "    \"brca2 altered\",\n",
    "    \"brca1/2\", \n",
    "    \"brca2-mutated\", \n",
    "    \"brca deficient\",\n",
    "    \"brca linked\", \n",
    "    \"brca negative\", \n",
    "    \"brca positive\", \n",
    "    \"cell line\", \n",
    "    \"cell lines\", \n",
    "    \"iii\", \"iiii\", \"iiiii\", \"iiiv\", \"iiv\",\n",
    "    \"chemoresistant\", \"circulating\",\n",
    "    \"disease\", \"diseases\",\n",
    "    \"cisplatin\", \n",
    "    \"dna alterations\", \n",
    "    \"double negative\", \n",
    "    \"early stage\",\n",
    "    \"germline\",  \n",
    "    \"human\",\n",
    "    \"kras mutant\", \"kras\",\n",
    "    \"hypoxic\",\n",
    "    \"intercellular\",\n",
    "    \"late stage\", \n",
    "    \"line\", \n",
    "    \"lines\",\n",
    "    \"mcf\", \"mcf 7\", \n",
    "    \"mediastinal\", \n",
    "    \"membrane\", \n",
    "    \"methylated\", \n",
    "    \"mice\", \n",
    "    \"mouse\", \n",
    "    \"murine\",\n",
    "    \"mutation\", \n",
    "    \"n myc\", \n",
    "    \"organoids\", \n",
    "    \"pain\", \n",
    "    \"parp\", \n",
    "    \"patient\", \n",
    "    \"patients\", \n",
    "    \"platinum-sensitive\", \n",
    "    \"predisposition\", \n",
    "    \"sample\", \"samples\", \n",
    "    \"senescent\", \n",
    "    \"silenced\",  \n",
    "    \"somatic\", \n",
    "    \"specific\", \n",
    "    \"specimen\", \n",
    "    \"specimens\", \n",
    "    \"stage\", \n",
    "    \"tissue\", \"tissues\", \"tnbc\", \"tumor dna\", \n",
    "    \"tp53\", \"p53\",\n",
    "    \"tumor specimen\", \"tumorigenic\", \"xenograft\", \n",
    "    \"xenografts\",\n",
    "    \"brcawt\", \"dna\", \"biopsis\",\"abstract\",\n",
    "    \"therapy related\",\n",
    "    \"moderate\",\n",
    "    \"advance stage\",\"advanced stage\",\n",
    "    \"chemo\", \"chemotherapy\", \"ilc\"\n",
    "]\n",
    "\n",
    "# Define replacements for specific words\n",
    "word_replacements = {\n",
    "    \"cancers\": \"cancer\",\n",
    "    \"tumour\": \"tumor\",\n",
    "    \"tumours\": \"tumor\",\n",
    "    \"tumors\": \"tumor\",\n",
    "    \"carcinomas\": \"carcinoma\",\n",
    "    \"gliomas\": \"glioma\",\n",
    "    \"adenocarcinomas\": \"adenocarcinoma\"\n",
    "}\n",
    "\n",
    "def clean_cancer_terms(terms):\n",
    "    cleaned_terms = []\n",
    "    \n",
    "    # Iterate over the terms in the list\n",
    "    for term in terms:\n",
    "        term = term.strip().lower()  # Make term lowercase for consistency\n",
    "        # Remove unwanted characters like +, ., /, and numbers at the beginning\n",
    "        term = re.sub(r\"^[\\+\\.,\\d\\(\\)\\-\\s]+\", \"\", term)  # Remove numbers, commas, plus signs, spaces, and dots at the start\n",
    "        # Remove unwanted prefixes using regex with word boundaries (\\b)\n",
    "        for prefix in prefixes_to_remove:\n",
    "            term = re.sub(rf\"\\b{prefix}\\b\\s*\", \"\", term)  # Remove exact match of prefix, ensuring it's a whole word\n",
    "        # Replace specified words based on the `word_replacements` dictionary\n",
    "        for old_word, new_word in word_replacements.items():\n",
    "            term = term.replace(old_word, new_word)\n",
    "        # Remove duplicate terms within the same string (e.g., 'gastric cancer gastric cancer' -> 'gastric cancer')\n",
    "        words = term.split()\n",
    "        unique_words = list(dict.fromkeys(words))  # Using dict.fromkeys to remove duplicates while keeping order\n",
    "        cleaned_term = \" \".join(unique_words)\n",
    "        # Add cleaned term only if it's not empty\n",
    "        if cleaned_term.strip():\n",
    "            cleaned_terms.append(cleaned_term.strip())\n",
    "    return cleaned_terms\n",
    "\n",
    "# Function to clean the list of cancer terms\n",
    "def clean_extracted_terms(value):\n",
    "    if isinstance(value, list):\n",
    "        return clean_cancer_terms(value)\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "# Apply cleaning to the \"Extracted_Cancer_Terms\" column\n",
    "cancer_mapping_df_cleaning[\"Extracted_Cancer_Terms_cleaned\"] = cancer_mapping_df_cleaning[\"Extracted_Cancer_Terms\"].progress_apply(clean_extracted_terms)\n",
    "cancer_mapping_df_cleaning.rename(columns={\n",
    "    \"Extracted_Cancer_Terms\": \"Extracted_Cancer_Terms_old\", \n",
    "    \"Extracted_Cancer_Terms_cleaned\": \"Extracted_Cancer_Terms\"\n",
    "}, inplace=True)\n",
    "\n",
    "print(cancer_mapping_df_cleaning[['Extracted_Cancer_Terms_old', 'Extracted_Cancer_Terms']].head())\n",
    "cancer_mapping_df_cleaning.to_csv(\"cleaned_extracted_cancer_terms.csv\", index=False)\n",
    "print(\"\\n\\n--> Full dataset has been saved to 'cleaned_extracted_cancer_terms.csv'.\")\n",
    "cancer_mapping_df_cleaning.head(2000).to_csv(\"cleaned_extracted_cancer_terms_2000.csv\", index=False) #subset\n",
    "print(\"--> The first 2000 rows have been saved to 'cleaned_extracted_cancer_terms_2000'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224faf0c",
   "metadata": {},
   "source": [
    "## 4.3) Run binary matrix creation, and create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8750be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and load dataset\n",
    "df = cancer_mapping_df_cleaning.copy()\n",
    "print(f\"Length of dataset copy: {len(cancer_mapping_df_cleaning):,}\")\n",
    "\n",
    "# Ensure \"Extracted_Cancer_Terms\" is in list format\n",
    "df[\"Extracted_Cancer_Terms\"] = df[\"Extracted_Cancer_Terms\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Normalize cancer terms for better matching\n",
    "def normalize_cancer_term(term):\n",
    "    if not isinstance(term, str):\n",
    "        return term\n",
    "    term = term.lower().strip()\n",
    "    term = unicodedata.normalize(\"NFKC\", term)\n",
    "    term = re.sub(r\"\\(.*?\\)\", \"\", term).strip()\n",
    "    term = re.sub(r'\\b(cancers|carcinoma|carcinomas|tumor|tumors)\\b', 'cancer', term)\n",
    "    term = re.sub(r'[\\.\\d/]+$', '', term)\n",
    "    term = re.sub(r'\\s+', ' ', term).strip()\n",
    "    return term\n",
    "\n",
    "# Expand synonyms\n",
    "def expand_synonyms(df):\n",
    "    expanded_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        cancer_name = normalize_cancer_term(row[\"name\"])\n",
    "        expanded_rows.append({\"cancer_type\": cancer_name, \"standard_name\": cancer_name})\n",
    "        if isinstance(row[\"synonyms\"], list):\n",
    "            synonyms = [normalize_cancer_term(syn) for syn in row[\"synonyms\"] if syn.strip()]\n",
    "            for synonym in synonyms:\n",
    "                expanded_rows.append({\"cancer_type\": synonym, \"standard_name\": cancer_name})\n",
    "    return pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Load CIVIC dataset\n",
    "CIVIC_cancer_synonyms_expanded2 = pd.read_csv(\"CIVIC_cancer_synonyms_expanded2.csv\")\n",
    "expanded_cancer_df = expand_synonyms(CIVIC_cancer_synonyms_expanded2)\n",
    "# Remove rows where \"cancer_type\" is exactly \"cancer\"\n",
    "expanded_cancer_df = expanded_cancer_df[expanded_cancer_df[\"cancer_type\"].str.lower() != \"cancer\"]\n",
    "\n",
    "# Create a dictionary mapping names and synonyms to standardized names\n",
    "cancer_mapping = dict(zip(expanded_cancer_df[\"cancer_type\"], expanded_cancer_df[\"standard_name\"]))\n",
    "\n",
    "# Map extracted cancer terms\n",
    "no_match_count = 0\n",
    "open(\"unmatched_terms_log.txt\", \"w\").close()\n",
    "def map_cancer_terms(terms):\n",
    "    global no_match_count\n",
    "    if not isinstance(terms, list):\n",
    "        return []\n",
    "    mapped_terms = []\n",
    "    unmatched_terms = set()\n",
    "    for term in terms:\n",
    "        normalized_term = normalize_cancer_term(term)\n",
    "        if normalized_term in cancer_mapping:\n",
    "            mapped_terms.append(cancer_mapping[normalized_term])\n",
    "        else:\n",
    "            no_match_count += 1\n",
    "            unmatched_terms.add(normalized_term)\n",
    "\n",
    "    if unmatched_terms:\n",
    "        with open(\"unmatched_terms_log.txt\", \"a\") as f:\n",
    "            for term in unmatched_terms:\n",
    "                f.write(term + \"\\n\")\n",
    "\n",
    "    return list(set(mapped_terms))\n",
    "tqdm.pandas()\n",
    "df[\"Mapped_Cancer_Terms\"] = df[\"Extracted_Cancer_Terms\"].progress_apply(map_cancer_terms)\n",
    "\n",
    "# Identify Unmatched Terms\n",
    "df[\"Unmatched_Cancer_Terms\"] = df[\"Extracted_Cancer_Terms\"].apply(\n",
    "    lambda terms: [term for term in terms if term not in cancer_mapping]\n",
    ")\n",
    "\n",
    "# Clean Unmatched Terms (Remove \"Metastatic\" at Start or End)\n",
    "def clean_and_remap_unmatched_terms(terms):\n",
    "    global no_match_count\n",
    "    if not isinstance(terms, list):\n",
    "        return []\n",
    "    remapped_terms = []\n",
    "    for term in terms:\n",
    "        cleaned_term = re.sub(r\"^metastatic\\s+|\\s+metastatic$\", \"\", term, flags=re.IGNORECASE).strip()\n",
    "        if cleaned_term in cancer_mapping:\n",
    "            remapped_terms.append(cancer_mapping[cleaned_term])\n",
    "        else:\n",
    "            pass\n",
    "    return list(set(remapped_terms))\n",
    "df[\"Remapped_Cancer_Terms\"] = df[\"Unmatched_Cancer_Terms\"].apply(clean_and_remap_unmatched_terms)\n",
    "\n",
    "# Combine Original & Remapped Matches\n",
    "df[\"Final_Mapped_Cancer_Terms\"] = df[\"Mapped_Cancer_Terms\"] + df[\"Remapped_Cancer_Terms\"]\n",
    "df[\"Final_Mapped_Cancer_Terms\"] = df[\"Final_Mapped_Cancer_Terms\"].apply(lambda x: list(set(x)))\n",
    "\n",
    "# Generate and save binary matrix\n",
    "binary_rows = [{\"PaperId\": row[\"PaperId\"], \"mapped_cancer\": term} for _, row in df.iterrows() for term in row[\"Final_Mapped_Cancer_Terms\"]]\n",
    "binary_df = pd.DataFrame(binary_rows)\n",
    "binary_matrix = binary_df.pivot_table(index=\"PaperId\", columns=\"mapped_cancer\", aggfunc=lambda x: 1, fill_value=0)\n",
    "df_binary_matrix = df.merge(binary_matrix, on=\"PaperId\", how=\"left\").fillna(0)\n",
    "columns_to_remove = [col for col in df_binary_matrix.columns if col.lower() == \"cancer\"]\n",
    "df_binary_matrix.drop(columns=columns_to_remove, inplace=True)\n",
    "print(f\"Removed columns: {columns_to_remove}\")\n",
    "df_binary_matrix[\"Cancer_Type_Sum\"] = df_binary_matrix.iloc[:, df.shape[1]:].sum(axis=1)\n",
    "df_binary_matrix.to_csv(\"binary_cancer_matrix_with_sum.csv\", index=False) #save full matrix\n",
    "\n",
    "# Drop rows where Cancer_Type_Sum == 0\n",
    "df_binary_matrix_filtered = df_binary_matrix[df_binary_matrix[\"Cancer_Type_Sum\"] > 0]\n",
    "df_binary_matrix_filtered_zero = df_binary_matrix[df_binary_matrix[\"Cancer_Type_Sum\"] == 0]\n",
    "\n",
    "# Save the filtered dataset\n",
    "df_binary_matrix_filtered.to_csv(\"binary_cancer_matrix_filtered.csv\", index=False)\n",
    "df_binary_matrix_filtered_zero.to_csv(\"binary_cancer_matrix_filtered_zero.csv\", index=False)\n",
    "\n",
    "# Calculate lengths of datasets\n",
    "original_length = len(df_binary_matrix)\n",
    "filtered_length = len(df_binary_matrix_filtered)\n",
    "dropped_length = original_length - filtered_length\n",
    "dropped_percentage = (dropped_length / original_length) * 100\n",
    "cancer_percentage = (filtered_length / original_length) * 100\n",
    "\n",
    "# Print dataset sizes with thousand separators\n",
    "print(f\"\\nOriginal dataset length: {original_length:,}\")\n",
    "print(f\"Filtered dataset length (Cancer_Type_Sum > 0): {filtered_length:,} ({cancer_percentage:.2f}%)\")\n",
    "print(f\"Dropped rows (Cancer_Type_Sum == 0): {dropped_length:,} ({dropped_percentage:.2f}%)\")\n",
    "\n",
    "# Verify if numbers add up correctly\n",
    "if original_length == (filtered_length + dropped_length):\n",
    "    print(\"\\n--> The numbers add up correctly!\")\n",
    "else:\n",
    "    print(\"\\n--> Warning: The numbers do NOT add up correctly!\")\n",
    "\n",
    "print(\"\\nBinary matrix saved successfully!\")\n",
    "print(f\"\\nTotal 'No match found for' messages: {no_match_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e330fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for cancer columns\n",
    "column_name = \"solid tumor\"\n",
    "if column_name in df_binary_matrix_filtered.columns:\n",
    "    print(f\"Column '{column_name}' IS PRESENT in the DataFrame.\")\n",
    "else:\n",
    "    print(f\"Column '{column_name}' is NOT present in the DataFrame.\")\n",
    "    \n",
    "# Investigate unmatched terms\n",
    "with open(\"unmatched_terms_log.txt\", \"r\") as file:\n",
    "    unmatched_terms = file.readlines()\n",
    "unmatched_terms = [term.strip() for term in unmatched_terms]\n",
    "unmatched_terms.sort()\n",
    "with open(\"unmatched_terms_log_sorted.txt\", \"w\") as file:\n",
    "    for term in unmatched_terms:\n",
    "        file.write(term + \"\\n\")\n",
    "\n",
    "print(\"Unmatched terms sorted and saved to 'unmatched_terms_log_sorted.txt'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba600e2",
   "metadata": {},
   "source": [
    "# ========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba59aa80",
   "metadata": {},
   "source": [
    "# 5) Cancer parent mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f6e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIVIC_cancer_synonyms = \"CIVIC_cancer_synonyms.csv\"\n",
    "CIVIC_cancer_synonyms_df = pd.read_csv(CIVIC_cancer_synonyms)\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"Length of dataset\", len(CIVIC_cancer_synonyms_df))\n",
    "print(CIVIC_cancer_synonyms_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c2bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIVIC_cancer_synonyms = \"CIVIC_cancer_synonyms.csv\"\n",
    "CIVIC_cancer_synonyms_df = pd.read_csv(CIVIC_cancer_synonyms)\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"Length of dataset\", len(CIVIC_cancer_synonyms_df))\n",
    "\n",
    "##### Conntect to Disease Ontology API\n",
    "# Configure logging to suppress debug/info messages\n",
    "logging.basicConfig(level=logging.WARNING, format=\"%(levelname)s: %(message)s\")\n",
    "# Function to extract DOID from the diseaseURL column\n",
    "def extract_doid(url):\n",
    "    if pd.notna(url):\n",
    "        match = re.search(r\"DOID:(\\d+)\", url)  # Extracts numbers after \"DOID:\"\n",
    "        if match:\n",
    "            return match.group(1)  # Returns the extracted DOID (keeps leading zeros)\n",
    "    return None\n",
    "\n",
    "# Apply the extraction function\n",
    "CIVIC_cancer_synonyms_df[\"clean_doid\"] = CIVIC_cancer_synonyms_df[\"diseaseUrl\"].apply(extract_doid)\n",
    "\n",
    "# Disease Ontology API base URL\n",
    "DO_API_BASE = \"https://api.disease-ontology.org/v1/terms/DOID:{}\"\n",
    "\n",
    "# Lists to track issues\n",
    "missing_doid_records = []\n",
    "failed_api_requests = []\n",
    "successful_but_no_nci = []\n",
    "\n",
    "# Function to get NCI ID, Parent DOIDs, and Parent Names\n",
    "def get_nci_and_parents(doid, row):\n",
    "    if not doid:\n",
    "        missing_doid_records.append(row)  # Track rows with missing DOIDs\n",
    "        return None, None, None  # Skip if DOID is missing\n",
    "\n",
    "    doid_formatted = f\"DOID:{doid}\"\n",
    "    url = DO_API_BASE.format(doid_formatted)\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # Extract NCI ID\n",
    "            nci_id = None\n",
    "            if \"xrefs\" in data:\n",
    "                for ref in data[\"xrefs\"]:\n",
    "                    if ref.startswith(\"NCI:\"):\n",
    "                        nci_id = ref.replace(\"NCI:\", \"\")\n",
    "            \n",
    "            # Extract parent DOIDs\n",
    "            parents = data.get(\"parents\", [])\n",
    "            parent_doids = \", \".join(parents) if parents else None\n",
    "            \n",
    "            # Extract parent names\n",
    "            parent_names = []\n",
    "            for parent_doid in parents:\n",
    "                parent_name = get_parent_name(parent_doid)\n",
    "                if parent_name:\n",
    "                    parent_names.append(parent_name)\n",
    "            \n",
    "            parent_names_str = \", \".join(parent_names) if parent_names else None\n",
    "\n",
    "            # If no NCI ID, track it\n",
    "            if nci_id is None:\n",
    "                successful_but_no_nci.append(row)\n",
    "            return nci_id, parent_doids, parent_names_str\n",
    "        else:\n",
    "            logging.warning(f\"API Request Failed for DOID {doid_formatted} - Status Code: {response.status_code}\")\n",
    "            failed_api_requests.append(row)\n",
    "            return None, None, None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching DOID {doid_formatted}: {e}\")\n",
    "        failed_api_requests.append(row)\n",
    "        return None, None, None\n",
    "\n",
    "# Function to fetch parent disease name from DOID\n",
    "def get_parent_name(doid):\n",
    "    url = DO_API_BASE.format(doid)\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return data.get(\"name\", \"Unknown\") \n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception:\n",
    "        return \"Unknown\" \n",
    "\n",
    "# Manually iterate with progress bar\n",
    "nci_ids = []\n",
    "parent_doid_list = []\n",
    "parent_name_list = []\n",
    "\n",
    "for _, row in tqdm(CIVIC_cancer_synonyms_df.iterrows(), total=len(CIVIC_cancer_synonyms_df), desc=\"Fetching NCI IDs & Parents\"):\n",
    "    nci_id, parent_doids, parent_names = get_nci_and_parents(row[\"clean_doid\"], row)\n",
    "    nci_ids.append(nci_id)\n",
    "    parent_doid_list.append(parent_doids)\n",
    "    parent_name_list.append(parent_names)\n",
    "\n",
    "# Assign the extracted data to the DataFrame\n",
    "CIVIC_cancer_synonyms_df[\"NCI_ID\"] = nci_ids\n",
    "CIVIC_cancer_synonyms_df[\"parent_DOIDs\"] = parent_doid_list \n",
    "CIVIC_cancer_synonyms_df[\"parent_names\"] = parent_name_list\n",
    "\n",
    "# Save updated data\n",
    "output_file = \"CIVIC_cancer_synonyms_with_NCI_and_parents.csv\"\n",
    "CIVIC_cancer_synonyms_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Save missing DOIDs separately\n",
    "if missing_doid_records:\n",
    "    missing_doid_df = pd.DataFrame(missing_doid_records)\n",
    "    missing_doid_df.to_csv(\"CIVIC_cancers_missing_doid.csv\", index=False)\n",
    "    print(f\"Saved {len(missing_doid_records)} records with missing DOIDs to 'CIVIC_cancers_missing_doid.csv'\")\n",
    "\n",
    "# Save failed API requests separately\n",
    "if failed_api_requests:\n",
    "    failed_api_df = pd.DataFrame(failed_api_requests)\n",
    "    failed_api_df.to_csv(\"CIVIC_cancers_failed_requests.csv\", index=False)\n",
    "    print(f\"Saved {len(failed_api_requests)} records that failed API requests to 'CIVIC_cancers_failed_requests.csv'\")\n",
    "\n",
    "# Save successful API calls that had no NCI ID separately\n",
    "if successful_but_no_nci:\n",
    "    successful_but_no_nci_df = pd.DataFrame(successful_but_no_nci)\n",
    "    successful_but_no_nci_df.to_csv(\"CIVIC_cancers_successful_but_no_NCI.csv\", index=False)\n",
    "    print(f\"Saved {len(successful_but_no_nci)} records that had successful API responses but no NCI ID to 'CIVIC_cancers_successful_but_no_NCI.csv'\")\n",
    "\n",
    "# Summary output with detailed breakdown\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"- Total records processed: {len(CIVIC_cancer_synonyms_df)}\")\n",
    "print(f\"- Records with missing DOIDs: {len(missing_doid_records)}\")\n",
    "print(f\"- Records that failed API requests: {len(failed_api_requests)}\")\n",
    "print(f\"- Records with successful API responses but no NCI ID: {len(successful_but_no_nci)}\")\n",
    "print(f\"- Total records with missing NCI_IDs: {len(missing_doid_records) + len(failed_api_requests) + len(successful_but_no_nci)}\")\n",
    "print(f\"Processing complete! Updated file saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2faf3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CIVIC_cancer_synonyms_df) # Convert \"name\" column to a list\n",
    "# Issue in the database, replace \"DOID:0080202\" with properly capitalized \"Adenoid Cystic Carcinoma\"\n",
    "CIVIC_cancer_synonyms_df.loc[CIVIC_cancer_synonyms_df[\"name\"].str.lower() == \"doid:0080202\", \"name\"] = \"Adenoid Cystic Carcinoma\"\n",
    "# Save updated data\n",
    "output_file = \"CIVIC_cancer_synonyms_with_NCI_and_parents.csv\"\n",
    "CIVIC_cancer_synonyms_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a2e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cancer Cleaning\n",
    "\n",
    "file_path = \"CIVIC_cancer_synonyms_with_NCI_and_parents.csv\"\n",
    "if \"CIVIC_cancer_synonyms_df\" not in globals() or CIVIC_cancer_synonyms_df is None:\n",
    "    try:\n",
    "        CIVIC_cancer_synonyms_df = pd.read_csv(file_path)\n",
    "        print(\"Dataset successfully loaded.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found.\")\n",
    "        CIVIC_cancer_synonyms_df = None\n",
    "\n",
    "# Remove unnecessary words at the start\n",
    "words_to_remove = [\"malignant\", \"childhood\", \"adult\", \"juvenile\"]\n",
    "CIVIC_cancer_synonyms_df[\"parent_names\"] = CIVIC_cancer_synonyms_df[\"parent_names\"].str.replace(\n",
    "    r\"\\b(?:malignant|childhood|adult|juvenile)\\b\", \"\", case=False, regex=True\n",
    ").str.strip()\n",
    "\n",
    "# Ensure all text transformations are complete, then clean spaces\n",
    "CIVIC_cancer_synonyms_df[\"parent_names\"] = (\n",
    "    CIVIC_cancer_synonyms_df[\"parent_names\"]\n",
    "    .str.replace(r'\\s+', ' ', regex=True)  # Replace multiple spaces with a single space\n",
    "    .str.strip()  # Remove leading and trailing spaces\n",
    ")\n",
    "\n",
    "# Create the \"final_parent\" column\n",
    "def process_parent_name(row):\n",
    "    parent_names = row[\"parent_names\"]\n",
    "    # If parent_names is empty or None, copy \"name\" column\n",
    "    if pd.isna(parent_names) or parent_names.strip() == \"\":\n",
    "        return row[\"name\"]\n",
    "    # Split parent_names by commas and strip spaces\n",
    "    parent_list = [p.strip() for p in parent_names.split(\",\")]\n",
    "    # Define unwanted last names\n",
    "    unwanted_terms = {\"cancer\", \"carcinoma\", \"adenocarcinoma\", \"unknown\", \"cell type cancer\", \n",
    "                      \"cell type benign neoplasm\",\"autosomal dominant disease\", \"autosomal recessive disease\", \"syndrome\"} \n",
    "    # Iterate backwards to find a valid name\n",
    "    for parent in reversed(parent_list):\n",
    "        if parent.lower() not in unwanted_terms:\n",
    "            return parent\n",
    "    # If no valid name is found (everything was \"Unknown\"), fallback to \"name\" column\n",
    "    return row[\"name\"]\n",
    "CIVIC_cancer_synonyms_df[\"final_parent\"] = CIVIC_cancer_synonyms_df.apply(process_parent_name, axis=1)\n",
    "\n",
    "\n",
    "# Remove rows where both \"name\" and \"final_parent\" are only \"cancer\", \"carcinoma\", or \"solid tumor\"\n",
    "CIVIC_cancer_synonyms_df = CIVIC_cancer_synonyms_df[\n",
    "    ~(\n",
    "        (CIVIC_cancer_synonyms_df[\"name\"].str.lower().isin([\"doid:\", \"cancer\", \"carcinoma\", \"solid cancer\",\n",
    "                                                            \"solid tumor\", \"solid tumors, advanced\"])) & \n",
    "        (CIVIC_cancer_synonyms_df[\"final_parent\"].str.lower().isin([\"none\", \"cancer\", \"carcinoma\", \"solid cancer\",\n",
    "                                                            \"solid tumor\", \"solid tumors, advanced\"]))\n",
    "    )\n",
    "]\n",
    "\n",
    "# Remove unnecessary words from \"final_parent\" as well\n",
    "CIVIC_cancer_synonyms_df[\"final_parent\"] = CIVIC_cancer_synonyms_df[\"final_parent\"].str.replace(\n",
    "    r\"\\b(?:malignant|childhood|adult|juvenile|benign)\\b\", \"\", case=False, regex=True\n",
    ").str.strip()\n",
    "\n",
    "# Clean \"final_parent\" column (Replacing terms)\n",
    "CIVIC_cancer_synonyms_df[\"final_parent\"] = (\n",
    "    CIVIC_cancer_synonyms_df[\"final_parent\"]\n",
    "    .str.replace(\"neoplasm\", \"cancer\", case=False, regex=True)\n",
    "    .str.replace(\"carcinoma\", \"cancer\", case=False, regex=True)\n",
    "    .str.replace(\"adenocarcinoma\", \"cancer\", case=False, regex=True)\n",
    "    .str.replace(\"adenocancer\", \"cancer\", case=False, regex=True)\n",
    ")\n",
    "CIVIC_cancer_synonyms_df[\"final_parent\"] = CIVIC_cancer_synonyms_df[\"final_parent\"].str.replace(\"leukaemia\", \"leukemia\", case=False, regex=True)\n",
    "\n",
    "# Keyword mapping dictionary\n",
    "keyword_mapping = {\n",
    "    \"skin\": \"skin cancer\",\n",
    "    \"breast\": \"breast cancer\",\n",
    "    \"mammary\": \"breast cancer\",\n",
    "    \"mucinous\": \"mucinous cancer\",\n",
    "    \"lung\": \"lung cancer\",\n",
    "    \"bronchio\": \"lung cancer\",\n",
    "    \"spindle cell\": \"spindle cell cancer\",  \n",
    "    \"acute myeloid leukemia\": \"acute myeloid leukemia\",    \n",
    "    \"salivary gland\": \"salivary gland cancer\",\n",
    "    \"renal\": \"renal cancer\",\n",
    "    \"prostate\": \"prostate cancer\",\n",
    "    \"pancreatic\": \"pancreatic cancer\",\n",
    "    \"medulloblastoma\": \"medulloblastoma\",\n",
    "    \"lymphoblastic leukemia\": \"lymphoblastic leukemia\",\n",
    "    \"myeloid\": \"myeloid cancer\",\n",
    "    \"kidney\": \"kidney cancer\",\n",
    "    \"head and neck\": \"head and neck cancer\",\n",
    "    \"gastrointestinal\": \"gastrointestinal cancer\",\n",
    "    \"neurofibroma\": \"neurofibroma\",\n",
    "    \"ovarian\": \"ovarian cancer\",\n",
    "    \"ovary\": \"ovarian cancer\",\n",
    "    \"supratentorial ependymoma\": \"supratentorial ependymoma\",\n",
    "    \"cervix\": \"cervix cancer\", \n",
    "    \"cervical\": \"cervix cancer\",\n",
    "    \"colorectal\": \"colon cancer\",\n",
    "    \"colon\": \"colon cancer\",\n",
    "    \"endometri\": \"endometrial cancer\",\n",
    "    \"melano\": \"melanoma\",\n",
    "    \"laryngeal\": \"laryngeal cancer\",\n",
    "    \"glioma\": \"glioma\",\n",
    "    \"bone\": \"bone cancer\",\n",
    "    \"osteo\": \"bone cancer\",\n",
    "    \"peritoneal\": \"peritoneal cancer\",\n",
    "    \"astrocytoma\": \"astrocytoma\",\n",
    "    \"glioblastoma\": \"glioblastoma\",\n",
    "    \"gastric\": \"gastric cancer\",\n",
    "    \"mesothelioma\": \"mesothelioma\",\n",
    "    \"esophag\": \"esophagus cancer\",\n",
    "    \"thyroid\": \"thyroid cancer\",\n",
    "    \"thymus\": \"thymus cancer\",\n",
    "    \"uterus\": \"uterine cancer\",\n",
    "    \"spinal\": \"spinal cancer\",\n",
    "    \"hepatocellular\": \"liver cancer\",\n",
    "    \"cholangio\": \"cholangio cancer\",\n",
    "    \"bile duct\": \"biliary tract cancer\",\n",
    "    \"glioblastoma\": \"glioma\",\n",
    "    \"gliosarcoma\": \"glioma\",\n",
    "    \"myeloid cancer\": \"hematologic cancer\",\n",
    "    \"myeloproliferative cancer\": \"hematologic cancer\",\n",
    "    \"myelodysplastic syndrome\": \"hematologic cancer\",\n",
    "    \"essential thrombocythemia\": \"hematologic cancer\",\n",
    "    \"myelofibrosis\": \"hematologic cancer\",\n",
    "    \"barrett\": \"esophagus cancer\",\n",
    "    \"fraumeni\": \"li-fraumeni syndrome\",\n",
    "    \"liposarcoma\": \"liposarcoma\",\n",
    "    \"papillary\": \"papillary cancer\"\n",
    "}\n",
    "\n",
    "# Apply keyword mapping\n",
    "CIVIC_cancer_synonyms_df[\"final_parent\"] = CIVIC_cancer_synonyms_df[\"final_parent\"].apply(\n",
    "    lambda x: next((v for k, v in keyword_mapping.items() if isinstance(x, str) and k in x.lower()), x)\n",
    ")\n",
    "\n",
    "# Classify leukemia and lymphoma\n",
    "def classify_leukemia_lymphoma(name):\n",
    "    if isinstance(name, str):\n",
    "        name_lower = name.lower()\n",
    "        has_leukemia = any(word in name_lower for word in [\"leukemia\", \"leukemic\"])\n",
    "        has_lymphoma = \"lymphoma\" in name_lower\n",
    "        if has_leukemia and has_lymphoma:\n",
    "            return \"leukemia/lymphoma\"\n",
    "        elif has_leukemia:\n",
    "            return \"leukemia\"\n",
    "        elif has_lymphoma:\n",
    "            return \"lymphoma\"\n",
    "    return name \n",
    "\n",
    "# Apply classification\n",
    "CIVIC_cancer_synonyms_df[\"final_parent\"] = CIVIC_cancer_synonyms_df[\"final_parent\"].apply(classify_leukemia_lymphoma)\n",
    "# Advanced keyword mapping with regex\n",
    "def apply_keyword_mapping(name):\n",
    "    if not isinstance(name, str):\n",
    "        return name \n",
    "    name_lower = name.lower() \n",
    "\n",
    "    # Special handling for \"bladder\" to avoid \"gallbladder\" conflicts\n",
    "    if re.search(r'\\bbladder\\b', name_lower) and \"gallbladder\" not in name_lower:\n",
    "        return \"bladder cancer\"\n",
    "\n",
    "    # Special handling for \"gallbladder\"\n",
    "    if \"gallbladder\" in name_lower:\n",
    "        return \"gallbladder cancer\"\n",
    "\n",
    "    # General keyword mapping using regex for exact word matching\n",
    "    for keyword, replacement in keyword_mapping.items():\n",
    "        if re.search(rf'\\b{re.escape(keyword)}\\b', name_lower):  \n",
    "            return replacement\n",
    "    return name \n",
    "CIVIC_cancer_synonyms_df[\"final_parent\"] = CIVIC_cancer_synonyms_df[\"final_parent\"].apply(apply_keyword_mapping)\n",
    "\n",
    "# Convert the \"final_parent\" column to all lowercase for consistency\n",
    "CIVIC_cancer_synonyms_df[\"final_parent\"] = CIVIC_cancer_synonyms_df[\"final_parent\"].str.lower()\n",
    "print(f\"\\nFinal dataset saved with all lowercase.\")\n",
    "\n",
    "# Extract unique values and their counts\n",
    "final_parent_counts = CIVIC_cancer_synonyms_df[\"final_parent\"].value_counts().sort_index()\n",
    "\n",
    "# Display total count of unique values\n",
    "print(f\"Total unique 'final_parent' values after cleaning: {len(final_parent_counts)}\\n\")\n",
    "\n",
    "final_parent_df = pd.DataFrame(final_parent_counts).reset_index()\n",
    "final_parent_df.columns = [\"final_parent\", \"count\"]\n",
    "\n",
    "for parent_name, count in final_parent_counts.items():\n",
    "    print(f\"{parent_name}: {count}\")\n",
    "\n",
    "output_file = \"CIVIC_cancer_synonyms_cleaned.csv\"\n",
    "CIVIC_cancer_synonyms_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nUpdated dataset saved as: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fb0790",
   "metadata": {},
   "source": [
    "# ========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92638c59",
   "metadata": {},
   "source": [
    "# 6) Cancer orruance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3065d2d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if df_binary_matrix_filtered is in globals() and load if necessary\n",
    "if 'df_binary_matrix_filtered' in globals():\n",
    "    df_binary_matrix_filtered_figure = df_binary_matrix_filtered.copy()\n",
    "    print(\"Dataset loaded from globals.\")\n",
    "else:\n",
    "    os.chdir(output_directory)\n",
    "    df_binary_matrix_filtered_figure = pd.read_csv(\"binary_cancer_matrix_filtered.csv\")\n",
    "    print(\"Dataset loaded from file.....\")\n",
    "print(df_binary_matrix_filtered_figure.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7760f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Identify relevant columns for calculation (from 'Final_Mapped_Cancer_Terms' to 'Cancer_Type_Sum')\n",
    "relevant_columns = df_binary_matrix_filtered_figure.columns[df_binary_matrix_filtered_figure.columns.get_loc('Final_Mapped_Cancer_Terms') + 1: df_binary_matrix_filtered_figure.columns.get_loc('Cancer_Type_Sum')]\n",
    "\n",
    "# Calculate the sum of each of these columns (which is the count of occurrences for each cancer type)\n",
    "cancer_counts = df_binary_matrix_filtered_figure[relevant_columns].sum().sort_values(ascending=False)\n",
    "\n",
    "# Rank the columns by their sum from highest to lowest (most frequently mentioned cancer types)\n",
    "cancer_counts_sorted = cancer_counts.sort_values(ascending=False)\n",
    "print(cancer_counts_sorted)\n",
    "cancer_counts_df = cancer_counts.reset_index()\n",
    "cancer_counts_df.columns = [\"cancer_type\", \"count\"]\n",
    "print(\"\\nCancer type occurrence df:\")\n",
    "print(cancer_counts_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98660ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for cancer typess\n",
    "cancer_search_term = \"primary\"\n",
    "\n",
    "# Check if the cancer type exists in the 'cancer_type' column (case-insensitive)\n",
    "cancer_exists = cancer_counts_df['cancer_type'].str.contains(cancer_search_term, case=False, na=False)\n",
    "if cancer_exists.any():\n",
    "    found_cancer = cancer_counts_df[cancer_exists]\n",
    "    print(\"Found the cancer type in the dataset:\")\n",
    "    print(found_cancer)\n",
    "else:\n",
    "    print(f\"The cancer type '{cancer_search_term}' is not found in the dataset.\")\n",
    "    \n",
    "# Get all unique cancer types from the 'cancer_type' column\n",
    "all_cancer_types = cancer_counts_df['cancer_type'].unique()\n",
    "# Display the list of all unique cancer types\n",
    "print(\"List of all unique cancer types:\")\n",
    "print(all_cancer_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a2e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CIVIC_file = \"CIVIC_cancer_synonyms_cleaned.csv\"\n",
    "CIVIC_cancer_synonyms_df = pd.read_csv(CIVIC_file)\n",
    "\n",
    "# Function to standardize cancer terms clearly\n",
    "def standardize_cancer_terms(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower().strip()\n",
    "        text = text.replace(\"adenocarcinoma\", \"cancer\")\n",
    "        text = text.replace(\"tumor\", \"cancer\")\n",
    "        text = text.replace(\"carcinoma\", \"cancer\")\n",
    "    return text\n",
    "\n",
    "# Apply standardization explicitly\n",
    "cancer_counts_df[\"cancer_type\"] = cancer_counts_df[\"cancer_type\"].apply(standardize_cancer_terms)\n",
    "CIVIC_cancer_synonyms_df[\"name\"] = CIVIC_cancer_synonyms_df[\"name\"].apply(standardize_cancer_terms)\n",
    "CIVIC_cancer_synonyms_df[\"synonyms\"] = CIVIC_cancer_synonyms_df[\"synonyms\"].astype(str).apply(standardize_cancer_terms)\n",
    "\n",
    "# Function to find final_parent clearly using names/synonyms\n",
    "def find_final_parent(cancer_type, synonyms_df):\n",
    "    match = synonyms_df.loc[synonyms_df[\"name\"] == cancer_type, \"final_parent\"]\n",
    "    if not match.empty:\n",
    "        return match.values[0]\n",
    "    for _, row in synonyms_df.iterrows():\n",
    "        if isinstance(row[\"synonyms\"], str):\n",
    "            synonyms_list = [syn.strip().lower() for syn in row[\"synonyms\"].split(\",\")]\n",
    "            if cancer_type in synonyms_list:\n",
    "                return row[\"final_parent\"]\n",
    "    return None\n",
    "cancer_counts_df[\"final_parent\"] = cancer_counts_df[\"cancer_type\"].apply(\n",
    "    lambda x: find_final_parent(x, CIVIC_cancer_synonyms_df)\n",
    ")\n",
    "\n",
    "def apply_keyword_mapping_if_missing(row, keyword_mapping):\n",
    "    if pd.isna(row[\"final_parent\"]):\n",
    "        for keyword, replacement in keyword_mapping.items():\n",
    "            if keyword in row[\"cancer_type\"]:\n",
    "                return replacement\n",
    "    return row[\"final_parent\"]\n",
    "\n",
    "cancer_counts_df[\"final_parent\"] = cancer_counts_df.apply(\n",
    "    lambda row: apply_keyword_mapping_if_missing(row, keyword_mapping), axis=1\n",
    ")\n",
    "\n",
    "def classify_leukemia_lymphoma(final_parent, cancer_type):\n",
    "    \"\"\"Ensure proper classification for 'leukemia' and 'lymphoma'.\"\"\"\n",
    "    # Convert to lowercase for consistent comparison\n",
    "    final_parent_lower = final_parent.lower() if isinstance(final_parent, str) else \"\"\n",
    "    cancer_type_lower = cancer_type.lower() if isinstance(cancer_type, str) else \"\"\n",
    "\n",
    "    # Check for occurrences in either final_parent or cancer_type\n",
    "    has_lymphoma = \"lymphoma\" in final_parent_lower or \"lymphoma\" in cancer_type_lower\n",
    "    has_leukemia = \"leukemia\" in final_parent_lower or \"leukemia\" in cancer_type_lower\n",
    "\n",
    "    # Determine classification\n",
    "    if has_leukemia and has_lymphoma:\n",
    "        return \"leukemia/lymphoma\"\n",
    "    elif has_leukemia:\n",
    "        return \"leukemia\"\n",
    "    elif has_lymphoma:\n",
    "        return \"lymphoma\"\n",
    "    return final_parent\n",
    "cancer_counts_df[\"final_parent\"] = cancer_counts_df.apply(\n",
    "    lambda row: classify_leukemia_lymphoma(row[\"final_parent\"], row[\"cancer_type\"]), axis=1\n",
    ")\n",
    "cancer_counts_df = cancer_counts_df[\n",
    "    ~(\n",
    "        (cancer_counts_df[\"cancer_type\"].str.lower().isin([\"doid:\", \"cancer\", \"carcinoma\", \"solid cancer\",\n",
    "                                                            \"solid tumor\", \"solid tumors, advanced\"]))\n",
    ")\n",
    "]\n",
    "\n",
    "cancer_counts_df.to_csv(\"cancer_counts_of_all_cancer_types.csv\", index=False)\n",
    "print(\"CSV file saved successfully as 'cancer_counts_of_all_cancer_types.csv'\")\n",
    "print(\"Length of dataset:\", len(cancer_counts_df))\n",
    "print(cancer_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cancer category occurrences\n",
    "\n",
    "cancer_counts_df = pd.read_csv(\"cancer_counts_of_all_cancer_types.csv\")\n",
    "cancer_df_length = len(cancer_df)\n",
    "cancer_category_occurrences = cancer_counts_df.groupby(\"final_parent\", as_index=False)[\"count\"].sum()\n",
    "cancer_category_occurrences = cancer_category_occurrences.sort_values(by=\"count\", ascending=False)\n",
    "other_cancers = cancer_category_occurrences[cancer_category_occurrences[\"count\"] < 300]\n",
    "other_cancers_sum = other_cancers[\"count\"].sum()\n",
    "cancer_category_occurrences = cancer_category_occurrences[cancer_category_occurrences[\"count\"] >= 300]\n",
    "other_cancers_row = pd.DataFrame({\"final_parent\": [\"other cancers\"], \"count\": [other_cancers_sum]})\n",
    "cancer_category_occurrences = pd.concat([cancer_category_occurrences, other_cancers_row], ignore_index=True)\n",
    "total_mentions = cancer_df_length\n",
    "cancer_category_occurrences[\"percentage\"] = ((cancer_category_occurrences[\"count\"] / total_mentions) * 100).round(2)\n",
    "\n",
    "print(\"\\nSummed Cancer Category Occurrences:\")\n",
    "print(\"Length of category dataset:\", len(cancer_category_occurrences))\n",
    "print(cancer_category_occurrences)\n",
    "\n",
    "cancer_category_occurrences.to_csv(\"cancer_category_occurrences_with_percentages.csv\", index=False)\n",
    "print(\"\\nCSV file saved successfully as 'cancer_category_occurrences_with_percentages.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac1f3bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####### FINAL OUTPUT SUMMARY ######\n",
    "\n",
    "full_dataset = \"cleaned_BioBERT_data.csv\"\n",
    "full_df = pd.read_csv(full_dataset)\n",
    "filtered_dataset = \"binary_cancer_matrix_filtered.csv\"\n",
    "df_binary_matrix_filtered = pd.read_csv(filtered_dataset)\n",
    "\n",
    "total_screened_articles=len(full_df)\n",
    "total_articles_with_specific_cancer_types=len(df_binary_matrix_filtered)\n",
    "percentage_specific_cancer_articles = (total_articles_with_specific_cancer_types / total_screened_articles) * 100\n",
    "\n",
    "number_of_specific_cancer_types=len(cancer_counts_df)\n",
    "number_of_cancer_categories=len(cancer_category_occurrences)\n",
    "\n",
    "# Create a formatted summary string\n",
    "summary_text = f\"\"\"\n",
    "######################## FINAL OUTPUT SUMMARY ########################\n",
    "\n",
    "Total screened articles:               {total_screened_articles:,}\n",
    "Total articles with specific cancers:  {total_articles_with_specific_cancer_types:,} ({percentage_specific_cancer_articles:.2f}%)\n",
    "----------------------------------------------------------------------\n",
    "Number of specific cancer types:       {number_of_specific_cancer_types:,}\n",
    "Number of cancer categories:           {number_of_cancer_categories:,}\n",
    "\n",
    "######################################################################\n",
    "\"\"\"\n",
    "print(summary_text)\n",
    "summary_file_path = \"final_output_cancer_type_summary.txt\"\n",
    "with open(summary_file_path, \"w\") as file:\n",
    "    file.write(summary_text)\n",
    "print(f\"Summary has been saved to {summary_file_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7922926",
   "metadata": {},
   "source": [
    "# Create matching of final parents and create new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64de0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure correct working directory\n",
    "os.chdir(output_directory)\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "# Load datasets\n",
    "CIVIC_file = \"CIVIC_cancer_synonyms_cleaned.csv\"\n",
    "CIVIC_cancer_synonyms_df = pd.read_csv(CIVIC_file)\n",
    "cancer_df = pd.read_csv(\"binary_cancer_matrix_filtered.csv\")\n",
    "\n",
    "print(\"Datasets loaded successfully.\")\n",
    "\n",
    "# Count total columns at the beginning\n",
    "total_columns_initial = len(cancer_df.columns)\n",
    "\n",
    "# Define columns to ignore (metadata columns that are NOT cancer mentions for final parent matching)\n",
    "ignore_columns = {\"PaperTitle\", \"Citations\", \"CoFoS\", \"coFoS\", \"Lang\", \"Authors\", \n",
    "                  \"Abstract\", \"Language\", \"PubYear\", \"PubDate\", \"BioBERT\", \"Cancer_Type_Sum\"}\n",
    "\n",
    "# Count columns to be analyzed (excluding ignored ones)\n",
    "cancer_columns = [col for col in cancer_df.columns if col not in ignore_columns]\n",
    "total_cancer_columns_initial = len(cancer_columns)\n",
    "\n",
    "print(f\"Total columns at start: {total_columns_initial}\")\n",
    "print(f\"Total cancer-related columns at start (excluding ignored ones): {total_cancer_columns_initial}\")\n",
    "\n",
    "# Function to standardize cancer terms\n",
    "def standardize_cancer_terms(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower().strip()\n",
    "        text = text.replace(\"adenocarcinoma\", \"cancer\")\n",
    "        text = text.replace(\"tumor\", \"cancer\")\n",
    "        text = text.replace(\"carcinoma\", \"cancer\")\n",
    "    return text\n",
    "print(\"Standardizing cancer terms in CIVIC dataset...\")\n",
    "CIVIC_cancer_synonyms_df[\"name\"] = CIVIC_cancer_synonyms_df[\"name\"].apply(standardize_cancer_terms)\n",
    "CIVIC_cancer_synonyms_df[\"synonyms\"] = CIVIC_cancer_synonyms_df[\"synonyms\"].astype(str).apply(standardize_cancer_terms)\n",
    "print(\"Standardization complete.\")\n",
    "\n",
    "# Function to find final parent using names and synonyms\n",
    "def find_final_parent(cancer_type, synonyms_df):\n",
    "    match = synonyms_df.loc[synonyms_df[\"name\"] == cancer_type, \"final_parent\"]\n",
    "    if not match.empty:\n",
    "        return match.values[0]\n",
    "    for _, row in synonyms_df.iterrows():\n",
    "        if isinstance(row[\"synonyms\"], str):\n",
    "            synonyms_list = [syn.strip().lower() for syn in row[\"synonyms\"].split(\",\")]\n",
    "            if cancer_type in synonyms_list:\n",
    "                return row[\"final_parent\"]\n",
    "    return None\n",
    "\n",
    "# Map each cancer column to its final parent\n",
    "print(\"Mapping cancer types to their final parent...\")\n",
    "cancer_type_to_final_parent = {}\n",
    "for col in tqdm(cancer_columns, desc=\"Processing Cancer Types\"):\n",
    "    parent = find_final_parent(col, CIVIC_cancer_synonyms_df)\n",
    "    if parent:\n",
    "        cancer_type_to_final_parent[col] = parent + \"_finalparent\"\n",
    "\n",
    "# Remove unmapped cancer types\n",
    "cancer_type_to_final_parent = {k: v for k, v in cancer_type_to_final_parent.items() if v is not None}\n",
    "print(f\"Mapped {len(cancer_type_to_final_parent)} cancer types to final parents.\")\n",
    "\n",
    "unique_final_parents = list(set(cancer_type_to_final_parent.values()))\n",
    "df_final_binary_matrix = cancer_df.copy()\n",
    "print(\"Initializing final parent binary matrix...\")\n",
    "new_columns = pd.DataFrame(0, index=cancer_df.index, columns=unique_final_parents)\n",
    "df_final_binary_matrix = pd.concat([df_final_binary_matrix, new_columns], axis=1)\n",
    "\n",
    "# Populate the final parent columns based on existing cancer mentions\n",
    "print(\"Processing binary matrix transformation...\")\n",
    "for cancer_type, final_parent in tqdm(cancer_type_to_final_parent.items(), desc=\"Updating Binary Matrix\"):\n",
    "    df_final_binary_matrix[final_parent] |= cancer_df[cancer_type].fillna(0).astype(int)\n",
    "\n",
    "# Count total columns at the end\n",
    "total_columns_final = len(df_final_binary_matrix.columns)\n",
    "# Count columns to be analyzed at the end (excluding ignored ones)\n",
    "cancer_columns_final = [col for col in df_final_binary_matrix.columns if col not in ignore_columns]\n",
    "total_cancer_columns_final = len(cancer_columns_final)\n",
    "\n",
    "print(f\"Total columns at end: {total_columns_final}\")\n",
    "print(f\"Total cancer-related columns at end (excluding ignored ones): {total_cancer_columns_final}\")\n",
    "\n",
    "# Save the transformed binary matrix with a progress bar\n",
    "csv_filename = \"final_parent_binary_matrix.csv\"\n",
    "chunk_size = 5_000  # Number of rows per chunk\n",
    "\n",
    "print(\"Writing final parent binary matrix to CSV with progress tracking...\")\n",
    "\n",
    "with open(csv_filename, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    df_final_binary_matrix.iloc[:0].to_csv(f, index=False) \n",
    "    for start in tqdm(range(0, len(df_final_binary_matrix), chunk_size), desc=\"Saving to CSV\"):\n",
    "        df_final_binary_matrix.iloc[start:start+chunk_size].to_csv(f, index=False, header=False, mode=\"a\")\n",
    "\n",
    "print(f\"CSV file saved successfully as '{csv_filename}'.\")\n",
    "print(\"\\nPreview of Final Parent Binary Matrix:\")\n",
    "print(df_final_binary_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23191280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns that end with \"_finalparent\"\n",
    "print(len(df_final_binary_matrix))\n",
    "final_parent_columns = [col for col in df_final_binary_matrix.columns if col.endswith(\"_finalparent\")]\n",
    "rows_all_zero_finalparent = df_final_binary_matrix[final_parent_columns].sum(axis=1) == 0\n",
    "num_rows_all_zero = rows_all_zero_finalparent.sum()\n",
    "print(f\"Number of rows where all '_finalparent' columns are 0: {num_rows_all_zero}\")\n",
    "if num_rows_all_zero > 0:\n",
    "    print(\"\\nRows where all '_finalparent' columns are 0:\")\n",
    "    print(df_final_binary_matrix[rows_all_zero_finalparent][[\"PaperId\"] + final_parent_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e554de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Final Parent Binary Matrix CSV if it's not in memory\n",
    "file_path = \"final_parent_binary_matrix.csv\"\n",
    "print(\"Reading final parent binary matrix from CSV...\")\n",
    "df_final_binary_matrix = pd.read_csv(file_path)\n",
    "print(\"CSV loaded successfully.\")\n",
    "\n",
    "# Identify columns that end with \"_finalparent\"\n",
    "final_parent_columns = [col for col in df_final_binary_matrix.columns if col.endswith(\"_finalparent\")]\n",
    "\n",
    "# Calculate the sum for each final parent column\n",
    "final_parent_sums = df_final_binary_matrix[final_parent_columns].sum().sort_values(ascending=False)\n",
    "print(\"\\nTop 20 Final Parent Sums:\")\n",
    "print(final_parent_sums.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"cancer_counts_of_all_cancer_types.csv\"\n",
    "df_cancer_occurrences = pd.read_csv(file_path)\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Total rows: {len(df_cancer_occurrences)}\")\n",
    "print(f\"Total columns: {len(df_cancer_occurrences.columns)}\")\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df_cancer_occurrences.columns.tolist())\n",
    "\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(df_cancer_occurrences.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e592f",
   "metadata": {},
   "source": [
    "# 7) Figure creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 20 most mentioned cancer types based on categories\n",
    "top_20_cancers = cancer_category_occurrences.nlargest(20, \"count\")\n",
    "# Define colors, making \"prostate cancer\" dark green\n",
    "colors = [\"darkgreen\" if cancer == \"prostate cancer\" else \"royalblue\" for cancer in top_20_cancers[\"final_parent\"]]\n",
    "max_y_value = top_20_cancers[\"count\"].max()\n",
    "plt_ylim = max_y_value * 1.2\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(top_20_cancers[\"final_parent\"], top_20_cancers[\"count\"], color=colors)\n",
    "plt.xlabel(\"Cancer type\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Number of mentions\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(f\"Most frequently mentioned cancer types\\n in {total_articles_with_specific_cancer_types:,} \"\n",
    "          f\"({percentage_specific_cancer_articles:.2f}%) articles\", fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=10)\n",
    "plt.ylim(0, plt_ylim)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height * 1.02, f\"{int(height):,}\", \n",
    "             ha=\"center\", va=\"bottom\", fontsize=10, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207125d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Detailed figure of cancer types #####\n",
    "\n",
    "#Only keep the top 20 cancer types\n",
    "publication_number = len(df_binary_matrix_filtered)\n",
    "top_20_cancer_counts = cancer_counts_sorted.head(20)\n",
    "\n",
    "# Plot the figure (bar plot) for top 20 cancer types\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = top_20_cancer_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "# Highlight \"cancer of interest\" with dark green color and bold label\n",
    "for i, bar in enumerate(bars.patches):\n",
    "    if top_20_cancer_counts.index[i] == \"prostate cancer\":\n",
    "        bar.set_facecolor('darkgreen')\n",
    "        bars.get_xticklabels()[i].set_fontweight('bold')\n",
    "plt.title(f'Top 20 cancer types mentioned in publications (Total publications: {publication_number:,})', fontsize=16)\n",
    "plt.xlabel('Cancer type', fontsize=12)\n",
    "plt.ylabel('Number of publications', fontsize=12)\n",
    "formatter = FuncFormatter(lambda x, _: f'{int(x):,}')\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe191c",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca424a",
   "metadata": {},
   "source": [
    "# 6) Evaluation and other NER-based models for cacner type extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b86dd1",
   "metadata": {},
   "source": [
    "### 3.1) SciSpaCy \"en_ner_bionlp13cg_md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea19aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "def extract_cancer_mentions(text):\n",
    "    if pd.isna(text) or text.strip() == \"\": return []\n",
    "    doc = nlp_cancer(text)\n",
    "    cancer_terms = [ent.text.lower() for ent in doc.ents if \"cancer\" in ent.text.lower() or \"tumor\" in ent.text.lower()]\n",
    "    return list(set(cancer_terms))\n",
    "start_time = time.time()\n",
    "df = full_df.copy()\n",
    "df.loc[:, \"Extracted_Cancer_Terms\"] = (df[\"PaperTitle\"].astype(str) + \" \" + df[\"Abstract\"].astype(str)).progress_apply(extract_cancer_mentions)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "output_path = os.path.join(output_directory, \"Extracted_Cancer_Terms.csv\")\n",
    "df.to_csv(output_path, index=False)\n",
    "runtime_log_path = os.path.join(output_directory, \"running_time_cancer_extraction.txt\")\n",
    "with open(runtime_log_path, \"w\") as f: f.write(f\"Total execution time: {runtime:.2f} seconds\\n\")\n",
    "\n",
    "print(f\"File saved successfully: {output_path}\")\n",
    "print(f\"Execution time logged in: {runtime_log_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b801430b",
   "metadata": {},
   "source": [
    "### 3.2) SciSpaCy \"en_ner_bionlp13cg_md\" and \"en_ner_bc5cdr_md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUDE_TERMS = {\"anticancer\",\"anti cancer\", \"anti-cancer\", \"anti-tumor\", \"metastasis\", \"metastases\", \"antitumor\", \"anti tumor\", \"cancerous\", \"non-cancerous\", \"precancerous\", \"cancer-related\"}\n",
    "def clean_term(term): return term.lower().strip()\n",
    "def extract_cancer_mentions(text):\n",
    "    if pd.isna(text) or text.strip() == \"\": return []\n",
    "    extracted_terms = set()\n",
    "    doc1 = nlp_cancer_1(text)\n",
    "    doc2 = nlp_cancer_2(text)\n",
    "    for ent in doc1.ents:\n",
    "        term = clean_term(ent.text)\n",
    "        if \"cancer\" in term or \"tumor\" in term: extracted_terms.add(term)\n",
    "    for ent in doc2.ents:\n",
    "        term = clean_term(ent.text)\n",
    "        if \"cancer\" in term or \"tumor\" in term: extracted_terms.add(term)\n",
    "    filtered_terms = {term for term in extracted_terms if term not in EXCLUDE_TERMS}\n",
    "    return list(filtered_terms)\n",
    "start_time = time.time()\n",
    "tqdm.pandas()\n",
    "full_df.loc[:, \"Extracted_Cancer_Terms\"] = (full_df[\"PaperTitle\"].astype(str) + \" \" + full_df[\"Abstract\"].astype(str)).progress_apply(extract_cancer_mentions)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "output_path = os.path.join(output_directory, \"Extracted_Cancer_Terms_Hybrid.csv\")\n",
    "full_df.to_csv(output_path, index=False)\n",
    "runtime_log_path = os.path.join(output_directory, \"running_time_cancer_extraction_hybrid.txt\")\n",
    "with open(runtime_log_path, \"w\") as f: f.write(f\"Total execution time: {runtime:.2f} seconds\\n\")\n",
    "    \n",
    "print(f\"File saved successfully: {output_path}\")\n",
    "print(f\"Execution time logged in: {runtime_log_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628276fb",
   "metadata": {},
   "source": [
    "### 3.3 Combine SciSpaCy approach with Swifter to speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4365772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two models and swifter\n",
    "EXCLUDE_TERMS = {\"anticancer\",\"anti cancer\", \"anti-cancer\", \"anti-tumor\", \"metastasis\", \"metastases\", \"antitumor\", \"anti tumor\", \"cancerous\", \"non-cancerous\", \"precancerous\", \"cancer-related\"}\n",
    "def clean_term(term):\n",
    "    term = term.lower().strip()\n",
    "    term = unicodedata.normalize(\"NFKC\", term)\n",
    "    term = re.sub(r'[-‐–—]', ' ', term)\n",
    "    return term\n",
    "def extract_cancer_mentions(text):\n",
    "    if pd.isna(text) or text.strip() == \"\": return []\n",
    "    extracted_terms = set()\n",
    "    doc1 = nlp_cancer_1(text)\n",
    "    doc2 = nlp_cancer_2(text)\n",
    "    for ent in doc1.ents + doc2.ents:\n",
    "        term = clean_term(ent.text)\n",
    "        if \"cancer\" in term or \"tumor\" in term: extracted_terms.add(term)\n",
    "    filtered_terms = {term for term in extracted_terms if term not in EXCLUDE_TERMS}\n",
    "    return list(filtered_terms)\n",
    "def apply_cancer_extraction(df):\n",
    "    df[\"Extracted_Cancer_Terms\"] = (df[\"PaperTitle\"].astype(str) + \" \" + df[\"Abstract\"].astype(str)).swifter.apply(extract_cancer_mentions)\n",
    "    return df\n",
    "start_time = time.time()\n",
    "tqdm.pandas()\n",
    "df = full_df.copy()\n",
    "df = apply_cancer_extraction(df)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "output_path = os.path.join(output_directory, \"Extracted_Cancer_Terms.csv\")\n",
    "df.to_csv(output_path, index=False)\n",
    "runtime_log_path = os.path.join(output_directory, \"running_time_cancer_extraction.txt\")\n",
    "with open(runtime_log_path, \"w\") as f: f.write(f\"Total execution time: {runtime:.2f} seconds\\n\")\n",
    "\n",
    "print(f\"File saved successfully: {output_path}\")\n",
    "print(f\"Execution time logged in: {runtime_log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8037b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disease Onotlogy matching\n",
    "API_TIME_PER_TERM = 0.01\n",
    "def get_disease_ontology_name(term):\n",
    "    \"\"\"Queries Disease Ontology API to find the standardized disease name.\"\"\"\n",
    "    url = f\"https://www.ebi.ac.uk/ols/api/search?q={term}&ontology=doid\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        if results[\"response\"][\"numFound\"] > 0:\n",
    "            return results[\"response\"][\"docs\"][0][\"label\"]\n",
    "    return term\n",
    "\n",
    "def standardize_extracted_terms(terms):\n",
    "    \"\"\"Standardizes extracted cancer terms using Disease Ontology with a progress bar.\"\"\"\n",
    "    if not isinstance(terms, list) or len(terms) == 0:\n",
    "        return []\n",
    "    standardized_terms = []\n",
    "    for term in tqdm(terms, desc=\"Standardizing Cancer Terms\", unit=\"term\"):\n",
    "        standardized_name = get_disease_ontology_name(term)\n",
    "        standardized_terms.append(standardized_name)\n",
    "        time.sleep(API_TIME_PER_TERM)\n",
    "    return list(set(standardized_terms)) \n",
    "\n",
    "# Select rows for testing\n",
    "df_test = df.head(1000).copy()\n",
    "\n",
    "total_terms = df_test[\"Extracted_Cancer_Terms\"].explode().dropna().nunique()\n",
    "estimated_time_sec = total_terms * API_TIME_PER_TERM\n",
    "estimated_time_min = estimated_time_sec / 60\n",
    "print(f\"Estimated time required for the test: {estimated_time_sec:.2f} seconds (~{estimated_time_min:.2f} minutes)\")\n",
    "tqdm.pandas()\n",
    "df_test[\"Standardized_Cancer_Terms\"] = df_test[\"Extracted_Cancer_Terms\"].progress_apply(standardize_extracted_terms)\n",
    "\n",
    "df_test.to_csv(os.path.join(output_directory, \"Test_Standardized_Cancer_Terms.csv\"), index=False)\n",
    "print(\"Test run completed! Standardized cancer terms saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
