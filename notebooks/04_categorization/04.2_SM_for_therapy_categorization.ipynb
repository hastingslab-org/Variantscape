{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f95fb2",
   "metadata": {},
   "source": [
    "# SM-based extraction of therapies via CIVIC API\n",
    "- Extract treatments, drugs and therapies from PaperTitles and Abstracts\n",
    "- Connect to CIIVC API and match against the extracted drugs\n",
    "- Create a binary matrix\n",
    "- Create output statistics and figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c191c05",
   "metadata": {},
   "source": [
    "# 1) Set up libraries and datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7fbf24",
   "metadata": {},
   "source": [
    "## 1.1) Import libraries and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d33868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import ast\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "import swifter\n",
    "from fuzzywuzzy import fuzz\n",
    "from rapidfuzz import process\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156ff2e3",
   "metadata": {},
   "source": [
    "## 1.2) Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory and file paths\n",
    "input_directory = \"INPUT_DIRECTORY\"\n",
    "output_directory = \"OUTPUT_DIRECTORY\"\n",
    "gene_matrix = \"filtered_gene_binary_matrix.csv\"\n",
    "full_dataset = \"cleaned_BioBERT_data.csv\"\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the articles file\n",
    "os.chdir(output_directory)\n",
    "print(\"Current Work Directory:\",os.getcwd())\n",
    "full_df = pd.read_csv(full_dataset)\n",
    "print(f\"Length of full test dataset: {len(full_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefc583",
   "metadata": {},
   "source": [
    "## 1.3) Connect to CIVIC API for therapies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724a533",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the GraphQL endpoint\n",
    "url = \"https://civicdb.org/api/graphql\"\n",
    "\n",
    "# Define an empty list to store all therapies\n",
    "all_therapies = []\n",
    "end_cursor = None\n",
    "\n",
    "while True:\n",
    "    # Define the GraphQL query with pagination and therapyAliases\n",
    "    query = f\"\"\"\n",
    "    {{\n",
    "      browseTherapies(first: 100, after: \"{end_cursor if end_cursor else ''}\") {{\n",
    "        edges {{\n",
    "          node {{\n",
    "            id\n",
    "            name\n",
    "            therapyUrl\n",
    "            ncitId\n",
    "            therapyAliases\n",
    "          }}\n",
    "        }}\n",
    "        pageInfo {{\n",
    "          hasNextPage\n",
    "          endCursor\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the request headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "    # Send the POST request\n",
    "    response = requests.post(url, json={'query': query}, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'errors' in data:\n",
    "            print(\"Errors:\", data['errors'])\n",
    "            break\n",
    "\n",
    "        # Extract the therapies data\n",
    "        therapies = [edge['node'] for edge in data['data']['browseTherapies']['edges']]\n",
    "        all_therapies.extend(therapies)\n",
    "\n",
    "        # Get pagination info\n",
    "        page_info = data['data']['browseTherapies']['pageInfo']\n",
    "        \n",
    "        # If there are more pages, update the cursor and continue\n",
    "        if page_info['hasNextPage']:\n",
    "            end_cursor = page_info['endCursor']\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        print(f\"Error: Unable to fetch data (Status Code: {response.status_code})\")\n",
    "        break\n",
    "\n",
    "# Convert to DataFrame\n",
    "CIVIC_therapies = pd.DataFrame(all_therapies)\n",
    "CIVIC_therapies = CIVIC_therapies.sort_values(by=\"name\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Print summary\n",
    "print(f\"Total Therapies in CIViC: {CIVIC_therapies.shape[0]}\")\n",
    "print(CIVIC_therapies.head())\n",
    "print(\"\\nColumns:\", CIVIC_therapies.columns)\n",
    "\n",
    "os.chdir(output_directory)\n",
    "CIVIC_therapies.to_csv(\"CIVIC_therapies_with_aliases.csv\", index=False)\n",
    "print(\"\\nCSV file saved successfully: CIVIC_therapies_with_aliases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dffb72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Investigate therapy dataset\n",
    "# Define the therapy name to search for (case insensitive but exact)\n",
    "therapy_name = \"Trastuzumab\".lower()\n",
    "\n",
    "if \"CIVIC_therapies\" in globals():\n",
    "    CIVIC_therapies = CIVIC_therapies.copy()\n",
    "else:\n",
    "    CIVIC_therapies = pd.read_csv(\"CIVIC_therapies_with_aliases.csv\")\n",
    "filtered_data = CIVIC_therapies[CIVIC_therapies[\"name\"].str.lower() == therapy_name]\n",
    "therapy_aliases_list = filtered_data[\"therapyAliases\"].tolist()\n",
    "\n",
    "print(\"- Therapy-associated aliases and synonyms:\", therapy_aliases_list)\n",
    "\n",
    "######### Search aliases #########\n",
    "# Define alias keyword to search for (case-insensitive exact match)\n",
    "alias_keyword = \"Herceptin\".lower()\n",
    "\n",
    "# Convert therapyAliases to lists if they are stored as strings\n",
    "CIVIC_therapies[\"therapyAliases\"] = CIVIC_therapies[\"therapyAliases\"].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Ensure exact match (case-insensitive, but no partial matching)\n",
    "filtered_data = CIVIC_therapies[\n",
    "    CIVIC_therapies[\"therapyAliases\"].apply(\n",
    "        lambda aliases: any(alias.lower() == alias_keyword for alias in aliases) if isinstance(aliases, list) else False\n",
    "    )\n",
    "]\n",
    "\n",
    "therapy_names_list = filtered_data[\"name\"].tolist()\n",
    "print(\"\\n\\n- Alias-associated therapy:\", therapy_names_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b255ee9b",
   "metadata": {},
   "source": [
    "## Filter out unspecific abbreviation in order to avoid unspecific string matched, e.g., \n",
    "- Treatment \"RT\" (Raditation therapy) with RT-QPCR\n",
    "- \"Lysin\"e with the amino acid lysine\n",
    "- \"Immunological\" with string such as Immunological profiling \n",
    "- Inhibitor, as this can be anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda9e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean based on character length\n",
    "CIVIC_therapies_filtered = CIVIC_therapies.copy()\n",
    "# Set the character limit dynamically\n",
    "char_limit = 4\n",
    "CIVIC_therapies_filtered[\"filteredAliases\"] = CIVIC_therapies_filtered[\"therapyAliases\"].apply(lambda aliases: [alias for alias in aliases if isinstance(alias, str) and len(alias) <= char_limit] if isinstance(aliases, list) else [])\n",
    "short_aliases_df = CIVIC_therapies_filtered[CIVIC_therapies_filtered[\"filteredAliases\"].apply(lambda x: len(x) > 0)].copy()\n",
    "short_aliases_df[\"filteredAliases\"] = short_aliases_df[\"filteredAliases\"].apply(lambda x: ', '.join(x))\n",
    "short_treamtnet_df = pd.concat([short_aliases_df]).drop_duplicates(subset=[\"name\"]).reset_index(drop=True)\n",
    "print(\"\\nFiltered Therapies with Names or Aliases ≤\", char_limit, \"characters:\")\n",
    "print(short_treamtnet_df.head(10)[[\"name\",\"filteredAliases\"]])\n",
    "print(\"Number of short therapies:\", len(short_treamtnet_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3fde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset 'therapyAliases_new' by filtering out aliases ≤ char_limit characters\n",
    "CIVIC_therapies_filtered[\"therapyAliases_new\"] = CIVIC_therapies_filtered[\"therapyAliases\"].apply(lambda aliases: [alias for alias in aliases if isinstance(alias, str) and len(alias) > char_limit] if isinstance(aliases, list) else [])\n",
    "CIVIC_therapies_filtered[\"original_alias_count\"] = CIVIC_therapies_filtered[\"therapyAliases\"].apply(lambda aliases: len(aliases) if isinstance(aliases, list) else 0)\n",
    "CIVIC_therapies_filtered[\"new_alias_count\"] = CIVIC_therapies_filtered[\"therapyAliases_new\"].apply(len)\n",
    "CIVIC_therapies_filtered = CIVIC_therapies_filtered.rename(columns={\"therapyAliases\": \"therapyAliases_old\", \"therapyAliases_new\": \"therapyAliases\"})\n",
    "CIVIC_therapies_filtered.to_csv(\"CIVIC_therapies_filtered.csv\", index=False)\n",
    "print(\"Length of filtered CIVIC treamtment dataset:\", len(CIVIC_therapies_filtered))\n",
    "specific_names = short_treamtnet_df[\"name\"].tolist()\n",
    "CIVIC_therapies_removed = CIVIC_therapies_filtered[CIVIC_therapies_filtered[\"name\"].isin(specific_names)].copy()\n",
    "print(\"Length of removed dataset:\", len(CIVIC_therapies_removed))\n",
    "print(CIVIC_therapies_removed[[\"name\",\"therapyAliases_old\",\"therapyAliases\",\"original_alias_count\",\"new_alias_count\"]])\n",
    "CIVIC_therapies_removed.to_csv(\"check_removed_aliases.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7bcd60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######## Remove further therapies that are noise, e.g., inhibitor, lysine\n",
    "\n",
    "# Define words for removal from the \"name\" column\n",
    "name_removal = [\"lysine\", \"inhibitor\"]\n",
    "\n",
    "number_initial_treatments = len(CIVIC_therapies_filtered)\n",
    "CIVIC_therapies_filtered = CIVIC_therapies_filtered.copy()\n",
    "\n",
    "# Drop rows where \"name\" exactly matches any word in name_removal (case insensitive)\n",
    "rows_before = len(CIVIC_therapies_filtered)\n",
    "CIVIC_therapies_filtered = CIVIC_therapies_filtered[\n",
    "    ~CIVIC_therapies_filtered[\"name\"].str.lower().isin(name_removal)\n",
    "].copy()\n",
    "rows_after = len(CIVIC_therapies_filtered)\n",
    "\n",
    "number_dropped_treatments = rows_before - rows_after\n",
    "number_filtered_treatments = len(CIVIC_therapies_filtered)\n",
    "\n",
    "CIVIC_therapies_filtered.to_csv(\"CIVIC_therapies_filtered.csv\", index=False)\n",
    "\n",
    "print(\"Summary of Filtering Process:\")\n",
    "print(f\"Initial number of treatments: {number_initial_treatments}\")\n",
    "print(f\"Number of dropped treatments: {number_dropped_treatments}\")\n",
    "print(f\"Number of filtered treatments: {number_filtered_treatments}\")\n",
    "\n",
    "# Check if the numbers add up correctly\n",
    "if number_initial_treatments == (number_filtered_treatments + number_dropped_treatments):\n",
    "    print(\"--> The counts add up correctly! (Filtered + Dropped = Initial numberss)\")\n",
    "else:\n",
    "    print(\"--> The counts do NOT add up! There might be an issue in filtering.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96abb8d0",
   "metadata": {},
   "source": [
    "### Add information from NCI Thesaurus API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Add hierachy and information from NCI Thesaurus ####\n",
    "# Base URL for the NCI EVS REST API\n",
    "base_url = 'https://api-evsrest.nci.nih.gov/api/v1'\n",
    "\n",
    "# Function to get concept definitions\n",
    "def get_concept_definitions(concept_code):\n",
    "    url = f'{base_url}/concept/ncit/{concept_code}?include=definitions'\n",
    "    response = requests.get(url, headers={'accept': 'application/json'})\n",
    "    if response.status_code == 200:\n",
    "        return [d.get('definition', 'No Definition Found') for d in response.json().get('definitions', [])]\n",
    "    return []\n",
    "\n",
    "# Function to get concept associations\n",
    "def get_concept_associations(concept_code):\n",
    "    url = f'{base_url}/concept/ncit/{concept_code}/associations'\n",
    "    response = requests.get(url, headers={'accept': 'application/json'})\n",
    "    if response.status_code == 200:\n",
    "        return [\n",
    "            f\"{assoc.get('type', 'Unknown Type')}: {assoc.get('relatedName', 'Unknown Name')} (Code: {assoc.get('relatedCode', 'N/A')})\"\n",
    "            for assoc in response.json()\n",
    "        ]\n",
    "    return []\n",
    "\n",
    "# Function to get inverse associations\n",
    "def get_concept_inverse_associations(concept_code):\n",
    "    url = f'{base_url}/concept/ncit/{concept_code}/inverseAssociations'\n",
    "    response = requests.get(url, headers={'accept': 'application/json'})\n",
    "    if response.status_code == 200:\n",
    "        return [\n",
    "            f\"{inv_assoc.get('type', 'Unknown Type')}: {inv_assoc.get('relatedName', 'Unknown Name')} (Code: {inv_assoc.get('relatedCode', 'N/A')})\"\n",
    "            for inv_assoc in response.json()\n",
    "        ]\n",
    "    return []\n",
    "\n",
    "# Function to recursively get parent concepts until a duplicate is found\n",
    "def get_parent_hierarchy(concept_code):\n",
    "    hierarchy = []\n",
    "    seen_codes = set()\n",
    "    \n",
    "    while concept_code:\n",
    "        if concept_code in seen_codes:  # Stop if a duplicate parent is found\n",
    "            break\n",
    "        seen_codes.add(concept_code)\n",
    "        \n",
    "        url = f'{base_url}/concept/ncit/{concept_code}/parents'\n",
    "        response = requests.get(url, headers={'accept': 'application/json'})\n",
    "        if response.status_code == 200:\n",
    "            parents = response.json()\n",
    "            if not parents:\n",
    "                break\n",
    "            parent = parents[0]  # Take the first parent only\n",
    "            hierarchy.append((parent.get('code'), parent.get('name')))\n",
    "            concept_code = parent.get('code')  # Move to next parent\n",
    "        else:\n",
    "            break\n",
    "    return hierarchy\n",
    "\n",
    "# Set output directory and file names\n",
    "output_directory = os.getcwd()  # Uses the current working directory\n",
    "input_filepath = os.path.join(output_directory, \"CIVIC_therapies_filtered.csv\")\n",
    "output_filepath = os.path.join(output_directory, \"CIVIC_therapies_with_NCIT_information.csv\")\n",
    "\n",
    "# Read input CSV\n",
    "CIVIC_ncit_df = pd.read_csv(input_filepath)\n",
    "CIVIC_ncit_df_processed = CIVIC_ncit_df.copy()\n",
    "ncit_data = []\n",
    "\n",
    "for _, row in tqdm(CIVIC_ncit_df.iterrows(), total=len(CIVIC_ncit_df), desc=\"Processing Rows\", unit=\"row\"):\n",
    "    concept_code = str(row['ncitId']).strip()\n",
    "    \n",
    "    if not concept_code:  # Skip if ncitId is empty\n",
    "        continue\n",
    "    definitions = get_concept_definitions(concept_code)\n",
    "    associations = get_concept_associations(concept_code)\n",
    "    inverse_associations = get_concept_inverse_associations(concept_code)\n",
    "    parent_hierarchy = get_parent_hierarchy(concept_code)\n",
    "    parent_dict = {f'parent_{i+1}': parent_hierarchy[i][1] for i in range(len(parent_hierarchy))}\n",
    "    data = {\n",
    "        \"ncitId\": concept_code,\n",
    "        \"definitions\": \" | \".join(definitions),\n",
    "        \"associations\": \" | \".join(associations),\n",
    "        \"inverse_associations\": \" | \".join(inverse_associations),\n",
    "    }\n",
    "    data.update(parent_dict)  # Add parent hierarchy to the data\n",
    "    ncit_data.append(data)\n",
    "\n",
    "ncit_df = pd.DataFrame(ncit_data)\n",
    "CIVIC_ncit_df_processed = CIVIC_ncit_df_processed.merge(ncit_df, on=\"ncitId\", how=\"left\")\n",
    "CIVIC_ncit_df_processed.to_csv(output_filepath, index=False)\n",
    "len_CIVIC_ncit_df_processed=len(CIVIC_ncit_df_processed)\n",
    "\n",
    "print(f\"\\nData saved successfully to: {output_filepath}\")\n",
    "print(\"Length of dataset:\",len_CIVIC_ncit_df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d439bf2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Defining the final parent ###\n",
    "\n",
    "# Check if CIVIC_ncit_df_processed exists in memory\n",
    "if \"CIVIC_ncit_df_processed\" in globals():\n",
    "    CIVIC_ncit_df_finalparent = CIVIC_ncit_df_processed.copy()\n",
    "    print(\"Using existing dataset in memory.\")\n",
    "else:\n",
    "    output_filepath = os.path.join(output_directory, \"CIVIC_therapies_with_NCIT_information.csv\")\n",
    "    CIVIC_ncit_df_finalparent = pd.read_csv(output_filepath)\n",
    "    print(\"Loaded from CSV.\")\n",
    "\n",
    "# Print available columns\n",
    "print(\"Available columns:\", CIVIC_ncit_df_finalparent.columns.tolist())\n",
    "\n",
    "# Identify parent columns dynamically\n",
    "parent_columns = [col for col in CIVIC_ncit_df_finalparent.columns if col.startswith(\"parent_\")]\n",
    "parent_columns.sort(key=lambda x: int(x.split(\"_\")[1]))  # Sort numerically (parent_1, parent_2, etc.)\n",
    "\n",
    "# Define restricted values (exact matches)\n",
    "restricted_parents = {\n",
    "    \"Drug, Food, Chemical or Biomedical Material\",\n",
    "    \"Pharmacologic Substance\",\n",
    "    \"Drug or Chemical by Structure\",\n",
    "    \"Organic Chemical\",\n",
    "    \"Therapeutic Procedure\",\n",
    "    \"Clinical Intervention or Procedure\",\n",
    "    \"Clinical or Research Activity\",\n",
    "    \"Activity\",\n",
    "    \"Antineoplastic Agent\",\n",
    "    \"Cancer Diagnostic or Therapeutic Procedure\",\n",
    "    \"Cancer Therapeutic Procedure\",\n",
    "    \"Infusion Procedure\",\n",
    "    \"Adjuvant Therapy\"\n",
    "}\n",
    "\n",
    "# Function to determine the final parent\n",
    "def get_final_parent(row):\n",
    "    valid_parents = [row[col] for col in reversed(parent_columns) if pd.notna(row[col])]  # Start from the rightmost column (parent_n)\n",
    "\n",
    "    for parent in valid_parents:\n",
    "        # Check if the parent is in the restricted set OR starts with \"Retired Concept\"\n",
    "        if parent not in restricted_parents and not parent.startswith(\"Retired Concept\"):\n",
    "            return parent\n",
    "    return None \n",
    "CIVIC_ncit_df_finalparent[\"final_parent\"] = CIVIC_ncit_df_finalparent.apply(get_final_parent, axis=1)\n",
    "final_output_filepath = os.path.join(output_directory, \"CIVIC_ncit_df_finalparent.csv\")\n",
    "CIVIC_ncit_df_finalparent.to_csv(final_output_filepath, index=False)\n",
    "print(\"\\nUpdated dataset with 'final_parent' column saved to:\", final_output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a96bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Defining the final parent ###\n",
    "# Check if CIVIC_ncit_df_processed exists in memory\n",
    "if \"CIVIC_ncit_df_processed\" in globals():\n",
    "    CIVIC_ncit_df_finalparent = CIVIC_ncit_df_processed.copy()\n",
    "    print(\"Using existing dataset in memory.\")\n",
    "else:\n",
    "    output_filepath = os.path.join(output_directory, \"CIVIC_therapies_with_NCIT_information.csv\")\n",
    "    CIVIC_ncit_df_finalparent = pd.read_csv(output_filepath)\n",
    "    print(\"Loaded from CSV.\")\n",
    "\n",
    "# Print available columns\n",
    "print(\"Available columns:\", CIVIC_ncit_df_finalparent.columns.tolist())\n",
    "\n",
    "# Identify parent columns dynamically\n",
    "parent_columns = [col for col in CIVIC_ncit_df_finalparent.columns if col.startswith(\"parent_\")]\n",
    "parent_columns.sort(key=lambda x: int(x.split(\"_\")[1]))  # Sort numerically (parent_1, parent_2, etc.)\n",
    "\n",
    "# Define restricted values (exact matches)\n",
    "restricted_parents = {\n",
    "    \"Drug, Food, Chemical or Biomedical Material\",\n",
    "    \"Pharmacologic Substance\",\n",
    "    \"Drug or Chemical by Structure\",\n",
    "    \"Organic Chemical\",\n",
    "    \"Therapeutic Procedure\",\n",
    "    \"Clinical Intervention or Procedure\",\n",
    "    \"Clinical or Research Activity\",\n",
    "    \"Activity\",\n",
    "    \"Antineoplastic Agent\",\n",
    "    \"Cancer Diagnostic or Therapeutic Procedure\",\n",
    "    \"Cancer Therapeutic Procedure\",\n",
    "    \"Infusion Procedure\",\n",
    "    \"Adjuvant Therapy\",\n",
    "    \"Preventive Intervention\",\n",
    "    \"Local Therapy\",\n",
    "    \"Cancer Prevention\"\n",
    "}\n",
    "\n",
    "# Function to determine the final parent\n",
    "def get_final_parent(row):\n",
    "    valid_parents = [row[col] for col in reversed(parent_columns) if pd.notna(row[col])]\n",
    "\n",
    "    for parent in valid_parents:\n",
    "        # Check if the parent is in the restricted set OR starts with \"Retired Concept\"\n",
    "        if parent not in restricted_parents and not parent.startswith(\"Retired Concept\"):\n",
    "            return parent\n",
    "\n",
    "    # If all parents are restricted or missing, use the \"name\" column as the final parent\n",
    "    return row[\"name\"] if pd.notna(row[\"name\"]) else None\n",
    "\n",
    "# Apply function to determine \"final_parent\"\n",
    "CIVIC_ncit_df_finalparent[\"final_parent\"] = CIVIC_ncit_df_finalparent.apply(get_final_parent, axis=1)\n",
    "\n",
    "# Save updated DataFrame to CSV\n",
    "final_output_filepath = os.path.join(output_directory, \"CIVIC_ncit_df_finalparent.csv\")\n",
    "CIVIC_ncit_df_finalparent.to_csv(final_output_filepath, index=False)\n",
    "\n",
    "# Print confirmation message\n",
    "print(\"\\nUpdated dataset with 'final_parent' column saved to:\", final_output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea428d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_output_filepath = os.path.join(output_directory, \"CIVIC_ncit_df_finalparent.csv\")\n",
    "CIVIC_ncit_df_finalparent = pd.read_csv(final_output_filepath)\n",
    "total_rows = len(CIVIC_ncit_df_finalparent)i\n",
    "\n",
    "# Count statistics\n",
    "empty_final_parent_count = CIVIC_ncit_df_finalparent[\"final_parent\"].isna().sum()\n",
    "empty_final_parent_percentage = (empty_final_parent_count / total_rows) * 100\n",
    "non_empty_final_parent_count = total_rows - empty_final_parent_count\n",
    "non_empty_final_parent_percentage = (non_empty_final_parent_count / total_rows) * 100\n",
    "final_parent_counts = CIVIC_ncit_df_finalparent[\"final_parent\"].value_counts()\n",
    "\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "print(f\"Empty 'final_parent' count: {empty_final_parent_count} ({empty_final_parent_percentage:.2f}%)\")\n",
    "print(f\"Non-empty 'final_parent' count: {non_empty_final_parent_count} ({non_empty_final_parent_percentage:.2f}%)\\n\")\n",
    "print(\"Final Parent Counts:\")\n",
    "print(final_parent_counts.iloc[1:50])\n",
    "\n",
    "# Convert final parent counts to a DataFrame\n",
    "final_parent_counts_df = final_parent_counts.reset_index()\n",
    "final_parent_counts_df.columns = [\"final_parent\", \"count\"]\n",
    "CIVIC_ncit_df_finalparent[\"final_parent_count\"] = CIVIC_ncit_df_finalparent[\"final_parent\"].map(final_parent_counts)\n",
    "final_output_filepath = os.path.join(output_directory, \"CIVIC_ncit_df_finalparent_updated.csv\")\n",
    "CIVIC_ncit_df_finalparent.to_csv(final_output_filepath, index=False)\n",
    "num_distinct_final_parents = CIVIC_ncit_df_finalparent[\"final_parent\"].nunique()\n",
    "print(f\"Number of distinct final parents: {num_distinct_final_parents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d6d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### Treatment parent categorization\n",
    "CIVIC_ncit_df_finalparent_treatmentcategory = CIVIC_ncit_df_finalparent.copy()\n",
    "\n",
    "# Define treatment category mapping (case-sensitive)\n",
    "treatment_mapping = {\n",
    "    \"Chemotherapy\": {\"Chemotherapy\", \"Cytotoxic Chemotherapeutic Agent\", \"Adjuvant Chemotherapy\",\n",
    "                     \"Hydrocarbon\", \"Hyperthermic Intraperitoneal Chemotherapy\",\"Chemotherapy Regimen or Agent Combination\"},\n",
    "    \"Targeted therapy\": {\"Targeted Therapy Agent\", \"Signal Transduction Inhibitor\", \"FGF/VEGF Receptor Tyrosine Kinase Inhibitor, PD173074\",\n",
    "                         \"Enzyme Inhibitor\", \"Angiogenesis Inhibitor\", \"VEGF/VEGFR Inhibitors\",\"Apoptotic Pathway-targeting Antineoplastic Agent\"},\n",
    "    \"Biological\": {\"Antineoplastic Biological Agent\", \"Biological Therapy\",\"Biological Agent\"},\n",
    "    \"Hormone therapy\": {\"Hormone Therapy Agent\", \"Antineoplastic Hormonal/Endocrine Agent\", \"Hormone Therapy\"},\n",
    "    \"Immunotherapy\": {\"Immunotherapeutic Agent\", \"Antineoplastic Immunomodulating Agent\"},\n",
    "    \"Anti-infective therapy\": {\"Anti-Infective Agent\"},\n",
    "    \"Agent Affecting Nervous System\": {\"Agent Affecting Nervous System\"},\n",
    "    \"Radiation therapy\": {\"Radiation Therapy\",\"Radiation Ionizing Radiotherapy\"}\n",
    "}\n",
    "\n",
    "# Function to categorize treatments based on \"final_parent\"\n",
    "def categorize_treatment(final_parent):\n",
    "    if pd.isna(final_parent):\n",
    "        return \"Other therapy\"\n",
    "    for category, parent_values in treatment_mapping.items():\n",
    "        if final_parent in parent_values:\n",
    "            return category\n",
    "    return \"Other therapy\" \n",
    "\n",
    "CIVIC_ncit_df_finalparent_treatmentcategory[\"parent_treatment_category\"] = CIVIC_ncit_df_finalparent_treatmentcategory[\"final_parent\"].apply(categorize_treatment)\n",
    "output_filepath = os.path.join(output_directory, \"CIVIC_ncit_df_finalparent_treatmentcategory.csv\")\n",
    "CIVIC_ncit_df_finalparent_treatmentcategory.to_csv(output_filepath, index=False)\n",
    "print(f\"\\nUpdated dataset with 'parent_treatment_category' column saved to: {output_filepath}\")\n",
    "treatment_category_counts = CIVIC_ncit_df_finalparent_treatmentcategory[\"parent_treatment_category\"].value_counts()\n",
    "treatment_category_counts_df = treatment_category_counts.reset_index()\n",
    "treatment_category_counts_df.columns = [\"Treatment Category\", \"Count\"]\n",
    "\n",
    "print(\"\\n=== Summary of Treatment Category Counts ===\")\n",
    "print(treatment_category_counts_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320dc8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart\n",
    "final_output_filepath = os.path.join(output_directory, \"CIVIC_ncit_df_finalparent_treatmentcategory.csv\")\n",
    "CIVIC_ncit_df_finalparent_treatmentcategory = pd.read_csv(final_output_filepath)\n",
    "treatment_category_counts = CIVIC_ncit_df_finalparent_treatmentcategory[\"parent_treatment_category\"].value_counts()\n",
    "treatment_category_counts_df = treatment_category_counts.reset_index()\n",
    "treatment_category_counts_df.columns = [\"Treatment Category\", \"Count\"]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(treatment_category_counts_df[\"Treatment Category\"], treatment_category_counts_df[\"Count\"], color=\"skyblue\")\n",
    "plt.xlabel(\"Treatment parent category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of CIVIC treatment parent categories\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79beee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique occurrences of \"final_parent\" within \"Other therapy\" category\n",
    "other_therapy_counts = (\n",
    "    CIVIC_ncit_df_finalparent_treatmentcategory[\n",
    "        CIVIC_ncit_df_finalparent_treatmentcategory[\"parent_treatment_category\"] == \"Other therapy\"\n",
    "    ][\"final_parent\"]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "other_therapy_counts.columns = [\"final_parent\", \"Count\"]\n",
    "other_therapy_counts = other_therapy_counts.sort_values(by=\"Count\", ascending=False)\n",
    "total_other_therapy_count = other_therapy_counts[\"Count\"].sum()\n",
    "print(\"\\n=== Unique 'final_parent' Values for 'Other therapy' (Sorted by Frequency) ===\")\n",
    "print(other_therapy_counts.to_string(index=False))\n",
    "print(f\"\\nTotal occurrences of 'Other therapy' final parents: {total_other_therapy_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Define the final parent to investigate\n",
    "\n",
    "final_parent = \"Agent Targeting Cancer Metabolism\"\n",
    "final_output_filepath = os.path.join(output_directory, \"CIVIC_ncit_df_finalparent.csv\")\n",
    "CIVIC_ncit_df_finalparent = pd.read_csv(final_output_filepath)\n",
    "filtered_df = CIVIC_ncit_df_finalparent[CIVIC_ncit_df_finalparent[\"final_parent\"] == final_parent]\n",
    "if filtered_df.empty:\n",
    "    print(f\"No entries found for final parent: {final_parent}\")\n",
    "else:\n",
    "    name_list = filtered_df[\"name\"].dropna().tolist()\n",
    "    print(f\"\\nEntries for final parent '{final_parent}':\")\n",
    "    for name in name_list:\n",
    "        print(\"-\", name)\n",
    "\n",
    "print(CIVIC_ncit_df_finalparent_treatmentcategory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1efab7",
   "metadata": {},
   "source": [
    "## ====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6dbc60",
   "metadata": {},
   "source": [
    "# String matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96125ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "treatment_mapping_df = full_df.copy()\n",
    "print(f\"Total number of rows of dataset to process: {len(treatment_mapping_df):,}\")\n",
    "\n",
    "# Ensure CIVIC_therapies dataset is loaded\n",
    "if \"CIVIC_therapies_filtered\" in globals():\n",
    "    CIVIC_therapies_filtered = CIVIC_therapies_filtered.copy()\n",
    "    print(\"CIVIC_therapies_filtered loaded from globals\")\n",
    "else:\n",
    "    CIVIC_therapies_filtered = pd.read_csv(\"CIVIC_therapies_filtered.csv\")\n",
    "    print(\"CIVIC_therapies loaded from files\")\n",
    "print(f\"Total number of CIVIC therapies: {len(CIVIC_therapies_filtered):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30327d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping cancer therapy names and aliases onto scientific papers to detect mentions\n",
    "# then summarizing how often therapies are found in the papers\n",
    "\n",
    "start_time = time.time()\n",
    "CIVIC_therapies_filtered[\"therapyAliases\"] = CIVIC_therapies_filtered[\"therapyAliases\"].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "treatment_mapping_df[\"PaperTitle\"] = treatment_mapping_df[\"PaperTitle\"].astype(str).str.lower()\n",
    "treatment_mapping_df[\"Abstract\"] = treatment_mapping_df[\"Abstract\"].astype(str).str.lower()\n",
    "def find_matched_treatments(text, therapy_name, aliases):\n",
    "    matches = []\n",
    "    therapy_pattern = re.compile(rf\"\\b{re.escape(therapy_name.lower())}\\b\", re.IGNORECASE)\n",
    "    alias_patterns = {alias: re.compile(rf\"\\b{re.escape(alias.lower())}\\b\", re.IGNORECASE) for alias in aliases}\n",
    "    if therapy_pattern.search(text): matches.append(therapy_name)\n",
    "    for alias, pattern in alias_patterns.items():\n",
    "        if pattern.search(text): matches.append(alias)\n",
    "    return matches if matches else None\n",
    "\n",
    "original_columns = set(treatment_mapping_df.columns)\n",
    "new_columns_dict = {}\n",
    "treatment_matches_list = []\n",
    "for index, row in tqdm(CIVIC_therapies_filtered.iterrows(), total=len(CIVIC_therapies_filtered), desc=\"Processing Therapies\"):\n",
    "    therapy_name = row[\"name\"]\n",
    "    aliases = row[\"therapyAliases\"] if isinstance(row[\"therapyAliases\"], list) else []\n",
    "    matches = treatment_mapping_df.apply(lambda x: find_matched_treatments(x[\"PaperTitle\"] + \" \" + x[\"Abstract\"], therapy_name, aliases), axis=1)\n",
    "    new_columns_dict[therapy_name] = matches.apply(lambda x: 1 if x else 0)\n",
    "    treatment_matches_list.append(matches)\n",
    "    \n",
    "new_columns_df = pd.DataFrame(new_columns_dict)\n",
    "treatment_mapping_df = pd.concat([treatment_mapping_df, new_columns_df], axis=1)\n",
    "treatment_mapping_df[\"Treatment_matches\"] = pd.concat(treatment_matches_list, axis=1).apply(lambda row: [match for match in row if match is not None], axis=1)\n",
    "treatment_mapping_df[\"Treatment_matches\"] = treatment_mapping_df[\"Treatment_matches\"].apply(lambda x: x if len(x) > 0 else None)\n",
    "start_index = treatment_mapping_df.columns.get_loc(\"Sum_Gene_Mentions\") + 1 if \"Sum_Gene_Mentions\" in treatment_mapping_df.columns else len(original_columns)\n",
    "end_index = treatment_mapping_df.columns.get_loc(\"Treatment_matches\")\n",
    "therapy_columns = treatment_mapping_df.iloc[:, start_index:end_index].select_dtypes(include=['number']).columns\n",
    "treatment_mapping_df[\"Sum_treatments\"] = treatment_mapping_df[therapy_columns].sum(axis=1)\n",
    "output_file_path = os.path.join(output_directory, \"treatment_mapping_with_matches.csv\")\n",
    "treatment_mapping_df.to_csv(output_file_path, index=False)\n",
    "print(f\"File successfully saved at: {output_file_path}\")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "runtime_log_path = os.path.join(output_directory, \"running_time_treatment_mapping.txt\")\n",
    "with open(runtime_log_path, \"w\") as f: f.write(f\"Total execution time: {total_time:.2f} seconds\\n\")\n",
    "num_zero_treatments = (treatment_mapping_df[\"Sum_treatments\"] == 0).sum()\n",
    "num_nonzero_treatments = (treatment_mapping_df[\"Sum_treatments\"] >= 1).sum()\n",
    "\n",
    "print(\"\\n===== Summary =====\")\n",
    "print(f\"Rows with Sum_treatments == 0: {num_zero_treatments:,}\")\n",
    "print(f\"Rows with Sum_treatments >= 1: {num_nonzero_treatments:,}\")\n",
    "print(f\"Total sums: {(num_zero_treatments + num_nonzero_treatments):,}\")\n",
    "print(f\"Len of dataset: {len(treatment_mapping_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82dafe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of results\n",
    "num_zero_treatments = (treatment_mapping_df[\"Sum_treatments\"] == 0).sum()\n",
    "num_nonzero_treatments = (treatment_mapping_df[\"Sum_treatments\"] >= 1).sum()\n",
    "\n",
    "print(\"\\n===== Summary =====\")\n",
    "print(f\"Rows with Sum_treatments == 0: {num_zero_treatments:,}\")\n",
    "print(f\"Rows with Sum_treatments >= 1: {num_nonzero_treatments:,}\")\n",
    "print(f\"Total sums: {(num_zero_treatments + num_nonzero_treatments):,}\")\n",
    "print(f\"Len of dataset: {len(treatment_mapping_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4fce0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Create the summary string\n",
    "# Calculate percentages\n",
    "total_rows=len(treatment_mapping_df)\n",
    "zero_treatment_percentage = (num_zero_treatments / total_rows) * 100\n",
    "nonzero_treatment_percentage = (num_nonzero_treatments / total_rows) * 100\n",
    "\n",
    "# Create the summary string\n",
    "summary = (\n",
    "    \"\\n===== Summary =====\\n\"\n",
    "    f\"Rows with Sum_treatments == 0, i.e., no treatments: {num_zero_treatments:,} ({zero_treatment_percentage:.2f}%)\\n\"\n",
    "    f\"Rows with Sum_treatments >= 1, i.e., detected treatments: {num_nonzero_treatments:,} ({nonzero_treatment_percentage:.2f}%)\\n\"\n",
    "    f\"Total sums: {num_zero_treatments + num_nonzero_treatments:,}\\n\"\n",
    "    f\"Len of dataset: {total_rows:,}\\n\"\n",
    ")\n",
    "filename_therapy_categorization = \"summary_runtime_therapy_categorization.txt\"\n",
    "with open(filename_therapy_categorization, \"w\") as file:\n",
    "    file.write(summary)\n",
    "with open(filename_therapy_categorization, \"r\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a28b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_mapping = \"treatment_mapping_with_matches.csv\"\n",
    "treatment_mapping_df = pd.read_csv(treatment_mapping)\n",
    "# Filter rows where Sum_treatments >= 1\n",
    "filtered_treatment_mapping_df = treatment_mapping_df[treatment_mapping_df[\"Sum_treatments\"] >= 1]\n",
    "# Count non-zero treatments\n",
    "num_nonzero_treatments = len(filtered_treatment_mapping_df)\n",
    "print(f\"\\nNumber of rows where 'Sum_treatments' >= 1: {num_nonzero_treatments:,}\")\n",
    "\n",
    "print(filtered_treatment_mapping_df[[\"PaperId\",\"PaperTitle\", \"Abstract\", \"Cisplatin\", \"Sum_treatments\", \"Treatment_matches\"]])\n",
    "\n",
    "filtered_csv_name = \"filtered_treatment_mapping_with_matches.csv\"\n",
    "filtered_treatment_mapping_df.to_csv(filtered_csv_name, index=False)\n",
    "print(f\"\\nFiltered DataFrame saved as '{filtered_csv_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd045fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNumber of articles in the initial dataset: {:,}\".format(len(full_df)))\n",
    "print(\"Number of columns of initial dataset: {:,}\".format(len(full_df.columns)))\n",
    "columns_list = full_df.columns.tolist()\n",
    "print(columns_list)\n",
    "\n",
    "print(\"\\nNumber of articles in the mapped dataset:{:,}\".format(len(treatment_mapping_df)))\n",
    "print(\"Number of columns of mapped dataset:{:,}\".format(len(treatment_mapping_df.columns)))\n",
    "columns_list_mapped = treatment_mapping_df.columns.tolist()\n",
    "print(columns_list_mapped)\n",
    "\n",
    "#### Total treatments\n",
    "total_treatments=len(treatment_mapping_df.columns)-len(full_df.columns)-2 #Treatment_matches', 'Sum_treatments'\n",
    "# Calculate treatments with at least 1 match!!\n",
    "total_treatments = list(set(treatment_mapping_df.columns) - set(full_df.columns))\n",
    "valid_treatment_cols = [col for col in total_treatments if col in treatment_mapping_df.columns and treatment_mapping_df[col].dtype in [int, float]]\n",
    "valid_treatments = sum(treatment_mapping_df[valid_treatment_cols].sum() >= 1)\n",
    "\n",
    "print(f\"\\nNumber of treatment columns with at least a sum of 1: {valid_treatments:,}\")\n",
    "print(\"\\nNumber of total treatments from CIVIC\", total_treatments) #Removed Lysine etc.\n",
    "print(\"Total number of treaments in CIVIC database: 565\")\n",
    "print(\"total number of treatments in publications (at least one match):\",valid_treatments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ed479",
   "metadata": {},
   "source": [
    "## Figure creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eeafd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Summarize and export the top 30 most mentioned treatments\n",
    "if \"Sum_Gene_Mentions\" in treatment_mapping_df.columns:\n",
    "    start_index = treatment_mapping_df.columns.get_loc(\"Sum_Gene_Mentions\") + 1\n",
    "else:\n",
    "    start_index = 0\n",
    "end_index = treatment_mapping_df.columns.get_loc(\"Treatment_matches\")\n",
    "treatment_counts = treatment_mapping_df.iloc[:, start_index:end_index].sum().sort_values(ascending=False)\n",
    "top_30_treatments = treatment_counts.head(30)\n",
    "total_treatment_mentions = treatment_counts.sum()\n",
    "treatment_summary = pd.DataFrame({\"Treatment\": top_30_treatments.index, \"Count\": top_30_treatments.values, \"Percentage\": (top_30_treatments.values / total_treatment_mentions * 100).round(2)})\n",
    "print(\"\\nTop 30 most mentioned treatments:\")\n",
    "print(treatment_summary.to_string(index=False, justify='left'))\n",
    "treatment_summary.to_csv(f\"{output_directory}/Top_30_treatments_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976070a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the top 30 most mentioned treatments as a bar chart\n",
    "if \"Sum_Gene_Mentions\" in treatment_mapping_df.columns:\n",
    "    start_index = treatment_mapping_df.columns.get_loc(\"Sum_Gene_Mentions\") + 1\n",
    "else:\n",
    "    start_index = 0\n",
    "end_index = treatment_mapping_df.columns.get_loc(\"Treatment_matches\")\n",
    "treatment_counts = treatment_mapping_df.iloc[:, start_index:end_index].sum().sort_values(ascending=False)\n",
    "top_20_treatments = treatment_counts.head(30)\n",
    "colors = plt.cm.Blues(np.linspace(1, 0.5, len(top_20_treatments)))\n",
    "formatted_labels = [name.capitalize() for name in top_20_treatments.index]\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(formatted_labels, top_20_treatments.values, color=colors, edgecolor='black')\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel(\"Treatment name\", fontsize=12)\n",
    "plt.ylabel(\"Number of mentions\", fontsize=12)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f\"{int(x):,}\"))\n",
    "total_rows = len(treatment_mapping_df)\n",
    "plt.title(f\"Top 30 most mentioned treatments in {num_nonzero_treatments:,} publications\", fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a19e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize mentions per parent treatment category\n",
    "metadata_columns = [\"PaperTitle\", \"Abstract\", \"Sum_treatments\", \"Treatment_matches\"]\n",
    "therapy_columns = [col for col in treatment_mapping_df.columns if col not in metadata_columns]\n",
    "treatment_to_parent_mapping = CIVIC_ncit_df_finalparent_treatmentcategory.set_index(\"name\")[\"parent_treatment_category\"].to_dict()\n",
    "parent_counts = {}\n",
    "for treatment in therapy_columns:\n",
    "    if treatment in treatment_to_parent_mapping:\n",
    "        parent_category = treatment_to_parent_mapping[treatment]\n",
    "        treatment_sum = treatment_mapping_df[treatment].sum()\n",
    "        if parent_category in parent_counts:\n",
    "            parent_counts[parent_category] += treatment_sum\n",
    "        else:\n",
    "            parent_counts[parent_category] = treatment_sum\n",
    "            \n",
    "parent_counts_df = pd.DataFrame(list(parent_counts.items()), columns=[\"Parent Category\", \"Total Mentions\"])\n",
    "total_mentions = parent_counts_df[\"Total Mentions\"].sum()\n",
    "parent_counts_df[\"Percentage\"] = (parent_counts_df[\"Total Mentions\"] / total_mentions * 100).round(2)\n",
    "parent_counts_df = parent_counts_df.sort_values(by=\"Total Mentions\", ascending=False)\n",
    "\n",
    "print(\"\\nTotal mentions per parent treatment category:\")\n",
    "print(parent_counts_df.to_string(index=False, justify='left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fa5980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total mentions per parent treatment category\n",
    "metadata_columns = [\"PaperTitle\", \"Abstract\", \"Sum_treatments\", \"Treatment_matches\"]\n",
    "therapy_columns = [col for col in treatment_mapping_df.columns if col not in metadata_columns]\n",
    "treatment_to_parent_mapping = CIVIC_ncit_df_finalparent_treatmentcategory.set_index(\"name\")[\"parent_treatment_category\"].to_dict()\n",
    "parent_counts = {}\n",
    "for treatment in therapy_columns:\n",
    "    if treatment in treatment_to_parent_mapping:\n",
    "        parent_category = treatment_to_parent_mapping[treatment]\n",
    "        treatment_sum = treatment_mapping_df[treatment].sum()\n",
    "        parent_counts[parent_category] = parent_counts.get(parent_category, 0) + treatment_sum\n",
    "        \n",
    "parent_counts_df = pd.DataFrame(list(parent_counts.items()), columns=[\"Parent Category\", \"Total Mentions\"]).sort_values(by=\"Total Mentions\", ascending=False)\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = plt.cm.Blues(np.linspace(1, 0.5, len(parent_counts_df)))\n",
    "bars = plt.bar(parent_counts_df[\"Parent Category\"], parent_counts_df[\"Total Mentions\"], color=colors, edgecolor=\"black\")\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel(\"Parent treatment category\", fontsize=12)\n",
    "plt.ylabel(\"Number of mentions\", fontsize=12)\n",
    "plt.title(\"Total mentions per parent treatment category\", fontsize=14)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f\"{int(x):,}\"))\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20d0bf6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot top 20 most mentioned final parent treatment categories\n",
    "treatment_mapping_df = pd.read_csv(\"treatment_mapping_with_matches.csv\")\n",
    "CIVIC_ncit_df_finalparent_treatmentcategory = pd.read_csv(\"CIVIC_ncit_df_finalparent_treatmentcategory.csv\")\n",
    "metadata_columns = [\"PaperTitle\", \"Abstract\", \"Sum_treatments\", \"Treatment_matches\"]\n",
    "therapy_columns = [col for col in treatment_mapping_df.columns if col not in metadata_columns]\n",
    "treatment_to_finalparent_mapping = CIVIC_ncit_df_finalparent_treatmentcategory.set_index(\"name\")[\"final_parent\"].to_dict()\n",
    "final_parent_counts = {}\n",
    "for treatment in therapy_columns:\n",
    "    if treatment in treatment_to_finalparent_mapping:\n",
    "        final_parent_category = treatment_to_finalparent_mapping[treatment]\n",
    "        treatment_sum = treatment_mapping_df[treatment].sum()\n",
    "        final_parent_counts[final_parent_category] = final_parent_counts.get(final_parent_category, 0) + treatment_sum\n",
    "\n",
    "        final_parent_counts_df = pd.DataFrame(list(final_parent_counts.items()), columns=[\"Final Parent Category\", \"Total Mentions\"]).sort_values(by=\"Total Mentions\", ascending=False).head(20)\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = plt.cm.Greens(np.linspace(1, 0.5, len(final_parent_counts_df)))\n",
    "bars = plt.bar(final_parent_counts_df[\"Final Parent Category\"], final_parent_counts_df[\"Total Mentions\"], color=colors, edgecolor=\"black\")\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel(\"Final Parent Category\", fontsize=12)\n",
    "plt.ylabel(\"Number of mentions\", fontsize=12)\n",
    "plt.title(\"Top 20 most mentioned parents\", fontsize=14)\n",
    "plt.gca().yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f\"{int(x):,}\"))\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113bc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sunburst chart for parent and final parent treatment categories\n",
    "metadata_columns = [\"PaperTitle\", \"Abstract\", \"Sum_treatments\", \"Treatment_matches\"]\n",
    "therapy_columns = [col for col in treatment_mapping_df.columns if col not in metadata_columns]\n",
    "treatment_mapping_df[therapy_columns] = treatment_mapping_df[therapy_columns].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "treatment_to_parent_mapping = CIVIC_ncit_df_finalparent_treatmentcategory.set_index(\"name\")[\"parent_treatment_category\"].to_dict()\n",
    "treatment_to_finalparent_mapping = CIVIC_ncit_df_finalparent_treatmentcategory.set_index(\"name\")[\"final_parent\"].to_dict()\n",
    "hierarchy_data = []\n",
    "for treatment in therapy_columns:\n",
    "    treatment_sum = treatment_mapping_df[treatment].sum()\n",
    "    if treatment in treatment_to_parent_mapping and treatment in treatment_to_finalparent_mapping:\n",
    "        hierarchy_data.append([treatment_to_parent_mapping[treatment], treatment_to_finalparent_mapping[treatment], treatment_sum])\n",
    "\n",
    "        hierarchy_df = pd.DataFrame(hierarchy_data, columns=[\"Parent Category\", \"Final Parent Category\", \"Total Mentions\"])\n",
    "hierarchy_df[\"Parent Category\"] = hierarchy_df[\"Parent Category\"].astype(str)\n",
    "hierarchy_df[\"Final Parent Category\"] = hierarchy_df[\"Final Parent Category\"].astype(str)\n",
    "hierarchy_df = hierarchy_df.groupby([\"Parent Category\", \"Final Parent Category\"]).sum().reset_index()\n",
    "fig = px.sunburst(hierarchy_df, path=[\"Parent Category\", \"Final Parent Category\"], values=\"Total Mentions\", color=\"Parent Category\", title=\"Hierarchy of Treatment Categories and Final Parent Categories\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b5171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sunburst chart for parent and final parent treatment categories with mention counts\n",
    "metadata_columns = [\"PaperTitle\", \"Abstract\", \"Sum_treatments\", \"Treatment_matches\"]\n",
    "therapy_columns = [col for col in treatment_mapping_df.columns if col not in metadata_columns]\n",
    "treatment_mapping_df[therapy_columns] = treatment_mapping_df[therapy_columns].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "treatment_to_parent_mapping = CIVIC_ncit_df_finalparent_treatmentcategory.set_index(\"name\")[\"parent_treatment_category\"].to_dict()\n",
    "treatment_to_finalparent_mapping = CIVIC_ncit_df_finalparent_treatmentcategory.set_index(\"name\")[\"final_parent\"].to_dict()\n",
    "hierarchy_data = []\n",
    "for treatment in therapy_columns:\n",
    "    treatment_sum = treatment_mapping_df[treatment].sum()\n",
    "    if treatment in treatment_to_parent_mapping and treatment in treatment_to_finalparent_mapping:\n",
    "        hierarchy_data.append([treatment_to_parent_mapping[treatment], treatment_to_finalparent_mapping[treatment], treatment_sum])\n",
    "hierarchy_df = pd.DataFrame(hierarchy_data, columns=[\"Parent Category\", \"Final Parent Category\", \"Total Mentions\"])\n",
    "hierarchy_df[\"Parent Category\"] = hierarchy_df[\"Parent Category\"].astype(str)\n",
    "hierarchy_df[\"Final Parent Category\"] = hierarchy_df[\"Final Parent Category\"].astype(str)\n",
    "hierarchy_df = hierarchy_df.groupby([\"Parent Category\", \"Final Parent Category\"]).sum().reset_index()\n",
    "hierarchy_df[\"Final Parent Category Label\"] = hierarchy_df[\"Final Parent Category\"] + \" (\" + hierarchy_df[\"Total Mentions\"].apply(lambda x: f\"{int(x):,}\") + \")\"\n",
    "fig = px.sunburst(hierarchy_df, path=[\"Parent Category\", \"Final Parent Category Label\"], values=\"Total Mentions\", color=\"Parent Category\", title=\"Hierarchy of Treatment Categories and Final Parent Categories\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a278b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot treemap\n",
    "fig = px.treemap(\n",
    "    hierarchy_df,\n",
    "    path=[\"Parent Category\", \"Final Parent Category\"],\n",
    "    values=\"Total Mentions\",\n",
    "    color=\"Parent Category\",\n",
    "    title=\"Treemap of Treatment Categories and Final Parent Categories\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CIVIC_ncit_df_finalparent_treatmentcategory.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sunburst, treemap, and icicle charts for treatment hierarchy with total mentions\n",
    "treatment_mapping_df = pd.read_csv(\"treatment_mapping_with_matches.csv\")\n",
    "CIVIC_ncit_df_finalparent_treatmentcategory = pd.read_csv(\"CIVIC_ncit_df_finalparent_treatmentcategory.csv\")\n",
    "metadata_columns = [\"PaperTitle\", \"Abstract\", \"Sum_treatments\", \"Treatment_matches\"]\n",
    "therapy_columns = [col for col in treatment_mapping_df.columns if col not in metadata_columns]\n",
    "treatment_mapping_df[therapy_columns] = treatment_mapping_df[therapy_columns].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "treatment_to_parent_mapping = CIVIC_ncit_df_finalparent_treatmentcategory.set_index(\"name\")[\"parent_treatment_category\"].to_dict()\n",
    "treatment_to_finalparent_mapping = CIVIC_ncit_df_finalparent_treatmentcategory.set_index(\"name\")[\"final_parent\"].to_dict()\n",
    "hierarchy_data = []\n",
    "for treatment in therapy_columns:\n",
    "    treatment_sum = treatment_mapping_df[treatment].sum()\n",
    "    if treatment in treatment_to_parent_mapping and treatment in treatment_to_finalparent_mapping:\n",
    "        hierarchy_data.append([treatment_to_parent_mapping[treatment], treatment_to_finalparent_mapping[treatment], treatment_sum])\n",
    "hierarchy_df = pd.DataFrame(hierarchy_data, columns=[\"Parent Category\", \"Final Parent Category\", \"Total Mentions\"])\n",
    "hierarchy_df = hierarchy_df.groupby([\"Parent Category\", \"Final Parent Category\"]).sum().reset_index()\n",
    "hierarchy_df[\"Parent Category\"] = hierarchy_df[\"Parent Category\"] + \" (\" + hierarchy_df[\"Total Mentions\"].astype(int).astype(str) + \")\"\n",
    "hierarchy_df[\"Final Parent Category\"] = hierarchy_df[\"Final Parent Category\"] + \" (\" + hierarchy_df[\"Total Mentions\"].astype(int).astype(str) + \")\"\n",
    "\n",
    "# *** Sunburst Chart\n",
    "fig_sunburst = px.sunburst(hierarchy_df, path=[\"Parent Category\", \"Final Parent Category\"], values=\"Total Mentions\", color=\"Parent Category\", title=\"Sunburst Chart: Treatment Categories and Final Parent Categories\")\n",
    "fig_sunburst.show()\n",
    "\n",
    "# *** Treemap\n",
    "fig_treemap = px.treemap(hierarchy_df, path=[\"Parent Category\", \"Final Parent Category\"], values=\"Total Mentions\", color=\"Parent Category\", title=\"Treemap: Treatment Categories and Final Parent Categories\")\n",
    "fig_treemap.show()\n",
    "\n",
    "# *** Icicle Plot\n",
    "fig_icicle = px.icicle(hierarchy_df, path=[\"Parent Category\", \"Final Parent Category\"], values=\"Total Mentions\", color=\"Parent Category\", title=\"Icicle Plot: Treatment Categories and Final Parent Categories\")\n",
    "fig_icicle.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff063d8",
   "metadata": {},
   "source": [
    "# Merging and hierachy creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841b7d64",
   "metadata": {},
   "source": [
    "# =========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a1a172",
   "metadata": {},
   "source": [
    "# Evaluation: Previous methods to extarct treamtents and drugs from PaperTitle and Abstarct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!pip install scispacy\n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz \n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ccc6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_treatments = spacy.load(\"en_ner_bionlp13cg_md\")\n",
    "print(\"Success!\")\n",
    "try:\n",
    "    nlp_treatments = spacy.load(\"en_ner_bionlp13cg_md\")\n",
    "    print(\"SciSpaCy Model 'en_ner_bionlp13cg_md' loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading SciSpaCy model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f741b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract drug mentions from text using binary string matching\n",
    "\n",
    "tqdm.pandas(desc=\"Extracting drug mentions\")\n",
    "CIVIC_therapies_analysis[\"name\"] = CIVIC_therapies_analysis[\"name\"].str.lower().str.strip()\n",
    "CIVIC_therapies_analysis[\"therapyAliases\"] = CIVIC_therapies_analysis[\"therapyAliases\"].apply(lambda x: [alias.strip().lower() for alias in eval(x)] if isinstance(x, str) and x.startswith(\"[\") else [])\n",
    "drug_mapping = {}\n",
    "for _, row in CIVIC_therapies_analysis.iterrows():\n",
    "    drug_name = row[\"name\"]\n",
    "    aliases = row[\"therapyAliases\"]\n",
    "    drug_mapping[drug_name] = set([drug_name] + aliases)\n",
    "all_drug_terms = set()\n",
    "for aliases in drug_mapping.values():\n",
    "    all_drug_terms.update(aliases)\n",
    "all_drug_terms = list(all_drug_terms)\n",
    "def extract_drugs_binary(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return {drug: 0 for drug in all_drug_terms}\n",
    "    text = text.lower()\n",
    "    matches = {drug: 1 if drug in text else 0 for drug in all_drug_terms}\n",
    "    return matches\n",
    "\n",
    "df['Title_Abstract'] = df['PaperTitle'].astype(str) + \" \" + df['Abstract'].astype(str)\n",
    "start_time_expected = time.time()\n",
    "test_row = df['Title_Abstract'].iloc[0]\n",
    "test_time_start = time.time()\n",
    "extract_drugs_binary(test_row)\n",
    "test_time_end = time.time()\n",
    "single_row_time = test_time_end - test_time_start\n",
    "expected_runtime_seconds = single_row_time * total_rows\n",
    "print(f\"Expected runtime: {expected_runtime_seconds:.2f} seconds (~{expected_runtime_seconds/60:.2f} minutes)\")\n",
    "start_time_execution = time.time()\n",
    "binary_matrix = df['Title_Abstract'].progress_apply(extract_drugs_binary).apply(pd.Series)\n",
    "binary_matrix[\"Sum_drug_mentions\"] = binary_matrix.sum(axis=1)\n",
    "df = pd.concat([df, binary_matrix], axis=1)\n",
    "rows_with_drug_mentions = (df[\"Sum_drug_mentions\"] >= 1).sum()\n",
    "rows_with_no_mentions = (df[\"Sum_drug_mentions\"] == 0).sum()\n",
    "percentage_with_drugs = (rows_with_drug_mentions / total_rows) * 100\n",
    "output_path = \"Drug_Binary_Matrix_String_Matching.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "summary_text = f\"\"\"\n",
    "Total rows in dataset: {total_rows}\n",
    "Rows with at least one drug mention: {rows_with_drug_mentions}\n",
    "Rows with no drug mentions: {rows_with_no_mentions}\n",
    "Percentage of articles with drug mentions: {percentage_with_drugs:.2f}%\n",
    "\"\"\"\n",
    "summary_output_path = \"Drug_Matching_Summary.txt\"\n",
    "with open(summary_output_path, \"w\") as f:\n",
    "    f.write(summary_text)\n",
    "end_time_execution = time.time()\n",
    "actual_runtime_seconds = end_time_execution - start_time_execution\n",
    "\n",
    "\n",
    "print(summary_text)\n",
    "print(f\"Processing completed successfully! Results saved to {output_path} and summary saved to {summary_output_path}\")\n",
    "print(f\"Actual runtime: {actual_runtime_seconds:.2f} seconds (~{actual_runtime_seconds/60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e6e6c",
   "metadata": {},
   "source": [
    "## Extract therapies mentions using SSciSpaCy \"en_ner_bionlp13cg_md\" and \"en_ner_bc5cdr_md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88744f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SciSpaCy models for drug extraction\n",
    "try:\n",
    "    nlp_drug_1 = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "    nlp_drug_2 = spacy.load(\"en_ner_bionlp13cg_md\") \n",
    "    print(\"SciSpaCy Models Loaded Successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error Loading Models: {e}\")\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords to filter out false positives\n",
    "EXCLUDE_TERMS = {\"gene\", \"HRR\",\"DDR\",}\n",
    "\n",
    "# Function to clean extracted terms\n",
    "def clean_term(term):\n",
    "    \"\"\"Cleans extracted terms by normalizing Unicode and standardizing hyphens.\"\"\"\n",
    "    term = term.lower().strip()\n",
    "    term = unicodedata.normalize(\"NFKC\", term)  # Normalize Unicode characters\n",
    "    term = re.sub(r'[-‐–—]', ' ', term)  # Standardize hyphens\n",
    "    return term\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drug_mentions(text):\n",
    "    \"\"\"\n",
    "    Extracts drug-related mentions from the text using two SciSpaCy models.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return []\n",
    "    extracted_terms = set() \n",
    "    doc1 = nlp_drug_1(text)\n",
    "    doc2 = nlp_drug_2(text)\n",
    "\n",
    "    for ent in doc1.ents + doc2.ents:\n",
    "        term = clean_term(ent.text)\n",
    "        if ent.label_ == \"CHEMICAL\":\n",
    "            extracted_terms.add(term)\n",
    "\n",
    "    # Remove false positives\n",
    "    filtered_terms = {term for term in extracted_terms if term not in EXCLUDE_TERMS}\n",
    "\n",
    "    return list(filtered_terms)\n",
    "\n",
    "def apply_drug_extraction(df):\n",
    "    \"\"\"\n",
    "    Apply drug extraction to the 'PaperTitle' and 'Abstract' columns using swifter for faster execution.\n",
    "    \"\"\"\n",
    "    print(f\"Starting extraction for {len(df)} rows\")\n",
    "    df[\"Extracted_Drugs_Chemicals\"] = (\n",
    "        df[\"PaperTitle\"].astype(str) + \" \" + df[\"Abstract\"].astype(str)\n",
    "    ).swifter.apply(extract_drug_mentions)\n",
    "    print(f\"Extraction complete for {len(df)} rows\")\n",
    "    return df\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1462fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract drugs and therapies from dataset and save results\n",
    "start_time = time.time()\n",
    "tqdm.pandas()\n",
    "df_drug_extraction = full_df.copy()\n",
    "print(f\"Length of dataset: {len(df_drug_extraction)}\")\n",
    "df_drug_extraction = apply_drug_extraction(df_drug_extraction)\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "output_path = os.path.join(output_directory, \"Extracted_Drug_Chemical_Terms.csv\")\n",
    "df_drug_extraction.to_csv(output_path, index=False)\n",
    "print(f\"Length of dataset after extraction: {len(df_drug_extraction)}\")\n",
    "runtime_log_path = os.path.join(output_directory, \"running_time_drug_extraction.txt\")\n",
    "with open(runtime_log_path, \"w\") as f:\n",
    "    f.write(f\"Total execution time: {runtime:.2f} seconds\\n\")\n",
    "\n",
    "print(f\"File saved successfully: {output_path}\")\n",
    "print(f\"Execution time logged in: {runtime_log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff917a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the specific columns from df_drug_extraction\n",
    "print(len(df_drug_extraction))\n",
    "print(df_drug_extraction.columns)\n",
    "columns_to_display = [\"PaperId\", \"PaperTitle\", \"Abstract\", \"Extracted_Drugs_Chemicals\"]\n",
    "print(df_drug_extraction[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a4ed52",
   "metadata": {},
   "source": [
    "# =================================================\n",
    "## Using BERT for therapy and drug extraction:\n",
    "## alvaroalon2/biobert_chemical_ner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch\n",
    "print(\"Success!\")\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "print(\"Success!\")\n",
    "\n",
    "model_name = \"alvaroalon2/biobert_chemical_ner\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", device=0 if torch.cuda.is_available() else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5165133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drugs(text):\n",
    "    if pd.isna(text) or not text.strip():\n",
    "        return []\n",
    "    # Tokenize and encode the text with truncation\n",
    "    encoded_input = tokenizer(text, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    # Apply the NER pipeline to the text\n",
    "    entities = nlp(text)\n",
    "    # Filter entities labeled as 'CHEMICAL'\n",
    "    drugs = [entity['word'] for entity in entities if entity['entity_group'] == 'CHEMICAL']\n",
    "    return list(set(drugs)) \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract drug names using BioBERT model\n",
    "df = full_df.copy()\n",
    "tqdm.pandas(desc=\"Extracting drug names\")\n",
    "df['Title_Abstract'] = df['PaperTitle'].astype(str) + \" \" + df['Abstract'].astype(str)\n",
    "df['Extracted_Drugs'] = df['Title_Abstract'].progress_apply(extract_drugs)\n",
    "print(\"Extraction completed successfully!\")\n",
    "print(df)\n",
    "\n",
    "output_path = os.path.join(output_directory, \"Extracted_Drugs_BioBERT.csv\")\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"File saved successfully: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03edf61f",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "## Using BERT for therapy and drug extraction:\n",
    "## allenai/biomed_roberta_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b1451",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers pandas tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "model_name = \"allenai/biomed_roberta_base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drugs(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return []\n",
    "\n",
    "    # Apply the NER pipeline to the text\n",
    "    entities = nlp(text)\n",
    "\n",
    "    # Filter entities labeled as 'CHEMICAL' or 'DRUG'\n",
    "    drugs = [entity['word'] for entity in entities if entity['entity_group'] in ['CHEMICAL', 'DRUG']]\n",
    "\n",
    "    return list(set(drugs))  # Remove duplicates\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f36f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original DataFrame\n",
    "df = full_df.copy()\n",
    "\n",
    "# Ensure tqdm works properly\n",
    "tqdm.pandas(desc=\"Extracting drug names\")\n",
    "\n",
    "# Create a combined text field for processing (PaperTitle + Abstract)\n",
    "df['Title_Abstract'] = df['PaperTitle'].astype(str) + \" \" + df['Abstract'].astype(str)\n",
    "\n",
    "# Apply the extract_drugs function to the combined text field\n",
    "df['Extracted_Drugs'] = df['Title_Abstract'].progress_apply(extract_drugs)\n",
    "print(\"Extraction completed successfully!\")\n",
    "\n",
    "output_path = \"Extracted_Drugs_biomed_roberta_base.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1e5fda",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "## Improve chemical NER BERT for therapy and drug extraction:\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40194971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract drug names from text using BioBERT model alvaroalon2/biobert_chemical_ner\n",
    "model_name = \"alvaroalon2/biobert_chemical_ner\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "def split_text_into_chunks(text, max_length=512):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return [tokens[i:i+max_length] for i in range(0, len(tokens), max_length)]\n",
    "def extract_drugs(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return []\n",
    "    entities = nlp(text)\n",
    "    drugs = []\n",
    "    for entity in entities:\n",
    "        word = entity['word']\n",
    "        if word.startswith('##'):\n",
    "            word = word[2:]\n",
    "        elif word.startswith('r') and len(word) > 1:\n",
    "            word = word[0] + word[1:]\n",
    "        if entity['entity_group'] == 'CHEMICAL' and word not in drugs:\n",
    "            drugs.append(word)\n",
    "    return drugs\n",
    "df = full_df.copy()\n",
    "tqdm.pandas(desc=\"Extracting drug names\")\n",
    "df['Title_Abstract'] = df['PaperTitle'].astype(str) + \" \" + df['Abstract'].astype(str)\n",
    "df['Extracted_Drugs'] = df['Title_Abstract'].progress_apply(extract_drugs)\n",
    "output_path = \"Extracted_Drug_Names.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Extraction completed successfully! Results saved to {output_path}\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df94e44",
   "metadata": {},
   "source": [
    "# ========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc8079",
   "metadata": {},
   "source": [
    "# Match with CIVIC for binary matrix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIVIC therapy dataset\n",
    "# Check if the 'CIVIC_therapies' variable already exists in the global environment\n",
    "if \"CIVIC_therapies\" in globals():\n",
    "    CIVIC_therapies_analysis = CIVIC_therapies.copy()\n",
    "else:\n",
    "    CIVIC_therapies_analysis = pd.read_csv(\"/path/to/CIVIC_therapies_with_aliases.csv\")\n",
    "\n",
    "print(CIVIC_therapies_analysis.head())\n",
    "print(\"Length of dataset:\",len(CIVIC_therapies_analysis))\n",
    "print(\"\\n\\nSuccess!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a51858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and load dataset\n",
    "if \"df_drug_extraction\" in globals():\n",
    "    df_drug_extraction = df_drug_extraction.copy()\n",
    "else:\n",
    "    print(\"Loading dataset from file...\")\n",
    "    df_drug_extraction = pd.read_csv(output_directory + \"Extracted_Drug_Chemical_Terms.csv\")\n",
    "print(f\"Length of dataset copy: {len(df_drug_extraction):,}\")\n",
    "\n",
    "# Ensure that the 'Extracted_Drugs_Chemicals' column is processed as a list of strings\n",
    "df_drug_extraction[\"Extracted_Drugs_Chemicals\"] = df_drug_extraction[\"Extracted_Drugs_Chemicals\"].apply(\n",
    "    lambda x: x if isinstance(x, list) else ast.literal_eval(x) \n",
    ")\n",
    "\n",
    "print(df_drug_extraction[[\"PaperId\", \"Extracted_Drugs_Chemicals\"]].head())\n",
    "print(\"Succes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f111ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize drug names for consistent matching\n",
    "def normalize_drug_name(term):\n",
    "    if not isinstance(term, str):\n",
    "        return term\n",
    "    term = term.lower().strip()\n",
    "    term = unicodedata.normalize(\"NFKC\", term)\n",
    "    term = re.sub(r'[-‐–—]', ' ', term)\n",
    "    ignore_prefixes = [\"drug\", \"treatment\", \"therapy\", \"chemotherapy\", \"medication\", \"cancer\"]\n",
    "    term = re.sub(r'\\b(' + '|'.join(ignore_prefixes) + r')\\b', '', term)\n",
    "    term = re.sub(r'[\\.\\d/]+$', '', term)\n",
    "    term = re.sub(r'\\s+', ' ', term).strip()\n",
    "    words = term.split()\n",
    "    term = ' '.join(sorted(set(words), key=words.index))\n",
    "    return term\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map extracted drug terms to known therapies and save results\n",
    "no_match_count = 0\n",
    "open(\"unmatched_therapy_terms_log.txt\", \"w\").close()\n",
    "def map_therapy_terms(terms):\n",
    "    global no_match_count\n",
    "    if not isinstance(terms, list):\n",
    "        return []\n",
    "    mapped_therapies = []\n",
    "    unmatched_therapies = set()\n",
    "    for term in terms:\n",
    "        normalized_term = normalize_drug_name(term).lower()\n",
    "        matched_therapy = next((therapy for therapy in therapy_mapping if normalized_term in therapy.lower()), None)\n",
    "        if matched_therapy:\n",
    "            mapped_therapies.append(matched_therapy)\n",
    "        else:\n",
    "            no_match_count += 1\n",
    "            unmatched_therapies.add(normalized_term)\n",
    "    if unmatched_therapies:\n",
    "        with open(\"unmatched_therapy_terms_log.txt\", \"a\") as f:\n",
    "            for term in unmatched_therapies:\n",
    "                f.write(term + \"\\n\")\n",
    "    return list(set(mapped_therapies))\n",
    "df_drug_extraction[\"Mapped_Therapies\"] = df_drug_extraction[\"Extracted_Drugs_Chemicals\"].progress_apply(map_therapy_terms)\n",
    "\n",
    "print(df_drug_extraction[[\"PaperId\", \"Extracted_Drugs_Chemicals\", \"Mapped_Therapies\"]].head(10))\n",
    "df_drug_extraction.to_csv(os.path.join(output_directory, \"Extracted_Drug_Chemical_Terms_with_mapped_therapies_1.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac73a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "with open(\"unmatched_therapy_terms_log.txt\", \"r\") as f:\n",
    "    unmatched_therapy_terms_log = f.readlines()\n",
    "print(unmatched_therapy_terms_log[:20])  # Show first 20 unmatched terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d00c8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Map extracted drug terms to therapy names and aliases\n",
    "no_match_count = 0\n",
    "open(\"unmatched_therapy_terms_log.txt\", \"w\").close()\n",
    "def map_therapy_terms(terms):\n",
    "    global no_match_count\n",
    "    if not isinstance(terms, list):\n",
    "        return []\n",
    "    mapped_therapies = []\n",
    "    unmatched_therapies = set()\n",
    "    for term in terms:\n",
    "        normalized_term = normalize_drug_name(term).lower()\n",
    "        matched = next((therapy for therapy in CIVIC_therapies_analysis.itertuples() if normalized_term in normalize_drug_name(therapy.name).lower() or any(normalized_term in normalize_drug_name(alias).lower() for alias in (therapy.therapyAliases if isinstance(therapy.therapyAliases, list) else []))), None)\n",
    "        if matched:\n",
    "            mapped_therapies.append(matched.name)\n",
    "        else:\n",
    "            no_match_count += 1\n",
    "            unmatched_therapies.add(normalized_term)\n",
    "    if unmatched_therapies:\n",
    "        with open(\"unmatched_therapy_terms_log.txt\", \"a\") as f:\n",
    "            f.writelines(term + \"\\n\" for term in unmatched_therapies)\n",
    "    return list(set(mapped_therapies))\n",
    "df_drug_extraction[\"Mapped_Therapies\"] = df_drug_extraction[\"Extracted_Drugs_Chemicals\"].progress_apply(map_therapy_terms)\n",
    "\n",
    "print(df_drug_extraction[[\"PaperId\", \"Extracted_Drugs_Chemicals\", \"Mapped_Therapies\"]].head(10))\n",
    "df_drug_extraction.to_csv(os.path.join(output_directory, \"Extracted_Drug_Chemical_Terms_with_mapped_therapies_2.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c72ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "with open(\"unmatched_therapy_terms_log.txt\", \"r\") as f:\n",
    "    unmatched_therapy_terms_log = f.readlines()\n",
    "print(unmatched_therapy_terms_log[:20])  # Show first 20 unmatched terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map extracted drug terms to therapy names and aliases separately from CIVIC dataset\n",
    "no_match_count = 0\n",
    "open(\"unmatched_therapy_terms_log.txt\", \"w\").close()\n",
    "def map_therapy_terms(terms):\n",
    "    global no_match_count\n",
    "    if not isinstance(terms, list): return []\n",
    "    mapped_therapies = []\n",
    "    unmatched_therapies = set()\n",
    "    for term in terms:\n",
    "        normalized_term = normalize_drug_name(term).lower()\n",
    "        matched_therapy = next((therapy for therapy in CIVIC_therapies_analysis.itertuples() if normalized_term in normalize_drug_name(therapy.name).lower()), None)\n",
    "        if not matched_therapy:\n",
    "            matched_therapy = next((therapy for therapy in CIVIC_therapies_analysis.itertuples() if any(normalized_term in normalize_drug_name(alias).lower() for alias in (therapy.therapyAliases if isinstance(therapy.therapyAliases, list) else []))), None)\n",
    "        if matched_therapy: mapped_therapies.append(matched_therapy.name)\n",
    "        else:\n",
    "            no_match_count += 1\n",
    "            unmatched_therapies.add(normalized_term)\n",
    "    if unmatched_therapies:\n",
    "        with open(\"unmatched_therapy_terms_log.txt\", \"a\") as f: f.writelines(term + \"\\n\" for term in unmatched_therapies)\n",
    "    return list(set(mapped_therapies))\n",
    "df_drug_extraction[\"Mapped_Therapies\"] = df_drug_extraction[\"Extracted_Drugs_Chemicals\"].progress_apply(map_therapy_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f75936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if the mapping worked\n",
    "print(df_drug_extraction[[\"PaperId\", \"Extracted_Drugs_Chemicals\", \"Mapped_Therapies\"]].head(10))\n",
    "df_drug_extraction.to_csv(os.path.join(output_directory, \"Extracted_Drug_Chemical_Terms_with_mapped_therapies_3.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90741b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize drug names and map extracted drug terms to therapies by exact match\n",
    "\n",
    "def normalize_drug_name(term):\n",
    "    if not isinstance(term, str): return term\n",
    "    term = term.lower().strip()\n",
    "    term = unicodedata.normalize(\"NFKC\", term)\n",
    "    term = re.sub(r'[-‐–—]', ' ', term)\n",
    "    term = re.sub(r'\\b(' + '|'.join([\"drug\",\"treatment\",\"therapy\",\"chemotherapy\",\"medication\",\"cancer\"]) + r')\\b', '', term)\n",
    "    term = re.sub(r'[\\.\\d/]+$', '', term)\n",
    "    term = re.sub(r'\\s+', ' ', term).strip()\n",
    "    words = term.split()\n",
    "    return ' '.join(sorted(set(words), key=words.index))\n",
    "print(\"Success!\")\n",
    "\n",
    "no_match_count = 0\n",
    "open(\"unmatched_therapy_terms_log.txt\", \"w\").close()\n",
    "\n",
    "def map_therapy_terms(terms):\n",
    "    global no_match_count\n",
    "    if not isinstance(terms, list): return []\n",
    "    mapped_therapies = []\n",
    "    unmatched_therapies = set()\n",
    "    for term in terms:\n",
    "        normalized_term = normalize_drug_name(term).lower()\n",
    "        matched_therapy = next((therapy for therapy in CIVIC_therapies_analysis.itertuples() if normalized_term == normalize_drug_name(therapy.name).lower()), None)\n",
    "        if not matched_therapy:\n",
    "            matched_therapy = next((therapy for therapy in CIVIC_therapies_analysis.itertuples() if isinstance(therapy.therapyAliases, list) and any(normalized_term == normalize_drug_name(alias).lower() for alias in therapy.therapyAliases)), None)\n",
    "        if matched_therapy: mapped_therapies.append(matched_therapy.name)\n",
    "        else:\n",
    "            no_match_count += 1\n",
    "            unmatched_therapies.add(normalized_term)\n",
    "    if unmatched_therapies:\n",
    "        with open(\"unmatched_therapy_terms_log.txt\", \"a\") as f: f.writelines(term + \"\\n\" for term in unmatched_therapies)\n",
    "    return list(set(mapped_therapies))\n",
    "df_drug_extraction[\"Mapped_Therapies\"] = df_drug_extraction[\"Extracted_Drugs_Chemicals\"].progress_apply(map_therapy_terms)\n",
    "print(df_drug_extraction[[\"PaperId\", \"Extracted_Drugs_Chemicals\", \"Mapped_Therapies\"]].head())\n",
    "df_drug_extraction.to_csv(os.path.join(output_directory, \"Extracted_Drug_Chemical_Terms_with_mapped_therapies_4.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0515df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize drug names and map them to therapies using exact matching\n",
    "def normalize_drug_name(term):\n",
    "    if not isinstance(term, str): return term\n",
    "    term = term.lower().strip() # Convert to lowercase\n",
    "    term = unicodedata.normalize(\"NFKC\", term) # Normalize unicode characters\n",
    "    term = re.sub(r'[-‐–—_]', ' ', term) # Replace hyphens, dashes, and underscores with spaces\n",
    "    term = re.sub(r'\\b(' + '|'.join([\"drug\",\"treatment\",\"therapy\",\"chemotherapy\",\"medication\",\"cancer\"]) + r')\\b', '', term) # Remove common prefixes and suffixes\n",
    "    term = re.sub(r'[\\.\\d/]+$', '', term) # Remove numbers or symbols at end\n",
    "    term = re.sub(r'\\s+', ' ', term).strip() # Remove consecutive spaces and extra spaces\n",
    "    term = re.sub(r'[^a-z\\s]', '', term) # Clean invalid characters\n",
    "    words = term.split()\n",
    "    return ' '.join(sorted(set(words), key=words.index)) # Remove consecutive duplicate words\n",
    "print(\"Success!\")\n",
    "\n",
    "\n",
    "no_match_count = 0\n",
    "open(\"unmatched_therapy_terms_log.txt\", \"w\").close()\n",
    "\n",
    "\n",
    "def map_therapy_terms(terms):\n",
    "    global no_match_count\n",
    "    if not isinstance(terms, list): return []\n",
    "    mapped_therapies = []\n",
    "    unmatched_therapies = set()\n",
    "    for term in terms:\n",
    "        normalized_term = normalize_drug_name(term).lower()\n",
    "        matched_therapy = next((therapy for therapy in CIVIC_therapies_analysis.itertuples() if normalized_term == normalize_drug_name(therapy.name).lower()), None)\n",
    "        if not matched_therapy:\n",
    "            matched_therapy = next((therapy for therapy in CIVIC_therapies_analysis.itertuples() if isinstance(therapy.therapyAliases, list) and any(normalized_term == normalize_drug_name(alias).lower() for alias in therapy.therapyAliases)), None)\n",
    "        if matched_therapy: mapped_therapies.append(matched_therapy.name)\n",
    "        else:\n",
    "            no_match_count += 1\n",
    "            unmatched_therapies.add(normalized_term)\n",
    "    if unmatched_therapies:\n",
    "        with open(\"unmatched_therapy_terms_log.txt\", \"a\") as f: f.writelines(term + \"\\n\" for term in unmatched_therapies)\n",
    "    return list(set(mapped_therapies))\n",
    "df_drug_extraction[\"Mapped_Therapies\"] = df_drug_extraction[\"Extracted_Drugs_Chemicals\"].progress_apply(map_therapy_terms)\n",
    "\n",
    "print(df_drug_extraction[[\"PaperId\", \"Extracted_Drugs_Chemicals\", \"Mapped_Therapies\"]].head())\n",
    "df_drug_extraction.to_csv(os.path.join(output_directory, \"Extracted_Drug_Chemical_Terms_with_mapped_therapies_5.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate binary therapy matrix from mapped therapies\n",
    "\n",
    "binary_rows = [{\"PaperId\": row[\"PaperId\"], \"mapped_therapy\": term} for _, row in df_drug_extraction.iterrows() for term in row[\"Mapped_Therapies\"]]\n",
    "binary_df = pd.DataFrame(binary_rows)\n",
    "binary_matrix = binary_df.pivot_table(index=\"PaperId\", columns=\"mapped_therapy\", aggfunc=lambda x: 1, fill_value=0)\n",
    "df_binary_matrix = df_drug_extraction.merge(binary_matrix, on=\"PaperId\", how=\"left\").fillna(0)\n",
    "df_binary_matrix[\"Therapy_Sum\"] = df_binary_matrix.iloc[:, df_drug_extraction.shape[1]:].sum(axis=1)\n",
    "df_binary_matrix.to_csv(\"binary_therapy_matrix.csv\", index=False)\n",
    "\n",
    "print(df_binary_matrix.head())\n",
    "print(df_binary_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba0436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter papers with mapped therapies and save separate outputs\n",
    "\n",
    "df_binary_matrix_filtered = df_binary_matrix[df_binary_matrix[\"Therapy_Sum\"] > 0]\n",
    "zero_rows_therapy_df = df_binary_matrix[df_binary_matrix[\"Therapy_Sum\"] == 0]\n",
    "df_binary_matrix_filtered.to_csv(\"binary_therapy_matrix_filtered.csv\", index=False)\n",
    "zero_rows_therapy_df.to_csv(\"zero_rows_therapy_df.csv\", index=False)\n",
    "print(f\"Filtered dataset size (papers with therapies): {len(df_binary_matrix_filtered)} rows\")\n",
    "print(f\"Dropped dataset size (papers with no therapies): {len(zero_rows_therapy_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a477a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter therapy matrix by Therapy_Sum and verify dataset size\n",
    "\n",
    "os.chdir(output_directory)\n",
    "matrix_file = \"binary_therapy_matrix_filtered.csv\"\n",
    "df_binary_matrix = pd.read_csv(matrix_file)\n",
    "df_binary_matrix_filtered = df_binary_matrix[df_binary_matrix[\"Therapy_Sum\"] > 0]\n",
    "original_length = len(df_binary_matrix)\n",
    "filtered_length = len(df_binary_matrix_filtered)\n",
    "dropped_length = original_length - filtered_length\n",
    "dropped_percentage = (dropped_length / original_length) * 100\n",
    "\n",
    "\n",
    "print(f\"\\nOriginal dataset length: {original_length:,}\")\n",
    "print(f\"Filtered dataset length (Therapy_Sum > 0): {filtered_length:,}\")\n",
    "print(f\"Dropped rows (Therapy_Sum == 0): {dropped_length:,} ({dropped_percentage:.2f}%)\")\n",
    "if original_length == (filtered_length + dropped_length):\n",
    "    print(\"\\n--> The numbers add up correctly!\")\n",
    "else:\n",
    "    print(\"\\n--> Warning: The numbers do NOT add up correctly!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
