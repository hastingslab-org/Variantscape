{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae425479",
   "metadata": {},
   "source": [
    "# Coassociation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3b553",
   "metadata": {},
   "source": [
    "# 1) Set up libraries and datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb218e22",
   "metadata": {},
   "source": [
    "## 1.1) Import libraries and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import pyvis\n",
    "import community\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, fisher_exact\n",
    "from scipy.cluster.hierarchy import fcluster, linkage, dendrogram\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c91129",
   "metadata": {},
   "source": [
    "## 1.2) Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory and file paths\n",
    "input_directory = \"INPUT_DIRECTORY\"\n",
    "output_directory = \"OUTPUT_DIRECTORY\"\n",
    "variantscape_directory = \"VARIANTSCAPE_DIRECTORY\"\n",
    "figure_directory = \"FIGURE_DIRECTORY\"\n",
    "variantscape_llm_coas_directory = \"VARIANTSCAPE_LLM_COAS_DIRECTORY\"\n",
    "\n",
    "os.chdir(variantscape_directory)\n",
    "print(\"Current directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf2ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "\n",
    "#### In input directory\n",
    "os.chdir(input_directory)\n",
    "oncomine_genes = pd.read_csv(\"oncomine_ngs_panel.csv\", header=None)\n",
    "ESCAT_genes = pd.read_csv(\"ESCAT_pc_genes.csv\", header=None)\n",
    "ESCAT_genes.rename(columns={ESCAT_genes.columns[0]: \"ESCAT_genes\"}, inplace=True)\n",
    "\n",
    "#### In variantscape directory\n",
    "# Change to the variantscape directory\n",
    "os.chdir(variantscape_directory)\n",
    "\n",
    "# Load the variant dataset (v3) and metadata mapping\n",
    "variant_analysis_df = pd.read_csv(\"cleaned_df_v4.csv\", low_memory=False)\n",
    "metadata_mapping = pd.read_csv(\"metadata_mapping.csv\", low_memory=False)\n",
    "\n",
    "# Check the lengths and columns of datasets\n",
    "len_variant_analysis_df_rows, len_variant_analysis_df_cols = variant_analysis_df.shape\n",
    "len_oncomine_genes_rows, len_oncomine_genes_cols = oncomine_genes.shape\n",
    "len_ESCAT_genes_rows, len_ESCAT_genes_cols = ESCAT_genes.shape\n",
    "len_metadata_mapping_rows, len_metadata_mapping_cols = metadata_mapping.shape\n",
    "\n",
    "# Validate that the number of columns in variant_analysis_df matches the number of entries in metadata_mapping\n",
    "if len_variant_analysis_df_cols == len_metadata_mapping_cols:\n",
    "    print(\"The number of columns in variant_analysis_df matches the number of metadata entries.\")\n",
    "else:\n",
    "    print(f\"Warning: The number of columns in variant_analysis_df ({len_variant_analysis_df_cols}) does not match the number of metadata entries ({len_metadata_mapping_cols}).\")\n",
    "print(\"\\nSuccess!\")\n",
    "print(f\"\\nMerged variant dataset: {len_variant_analysis_df_rows:,} rows, {len_variant_analysis_df_cols:,} columns\")\n",
    "print(f\"Number of oncomine genes: {len_oncomine_genes_rows:,} rows, {len_oncomine_genes_cols:,} columns\")\n",
    "print(f\"Number of ESCAT genes: {len_ESCAT_genes_rows:,} rows, {len_ESCAT_genes_cols:,} columns\")\n",
    "print(\"\\n\")\n",
    "print(ESCAT_genes)\n",
    "\n",
    "# Validate that the column names in variant_analysis_df correspond to metadata mapping\n",
    "# Convert metadata_mapping (which is a row) into a dictionary for comparison\n",
    "metadata_dict = metadata_mapping.iloc[0].to_dict()\n",
    "missing_metadata = [col for col in variant_analysis_df.columns if col not in metadata_dict]\n",
    "if not missing_metadata:\n",
    "    print(\"\\nAll columns in variant_analysis_df have corresponding metadata.\")\n",
    "else:\n",
    "    print(f\"Warning: The following columns in variant_analysis_df do not have corresponding metadata: {missing_metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd0aab",
   "metadata": {},
   "source": [
    "# Step 1) Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa433ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subdataset \n",
    "coas_variant_df = variant_analysis_df.copy()\n",
    "print(f\"Total rows in coas_variant_df: {len(coas_variant_df):,}\")\n",
    "print(f\"Total cols in coas_variant_df: {len(coas_variant_df.columns):,}\")\n",
    "\n",
    "# Create the metadata dictionary\n",
    "print(f\"Total cols in metadata mapping: {len(metadata_mapping.columns):,}\")\n",
    "\n",
    "# Calculate the total sum for each column (excluding non-numeric columns like 'PaperId')\n",
    "total_sum_per_column = coas_variant_df.iloc[:, 5:].sum()\n",
    "zero_sum_columns = total_sum_per_column[total_sum_per_column == 0]\n",
    "if zero_sum_columns.empty:\n",
    "    print(\"All columns have non-zero totals!\")\n",
    "else:\n",
    "    print(\"Columns with a total sum of zero (no associations):\")\n",
    "    print(zero_sum_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913cb906",
   "metadata": {},
   "source": [
    "# =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcf0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart\n",
    "dictionary = metadata_mapping.copy()\n",
    "coas_variant_df = variant_analysis_df.copy()\n",
    "total_articles = len(coas_variant_df)\n",
    "\n",
    "dictionary = dictionary.transpose().reset_index()\n",
    "dictionary.columns = [\"Column_Name\", \"Category\"]\n",
    "\n",
    "treatment_columns = dictionary[dictionary['Category'] == \"Treatment\"][\"Column_Name\"].tolist()\n",
    "cancer_columns = dictionary[dictionary['Category'] == \"Cancer\"][\"Column_Name\"].tolist()\n",
    "variant_columns = dictionary[dictionary['Category'] == \"Variant\"][\"Column_Name\"].tolist()\n",
    "\n",
    "treatment_df = coas_variant_df[treatment_columns]\n",
    "cancer_df = coas_variant_df[cancer_columns]\n",
    "variant_df = coas_variant_df[variant_columns]\n",
    "\n",
    "# Count the mentions for each treatment, cancer, and variant\n",
    "top_treatments = treatment_df.sum()\n",
    "\n",
    "# EXCLUDE SPECIFIC TREATMENTS\n",
    "excluded_treatments = [\n",
    "    'chemotherapy',\n",
    "    'immunotherapy',\n",
    "    'hormone therapy',\n",
    "    'radiation therapy',\n",
    "    'adjuvant chemotherapy',\n",
    "    'radiation ionizing radiotherapy',\n",
    "    'tyrosine kinase inhibitor',\n",
    "    'braf inhibitor'\n",
    "]\n",
    "top_treatments = top_treatments[~top_treatments.index.str.lower().isin([t.lower() for t in excluded_treatments])]\n",
    "top_treatments = top_treatments.sort_values(ascending=False).head(20)\n",
    "top_cancers = cancer_df.sum().sort_values(ascending=False).head(20)\n",
    "top_cancers.index = top_cancers.index.str.capitalize()\n",
    "top_variants = variant_df.sum().sort_values(ascending=False).head(20)\n",
    "\n",
    "# Calculate percentages\n",
    "top_treatments_percent = (top_treatments / total_articles) * 100\n",
    "top_cancers_percent = (top_cancers / total_articles) * 100\n",
    "top_variants_percent = (top_variants / total_articles) * 100\n",
    "\n",
    "def weighted_co_occurrence_matrix(df1, df2, weights, scaling_factor=1.0):\n",
    "    weights = weights * scaling_factor\n",
    "    weighted_df1 = df1.mul(weights, axis=0)\n",
    "    weighted_df2 = df2.mul(weights, axis=0)\n",
    "    matrix = weighted_df1.T.dot(weighted_df2)\n",
    "    return pd.DataFrame(matrix, index=df1.columns, columns=df2.columns)\n",
    "weights = coas_variant_df['Study_weight']\n",
    "\n",
    "def format_variant_label(label):\n",
    "    \"\"\"Convert 'v600e_BRAF' to 'V600E BRAF'.\"\"\"\n",
    "    if \"_\" in label:\n",
    "        variant, gene = label.split(\"_\")\n",
    "        return f\"{gene.upper()} {variant.upper()}\"\n",
    "    return label.upper()\n",
    "def plot_and_save_bar_chart(data, title, xlabel, ylabel, file_name, total_articles):\n",
    "    data_with_padding = data.copy()\n",
    "    data_with_padding['Invisible Padding'] = 0\n",
    "    fig, ax = plt.subplots(figsize=(16, 10), constrained_layout=True)\n",
    "    data_with_padding.plot(kind='bar', color=['#1f20b4'] * len(data) + ['white'], edgecolor='black', ax=ax)\n",
    "    ax.set_title(f'{title.capitalize()} out of {total_articles:,} articles', fontsize=18)\n",
    "    ax.set_xlabel(xlabel, fontsize=14)\n",
    "    ax.set_ylabel(ylabel, fontsize=14)\n",
    "    ax.set_ylim(0, data.max() * 1.4)\n",
    "    plt.gca().yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{int(x):,}'))\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    ax.set_xticks(range(len(data)))\n",
    "    ax.set_xticklabels(data.index, rotation=45, ha='right', fontsize=14)\n",
    "    for i, (label, count) in enumerate(zip(data.index, data.values)):\n",
    "        percentage = (count / data.sum()) * 100\n",
    "        plt.text(i, count + (data.max() * 0.04), f\"{int(count):,} ({percentage:.2f}%)\", \n",
    "                 ha='left', va='bottom', fontsize=14, rotation=45)\n",
    "    plt.subplots_adjust(left=0.05, right=0.99, bottom=0.35, top=0.95)\n",
    "    plt.savefig(file_name, bbox_inches='tight', pad_inches=0.5, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "statistics_file = os.path.join(current_directory, 'output_statistics.txt')\n",
    "top_variants.index = [format_variant_label(v) for v in top_variants.index]\n",
    "\n",
    "plot_and_save_bar_chart(top_treatments, 'Top 20 most mentioned treatments', 'Treatment', 'Mentions', \n",
    "                        os.path.join(current_directory, 'Top_20_Most_Mentioned_Treatments.png'), total_articles)\n",
    "\n",
    "plot_and_save_bar_chart(top_cancers, 'Top 20 most mentioned cancers', 'Cancer', 'Mentions', \n",
    "                        os.path.join(current_directory, 'Top_20_Most_Mentioned_Cancers.png'), total_articles)\n",
    "\n",
    "plot_and_save_bar_chart(top_variants, 'Top 20 most mentioned variants', 'Variant', 'Mentions', \n",
    "                        os.path.join(current_directory, 'Top_20_Most_Mentioned_Variants.png'), total_articles)\n",
    "\n",
    "# Generate output\n",
    "with open(statistics_file, 'w') as f:\n",
    "    f.write(\"DataFrame Statistics:\\n\")\n",
    "    f.write(f\"Number of rows: {len(coas_variant_df)}\\n\")\n",
    "    f.write(f\"Number of columns: {len(coas_variant_df.columns)}\\n\\n\")\n",
    "    f.write(f\"Treatment Columns: {len(treatment_columns)}\\n\")\n",
    "    f.write(f\"Cancer Columns: {len(cancer_columns)}\\n\")\n",
    "    f.write(f\"Variant Columns: {len(variant_columns)}\\n\\n\")\n",
    "    f.write(\"Top 20 Most Mentioned Treatments (with percentages):\\n\")\n",
    "    for treatment, count, percent in zip(top_treatments.index, top_treatments, top_treatments_percent):\n",
    "        f.write(f\"{treatment}: {count} mentions, {percent:.2f}%\\n\")\n",
    "    f.write(\"\\nTop 20 Most Mentioned Cancers (with percentages):\\n\")\n",
    "    for cancer, count, percent in zip(top_cancers.index, top_cancers, top_cancers_percent):\n",
    "        f.write(f\"{cancer}: {count} mentions, {percent:.2f}%\\n\")\n",
    "    f.write(\"\\nTop 20 Most Mentioned Variants (with percentages):\\n\")\n",
    "    for variant, count, percent in zip(top_variants.index, top_variants, top_variants_percent):\n",
    "        f.write(f\"{variant}: {count} mentions, {percent:.2f}%\\n\")\n",
    "print(\"Bar charts and statistics have been generated and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d142b",
   "metadata": {},
   "source": [
    "# Coassociation analysis weighted by study design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66bcbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate percentage-based co-occurrence matrix\n",
    "def normalized_co_occurrence_matrix(df1, df2, weights, scaling_factor=1.0):\n",
    "    # Apply weights to dataframes\n",
    "    weights = weights * scaling_factor\n",
    "    weighted_df1 = df1.mul(weights, axis=0)\n",
    "    weighted_df2 = df2.mul(weights, axis=0)\n",
    "    raw_matrix = weighted_df1.T.dot(weighted_df2)\n",
    "    row_totals = weighted_df1.sum(axis=0)\n",
    "    percentage_matrix = raw_matrix.div(row_totals, axis=0).mul(100)\n",
    "    \n",
    "    return percentage_matrix\n",
    "\n",
    "# Generate normalized co-occurrence matrices\n",
    "print(\"Generating normalized co-occurrence matrices...\")\n",
    "treatment_variant_matrix_normalized = normalized_co_occurrence_matrix(treatment_df, variant_df, weights)\n",
    "cancer_variant_matrix_normalized = normalized_co_occurrence_matrix(cancer_df, variant_df, weights)\n",
    "treatment_cancer_matrix_normalized = normalized_co_occurrence_matrix(treatment_df, cancer_df, weights)\n",
    "print(\"Normalized co-occurrence matrices generated successfully!\\n\")\n",
    "\n",
    "# Function to apply Fisher's Exact Test and FDR correction\n",
    "def apply_statistical_testing(co_occurrence_matrix):\n",
    "    print(f\"Applying statistical tests to matrix of size {co_occurrence_matrix.shape}...\")\n",
    "    p_values = []\n",
    "    matrix_shape = co_occurrence_matrix.shape\n",
    "    flattened_matrix = co_occurrence_matrix.values.flatten()\n",
    "    total_entries = len(flattened_matrix)\n",
    "    \n",
    "    for i, value in enumerate(tqdm(flattened_matrix, desc=\"Processing statistical tests\", total=total_entries)):\n",
    "        if value > 0:\n",
    "            contingency_table = np.array([[value, np.sum(flattened_matrix) - value], \n",
    "                                          [np.sum(co_occurrence_matrix.sum(axis=1)) - value, np.sum(flattened_matrix)]])\n",
    "            _, p_value = fisher_exact(contingency_table)\n",
    "        else:\n",
    "            p_value = 1.0\n",
    "        p_values.append(p_value)\n",
    "    print(\"Applying Benjamini-Hochberg correction...\")\n",
    "    corrected_p_values = multipletests(p_values, method='fdr_bh')[1]\n",
    "    corrected_p_values_matrix = np.reshape(corrected_p_values, matrix_shape)\n",
    "    return pd.DataFrame(corrected_p_values_matrix, index=co_occurrence_matrix.index, columns=co_occurrence_matrix.columns)\n",
    "\n",
    "treatment_variant_pvalues = apply_statistical_testing(treatment_variant_matrix_normalized)\n",
    "cancer_variant_pvalues = apply_statistical_testing(cancer_variant_matrix_normalized)\n",
    "treatment_cancer_pvalues = apply_statistical_testing(treatment_cancer_matrix_normalized)\n",
    "print(\"Saving results to CSV files...\")\n",
    "\n",
    "treatment_variant_matrix_normalized.to_csv(\"treatment_variant_matrix_normalized.csv\")\n",
    "cancer_variant_matrix_normalized.to_csv(\"cancer_variant_matrix_normalized.csv\")\n",
    "treatment_cancer_matrix_normalized.to_csv(\"treatment_cancer_matrix_normalized.csv\")\n",
    "treatment_variant_pvalues.to_csv(\"treatment_variant_pvalues.csv\")\n",
    "cancer_variant_pvalues.to_csv(\"cancer_variant_pvalues.csv\")\n",
    "treatment_cancer_pvalues.to_csv(\"treatment_cancer_pvalues.csv\")\n",
    "print(\"Results saved successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d89f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 50 heatmaps\n",
    "treatment_variant_matrix = pd.read_csv(\"treatment_variant_matrix_normalized.csv\", index_col=0)\n",
    "cancer_variant_matrix = pd.read_csv(\"cancer_variant_matrix_normalized.csv\", index_col=0)\n",
    "treatment_cancer_matrix = pd.read_csv(\"treatment_cancer_matrix_normalized.csv\", index_col=0)\n",
    "\n",
    "# Function to plot filtered heatmaps\n",
    "def plot_filtered_heatmap(matrix, title, filename, x_label, y_label, threshold=1.0, top_n=50):\n",
    "    filtered_matrix = matrix[matrix > threshold].fillna(0)\n",
    "    row_totals = filtered_matrix.sum(axis=1)\n",
    "    col_totals = filtered_matrix.sum(axis=0)\n",
    "    top_rows = row_totals.nlargest(top_n).index\n",
    "    top_cols = col_totals.nlargest(top_n).index\n",
    "    filtered_matrix = filtered_matrix.loc[top_rows, top_cols]\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(filtered_matrix, cmap=\"coolwarm\", annot=False, linewidths=0.5, cbar=True)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(x_label, fontsize=12)\n",
    "    plt.ylabel(y_label, fontsize=12)\n",
    "    plt.xticks(rotation=45, ha=\"right\", fontsize=7)\n",
    "    plt.yticks(fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Plot heatmaps\n",
    "plot_filtered_heatmap(treatment_variant_matrix, \n",
    "                      \"Treatment-variant co-occurrence\", \n",
    "                      \"filtered_treatment_variant_heatmap.png\", \n",
    "                      \"Variants\", \"Treatments\", \n",
    "                      threshold=1.0, top_n=50)\n",
    "\n",
    "plot_filtered_heatmap(cancer_variant_matrix, \n",
    "                      \"Cancer-variant co-occurrence\", \n",
    "                      \"filtered_cancer_variant_heatmap.png\", \n",
    "                      \"Variants\", \"Cancers\", \n",
    "                      threshold=1.0, top_n=50)\n",
    "\n",
    "plot_filtered_heatmap(treatment_cancer_matrix, \n",
    "                      \"Treatment-cancer co-occurrence\", \n",
    "                      \"filtered_treatment_cancer_heatmap.png\", \n",
    "                      \"Cancers\", \"Treatments\", \n",
    "                      threshold=1.0, top_n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131f012a",
   "metadata": {},
   "source": [
    "# Create focused heatmap for variant-treatment co-associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46a0aea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load CIVIC dataset\n",
    "final_output_filepath = os.path.join(output_directory, \"CIVIC_ncit_df_finalparent_treatmentcategory.csv\")\n",
    "CIVIC_ncit_df_finalparent = pd.read_csv(final_output_filepath)\n",
    "total_rows = len(CIVIC_ncit_df_finalparent)\n",
    "\n",
    "# Terms to exclude\n",
    "treatments_to_exclude = [\n",
    "    \"chemotherapy\", \"immunotherapy\", \"targeted therapy\",\n",
    "    \"radiation therapy\", \"radiation ionizing radiotherapy\", \"folfox regimen\", \"iniparib\",\n",
    "    \"epidermal growth factor receptor tyrosine kinase inhibitor\",\"tyrosine kinase inhibitor\",\n",
    "    \"mitogen-activated protein kinase kinase inhibitor\",\"iodine i-131\",\n",
    "    \"anti-vegf monoclonal antibody\", \"radioactive iodine\",\"egfr tyrosine kinase inhibitor therapy\",\n",
    "    \"aromatase inhibitor\", \"anti-pd-l1 monoclonal antibody\", \"mrna vaccine\", \"pd1 inhibitor\", \n",
    "]\n",
    "treatments_to_exclude = [t.strip().lower() for t in treatments_to_exclude]\n",
    "\n",
    "# Load treatment-variant matrix\n",
    "treatment_variant_matrix = pd.read_csv(\n",
    "    os.path.join(variantscape_directory, \"treatment_variant_matrix_normalized.csv\"),\n",
    "    index_col=0\n",
    ")\n",
    "treatment_variant_matrix.columns = treatment_variant_matrix.columns.str.strip().str.lower()\n",
    "treatment_variant_matrix.index   = treatment_variant_matrix.index.str.strip().str.lower()\n",
    "treatment_variant_matrix = treatment_variant_matrix[\n",
    "    ~treatment_variant_matrix.index.isin(treatments_to_exclude)\n",
    "]\n",
    "\n",
    "df_consensus = pd.read_csv(\n",
    "    os.path.join(variantscape_LLM_coas_directory, \"final_variant_treatment_consensus.csv\")\n",
    ")\n",
    "df_consensus[\"Variant_Treatment_Pair\"] = (\n",
    "    df_consensus[\"Variant_Treatment_Pair\"]\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    ")\n",
    "consensus_dict = dict(\n",
    "    zip(df_consensus[\"Variant_Treatment_Pair\"], df_consensus[\"Resolved_Prediction\"])\n",
    ")\n",
    "\n",
    "# Apply consensus adjustments\n",
    "adjusted_matrix = treatment_variant_matrix.copy().astype(float)\n",
    "print(\"Applying consensus adjustments...\")\n",
    "for treatment, variant in tqdm(\n",
    "    [(t, v) for t in adjusted_matrix.index for v in adjusted_matrix.columns],\n",
    "    desc=\"Consensus Adjustment\",\n",
    "    unit=\"pair\"\n",
    "):\n",
    "    key = f\"{variant} + {treatment}\".strip().lower()\n",
    "    consensus = consensus_dict.get(key, None)\n",
    "\n",
    "    if consensus is None or consensus.lower() == \"no consensus\":\n",
    "        adjusted_matrix.loc[treatment, variant] = np.nan\n",
    "    elif consensus.lower() == \"resistant\":\n",
    "        adjusted_matrix.loc[treatment, variant] = -abs(adjusted_matrix.loc[treatment, variant])\n",
    "    # others (sensitive, diagnostic, unrelated) remain positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43684f92",
   "metadata": {},
   "source": [
    "## Figure 1) Based on strongest positive and negative associations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42dbc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select strongest positive and negative associations\n",
    "flat = adjusted_matrix.unstack().dropna()\n",
    "sorted_flat = flat.sort_values()\n",
    "\n",
    "top_n = 50  # number of strong positive + negative associations\n",
    "top_negative = sorted_flat.head(top_n)\n",
    "top_positive = sorted_flat.tail(top_n)\n",
    "\n",
    "# Combine and reformat for plotting\n",
    "focus_pairs = pd.concat([top_positive, top_negative])\n",
    "focus_df = focus_pairs.reset_index()\n",
    "focus_df.columns = [\"Variant\", \"Treatment\", \"Score\"]\n",
    "\n",
    "# Add manually selected treatments (only top 3 variant associations per treatment)\n",
    "treatments_to_force = [\n",
    "    \"abiraterone\", \"trastuzumab\", \"osimertinib\",\n",
    "    \"erlotinib\", \"gefitinib\", \"crizotinib\", \"dabrafenib/trametinib regimen\", \"dabrafenib\", \"trametinib\",\n",
    "    \"alectinib\", \"ceritinib\", \"vemurafenib\", \"encorafenib\",\n",
    "    \"pembrolizumab\", \"nivolumab\", \"bevacizumab\",\n",
    "]\n",
    "treatments_to_force = [t.lower().strip() for t in treatments_to_force]\n",
    "\n",
    "manual_rows = []\n",
    "for treatment in treatments_to_force:\n",
    "    if treatment in adjusted_matrix.index:\n",
    "        variant_scores = adjusted_matrix.loc[treatment].dropna()\n",
    "        top_variants = variant_scores.reindex(variant_scores.abs().sort_values(ascending=False).index).head(3)\n",
    "        for variant, score in top_variants.items():\n",
    "            manual_rows.append({\"Treatment\": treatment, \"Variant\": variant, \"Score\": score})\n",
    "\n",
    "manual_df = pd.DataFrame(manual_rows)\n",
    "focus_df = pd.concat([focus_df, manual_df], ignore_index=True).drop_duplicates()\n",
    "\n",
    "#### Build the focused matrix\n",
    "top_variants = focus_df[\"Variant\"].unique()\n",
    "forced_variant_set = set(manual_df[\"Variant\"].unique())\n",
    "all_variants = list(pd.Index(top_variants).union(forced_variant_set))\n",
    "all_treatments = list(pd.Index(focus_df[\"Treatment\"].unique()).union(treatments_to_force))\n",
    "all_treatments = [t for t in all_treatments if t in adjusted_matrix.index]\n",
    "focus_matrix = adjusted_matrix.loc[all_treatments, all_variants]\n",
    "\n",
    "# Order rows/columns\n",
    "col_order = focus_df.groupby(\"Variant\")[\"Score\"].mean().sort_values(ascending=False).index\n",
    "row_order = focus_df.groupby(\"Treatment\")[\"Score\"].mean().sort_values(ascending=False).index\n",
    "row_order = pd.Index(row_order.tolist() + [t for t in all_treatments if t not in row_order])\n",
    "focus_matrix = focus_matrix.loc[row_order, col_order]\n",
    "\n",
    "plt.figure(figsize=(18, 14))\n",
    "sns.set(style=\"white\")\n",
    "sns.heatmap(\n",
    "    focus_matrix,\n",
    "    cmap=\"RdYlGn\",\n",
    "    center=0,\n",
    "    linewidths=0.5,  \n",
    "    linecolor=\"lightgray\", \n",
    "    square=False,\n",
    "    cbar_kws={\n",
    "        \"label\": \"Association score\",\n",
    "        \"shrink\": 0.8,\n",
    "        \"orientation\": \"vertical\"\n",
    "    },\n",
    "    mask=focus_matrix.isna()\n",
    ")\n",
    "\n",
    "# Force display of all Y-axis labels\n",
    "plt.yticks(\n",
    "    ticks=np.arange(len(focus_matrix.index)) + 0.5,\n",
    "    labels=focus_matrix.index,\n",
    "    fontsize=9,\n",
    "    rotation=0\n",
    ")\n",
    "\n",
    "# Format rest of the plot\n",
    "cbar = plt.gca().collections[0].colorbar\n",
    "cbar.ax.set_ylabel(\"Association score\", labelpad=-10)\n",
    "cbar.ax.yaxis.label.set_rotation(90)\n",
    "\n",
    "plt.title(\"Variant–treatment associations\", fontsize=18, pad=20)\n",
    "plt.xlabel(\"Variants\", fontsize=14, labelpad=10)\n",
    "plt.ylabel(\"Treatments\", fontsize=14, labelpad=10)\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=9)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "plt.savefig(\"variant_treatment_heatmap_clean.png\", dpi=300)\n",
    "plt.show()\n",
    "print(\"Final treatments shown on Y-axis:\")\n",
    "print(focus_matrix.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcbc135",
   "metadata": {},
   "source": [
    "## Figure 2) Based on strongest positive and negative associations and pre-selected treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dfed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select strongest positive and negative associations\n",
    "flat = adjusted_matrix.unstack().dropna()\n",
    "sorted_flat = flat.sort_values()\n",
    "\n",
    "top_n = 50\n",
    "top_negative = sorted_flat.head(top_n)\n",
    "top_positive = sorted_flat.tail(top_n)\n",
    "\n",
    "# Combine and reformat for plotting\n",
    "focus_pairs = pd.concat([top_positive, top_negative])\n",
    "focus_df = focus_pairs.reset_index()\n",
    "focus_df.columns = [\"Variant\", \"Treatment\", \"Score\"]\n",
    "\n",
    "# Add manually selected treatments (only top 3 variant associations per treatment)\n",
    "treatments_to_force = [\n",
    "    # Targeted therapies\n",
    "    \"trastuzumab\", \"pertuzumab\", \"osimertinib\", \"erlotinib\", \"gefitinib\",\n",
    "    \"crizotinib\", \"alectinib\", \"ceritinib\", \"larotrectinib\", \"entrectinib\",\n",
    "    \"dabrafenib\", \"trametinib\", \"vemurafenib\", \"encorafenib\", \"binimetinib\",\n",
    "    \"imatinib\", \"sunitinib\", \"axitinib\", \"bevacizumab\",\n",
    "\n",
    "    # Immunotherapies\n",
    "    \"pembrolizumab\", \"nivolumab\", \"atezolizumab\", \"durvalumab\", \"ipilimumab\",\n",
    "\n",
    "    # Hormonal therapies\n",
    "    \"tamoxifen\", \"letrozole\", \"anastrozole\", \"exemestane\",\n",
    "    \"abiraterone\", \"enzalutamide\",\n",
    "\n",
    "    # PARP inhibitors\n",
    "    \"olaparib\", \"rucaparib\", \"niraparib\", \"talazoparib\",\n",
    "\n",
    "    # Chemotherapy\n",
    "    \"cisplatin\", \"carboplatin\", \"paclitaxel\", \"docetaxel\",\"dabrafenib/trametinib\",\"dabrafenib\",\"trametinib\"\n",
    "]\n",
    "treatments_to_force = [t.lower().strip() for t in treatments_to_force]\n",
    "\n",
    "manual_rows = []\n",
    "for treatment in treatments_to_force:\n",
    "    if treatment in adjusted_matrix.index:\n",
    "        variant_scores = adjusted_matrix.loc[treatment]\n",
    "        top_variants = variant_scores.reindex(variant_scores.abs().sort_values(ascending=False).index).head(3)\n",
    "        for variant in top_variants.index:\n",
    "            score = variant_scores.get(variant, np.nan)\n",
    "            manual_rows.append({\"Treatment\": treatment, \"Variant\": variant, \"Score\": score})\n",
    "\n",
    "manual_df = pd.DataFrame(manual_rows)\n",
    "focus_df = pd.concat([focus_df, manual_df], ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Build the focused matrix\n",
    "# Variants from top-N plus manual associations\n",
    "top_variants = focus_df[\"Variant\"].unique()\n",
    "forced_variant_set = set(manual_df[\"Variant\"].unique())\n",
    "all_variants = list(pd.Index(top_variants).union(forced_variant_set))\n",
    "\n",
    "# Forced treatments to display\n",
    "all_treatments = list(pd.Index(focus_df[\"Treatment\"].unique()).union(treatments_to_force))\n",
    "all_treatments = [t for t in all_treatments if t in adjusted_matrix.index]\n",
    "\n",
    "focus_matrix = adjusted_matrix.loc[all_treatments, all_variants]\n",
    "focus_matrix = focus_matrix.dropna(axis=1, how='all')\n",
    "col_order = focus_df.groupby(\"Variant\")[\"Score\"].mean().sort_values(ascending=False).index\n",
    "row_order = focus_df.groupby(\"Treatment\")[\"Score\"].mean().sort_values(ascending=False).index\n",
    "row_order = pd.Index(row_order.tolist() + [t for t in all_treatments if t not in row_order])\n",
    "col_order = [v for v in col_order if v in focus_matrix.columns] \n",
    "focus_matrix = focus_matrix.loc[row_order, col_order]\n",
    "\n",
    "treatments_to_drop = [\n",
    "    \"naquotinib\", \"sotrastaurin acetate\", \"uprosertib\", \"rindopepimut\", \n",
    "    \"rilotumumab\",\n",
    "]\n",
    "treatments_to_drop = [t.lower().strip() for t in treatments_to_drop]\n",
    "\n",
    "# Filter out from focus_matrix\n",
    "focus_matrix = focus_matrix[~focus_matrix.index.isin(treatments_to_drop)]\n",
    "row_order = [t for t in row_order if t in focus_matrix.index]\n",
    "focus_matrix = focus_matrix.loc[row_order]\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(18, 14))\n",
    "sns.set(style=\"white\")\n",
    "sns.heatmap(\n",
    "    focus_matrix,\n",
    "    cmap=\"RdYlGn\",\n",
    "    center=0,\n",
    "    linewidths=0.5,\n",
    "    linecolor=\"lightgray\",\n",
    "    square=False,\n",
    "    cbar_kws={\n",
    "        \"label\": \"Association score\",\n",
    "        \"shrink\": 0.8,\n",
    "        \"orientation\": \"vertical\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Y-axis (treatments)\n",
    "plt.yticks(\n",
    "    ticks=np.arange(len(focus_matrix.index)) + 0.5,\n",
    "    labels=focus_matrix.index,\n",
    "    fontsize=8,\n",
    "    rotation=0\n",
    ")\n",
    "\n",
    "# X-axis (variants)\n",
    "plt.xticks(\n",
    "    ticks=np.arange(len(focus_matrix.columns)) + 0.5,\n",
    "    labels=focus_matrix.columns,\n",
    "    fontsize=8,\n",
    "    rotation=45,\n",
    "    ha=\"right\"\n",
    ")\n",
    "cbar = plt.gca().collections[0].colorbar\n",
    "cbar.ax.set_ylabel(\"Association score\", labelpad=-10)\n",
    "cbar.ax.yaxis.label.set_rotation(90)\n",
    "plt.title(\"Variant–treatment associations\", fontsize=18, pad=20)\n",
    "plt.xlabel(\"Variants\", fontsize=14, labelpad=10)\n",
    "plt.ylabel(\"Treatments\", fontsize=14, labelpad=10)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.savefig(\"variant_treatment_heatmap_clean.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e706d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all non-NaN variant–treatment associations\n",
    "# Flatten the matrix and drop NaNs\n",
    "all_associations = focus_matrix.stack().reset_index()\n",
    "all_associations.columns = [\"Treatment\", \"Variant\", \"Score\"]\n",
    "sorted_associations = all_associations.sort_values(by=\"Score\", ascending=False)\n",
    "pd.set_option(\"display.max_rows\", None) \n",
    "print(sorted_associations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a4cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Search by Variant ######\n",
    "# Input: variant name (e.g., \"v600e_braf\")\n",
    "search_variant = \"c797s_EGFR\" #\"g1202r_ALK\" \n",
    "search_variant = search_variant.strip().lower()\n",
    "if search_variant in focus_matrix.columns:\n",
    "    results = focus_matrix[search_variant].dropna().sort_values(ascending=False)\n",
    "    print(f\"\\n Treatments associated with variant '{search_variant}':\\n\")\n",
    "    print(results)\n",
    "else:\n",
    "    print(f\" Variant '{search_variant}' not found in the heatmap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2271d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Search by Treatment  ######\n",
    "search_treatment = \"dabrafenib\"  \n",
    "search_treatment = search_treatment.strip().lower()\n",
    "\n",
    "# Check and print associated variants\n",
    "matches = focus_matrix.loc[focus_matrix.index == search_treatment]\n",
    "\n",
    "if not matches.empty:\n",
    "    if len(matches) > 1:\n",
    "        print(f\"Note: multiple entries found for treatment '{search_treatment}' — showing all.\")\n",
    "    for i, (index, row) in enumerate(matches.iterrows()):\n",
    "        print(f\"\\nEntry {i+1} — Variants associated with treatment '{index}':\\n\")\n",
    "        result = row.dropna().sort_values(ascending=False)\n",
    "        print(result)\n",
    "else:\n",
    "    print(f\"Treatment '{search_treatment}' not found in the heatmap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3346e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top associations for a specific variant of interest\n",
    "variant_of_interest = \"v600e_braf\"\n",
    "if variant_of_interest in focus_matrix.columns:\n",
    "    print(f\"\\n Treatments associated with variant: {variant_of_interest.upper()}\")\n",
    "    variant_scores = focus_matrix[variant_of_interest].dropna().sort_values(ascending=False)\n",
    "    top_positives = variant_scores[variant_scores > 0].head(20)\n",
    "    top_negatives = variant_scores[variant_scores < 0].tail(20)\n",
    "    if not top_positives.empty:\n",
    "        print(\"\\nTop POSITIVE associations:\")\n",
    "        for treatment, score in top_positives.items():\n",
    "            print(f\"{treatment} --> {score:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nNo strong positive associations found.\")\n",
    "\n",
    "    if not top_negatives.empty:\n",
    "        print(\"\\nTop NEGATIVE associations:\")\n",
    "        for treatment, score in top_negatives.items():\n",
    "            print(f\"{treatment} --> {score:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nNo strong negative associations found.\")\n",
    "else:\n",
    "    print(f\"\\nVariant {variant_of_interest.upper()} not found in heatmap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6555f35d",
   "metadata": {},
   "source": [
    "# ====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25696447",
   "metadata": {},
   "source": [
    "# Create dot plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cancer-variant matrix\n",
    "matrix_path = os.path.join(variantscape_directory, \"cancer_variant_matrix_normalized.csv\")\n",
    "cancer_variant_matrix = pd.read_csv(matrix_path, index_col=0)\n",
    "cancer_variant_matrix.index = cancer_variant_matrix.index.str.strip().str.lower()\n",
    "cancer_variant_matrix.columns = cancer_variant_matrix.columns.str.strip().str.lower()\n",
    "\n",
    "# Define cancers and get top 5 strongest variants per cancer (skip \"v600\")\n",
    "target_cancers = ['lung cancer', 'breast cancer', 'colon cancer', 'prostate cancer', 'melanoma']\n",
    "top_rows = []\n",
    "for cancer in target_cancers:\n",
    "    row = cancer_variant_matrix.loc[cancer]\n",
    "    sorted_row = row.reindex(row.abs().sort_values(ascending=False).index)\n",
    "\n",
    "    picked = 0\n",
    "    for variant, score in sorted_row.items():\n",
    "        if variant == \"v600\" or (variant.startswith(\"v600_\") and variant.count(\"_\") == 1):\n",
    "            continue\n",
    "        top_rows.append({\n",
    "            \"Cancer\": cancer,\n",
    "            \"Variant\": variant,\n",
    "            \"Score\": score\n",
    "        })\n",
    "        picked += 1\n",
    "        if picked == 5:\n",
    "            break\n",
    "top_df = pd.DataFrame(top_rows)\n",
    "\n",
    "# Print top 5 table\n",
    "print(\"\\nTop 5 strongest variant associations per cancer:\\n\")\n",
    "for cancer in target_cancers:\n",
    "    subset = top_df[top_df[\"Cancer\"] == cancer]\n",
    "    print(f\"--- {cancer.upper()} ---\")\n",
    "    print(subset[[\"Variant\", \"Score\"]].to_string(index=False))\n",
    "    print()\n",
    "\n",
    "# Dot plot with bubble legend\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "dot_plot = sns.scatterplot(\n",
    "    data=top_df,\n",
    "    x=\"Variant\",\n",
    "    y=\"Cancer\",\n",
    "    size=np.abs(top_df[\"Score\"]),\n",
    "    hue=top_df[\"Score\"],\n",
    "    palette=\"Blues\",\n",
    "    sizes=(50, 400),\n",
    "    edgecolor=\"black\",\n",
    "    legend=\"brief\"\n",
    ")\n",
    "\n",
    "plt.title(\"Top variant associations by cancer\", fontsize=16)\n",
    "plt.xlabel(\"Variant\", fontsize=12)\n",
    "plt.ylabel(\"Cancer\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "unique = list(dict(zip(labels, handles)).items())\n",
    "filtered_handles = [h for l, h in unique if l.replace('.', '', 1).isdigit()]\n",
    "filtered_labels = [l for l in labels if l.replace('.', '', 1).isdigit()]\n",
    "plt.legend(\n",
    "    filtered_handles,\n",
    "    filtered_labels,\n",
    "    title=\"Weighted co-occurrence (%)\",\n",
    "    loc='upper left',\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    borderaxespad=0.,\n",
    "    labelspacing=1.2,\n",
    "    frameon=True\n",
    ")\n",
    "plt.savefig(\"top_variant_dotplot.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee9c91",
   "metadata": {},
   "source": [
    "# ======================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5b5e8",
   "metadata": {},
   "source": [
    "# Calculate statistically significant co-associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead2a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_filtered_matrix_as_csv(matrix, csv_filename, threshold=1.0, top_n=50):\n",
    "    \"\"\"\n",
    "    Filters the matrix and saves the filtered result to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - matrix (pd.DataFrame): The original matrix to filter.\n",
    "    - csv_filename (str): The name of the CSV file to save the filtered matrix.\n",
    "    - threshold (float): The minimum value threshold for filtering. Default is 1.0.\n",
    "    - top_n (int): The number of top rows and columns to keep based on totals. Default is 50.\n",
    "    \"\"\"\n",
    "    # Filter the matrix to only keep high-value associations\n",
    "    filtered_matrix = matrix[matrix > threshold].fillna(0)\n",
    "    row_totals = filtered_matrix.sum(axis=1)\n",
    "    col_totals = filtered_matrix.sum(axis=0)\n",
    "    top_rows = row_totals.nlargest(top_n).index\n",
    "    top_cols = col_totals.nlargest(top_n).index\n",
    "    filtered_matrix = filtered_matrix.loc[top_rows, top_cols]\n",
    "    filtered_matrix.to_csv(csv_filename)\n",
    "    print(f\"Filtered matrix saved to {csv_filename}\")\n",
    "    \n",
    "save_filtered_matrix_as_csv(treatment_variant_matrix, \n",
    "                        \"filtered_treatment_variant_matrix.csv\", \n",
    "                        threshold=1.0, top_n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef986a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Treatment x Cancer and Cancer x Variant matrices\n",
    "treatment_cancer_matrix = pd.read_csv(\"treatment_cancer_matrix_normalized.csv\", index_col=0)\n",
    "cancer_variant_matrix = pd.read_csv(\"cancer_variant_matrix_normalized.csv\", index_col=0)\n",
    "\n",
    "# Identify top associations for Treatment x Cancer matrix\n",
    "top_treatment_cancer = treatment_cancer_matrix.unstack().sort_values(ascending=False).head(50)\n",
    "top_treatment_cancer_df = top_treatment_cancer.reset_index()\n",
    "top_treatment_cancer_df.columns = ['Cancer', 'Treatment', 'Association Value']\n",
    "\n",
    "# Identify top associations for Cancer x Variant matrix\n",
    "top_cancer_variant = cancer_variant_matrix.unstack().sort_values(ascending=False).head(10)\n",
    "top_cancer_variant_df = top_cancer_variant.reset_index()\n",
    "top_cancer_variant_df.columns = ['Variant', 'Cancer', 'Association Value']\n",
    "\n",
    "print(\"\\nTop Associations - Treatment x Cancer:\")\n",
    "print(top_treatment_cancer_df)\n",
    "print(\"\\nTop Associations - Cancer x Variant:\")\n",
    "print(top_cancer_variant_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db12430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate significant associations \n",
    "treatment_variant_pvalues = pd.read_csv(\"treatment_variant_pvalues.csv\", index_col=0)\n",
    "total_associations = treatment_variant_pvalues.size\n",
    "\n",
    "# Identify significant associations\n",
    "SIGNIFICANCE_THRESHOLD = 0.05\n",
    "significant_results = treatment_variant_pvalues[treatment_variant_pvalues <= SIGNIFICANCE_THRESHOLD].stack().reset_index()\n",
    "significant_results.columns = ['Treatment', 'Variant', 'Corrected_p_value']\n",
    "num_significant = significant_results.shape[0]\n",
    "percentage_significant = (num_significant / total_associations) * 100\n",
    "\n",
    "print(\"\\nStatistical Significance Analysis Summary:\\n\")\n",
    "print(f\"{'Total Associations':<45} {total_associations:>15,}\")\n",
    "print(f\"{'Significant Associations (p < 0.05)':<45} {num_significant:>15,}\")\n",
    "print(f\"{'Percentage of Significant Associations (%)':<45} {percentage_significant:>15.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
