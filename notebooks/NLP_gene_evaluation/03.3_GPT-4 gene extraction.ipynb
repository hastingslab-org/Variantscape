{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbdd887b",
   "metadata": {},
   "source": [
    "# Use LLM (GPT-4) for gene extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83670bcd",
   "metadata": {},
   "source": [
    "# 1) Set up libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e0639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d977552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genes import successful!\n",
      "Loaded 2128318 articles from CSV.\n",
      "Article import successful!\n",
      "\n",
      "Imported 100 articles with 9 selected columns.\n",
      "Imported 161 oncomine genes.\n",
      "\n",
      "Current Working Directory: /data/JH/marie/TrendyVariants/ICIMTH\n"
     ]
    }
   ],
   "source": [
    "# Set the working directory and file paths\n",
    "working_directory = \"/data/JH/marie/TrendyVariants/ICIMTH\"\n",
    "input_directory = \"/data/JH/marie/TrendyVariants/Input\"\n",
    "output_directory = \"/data/JH/marie/TrendyVariants/Output\"\n",
    "articles_file = \"clean_df_step4.csv\" # We want to analyze the dataset after cleaning!\n",
    "genes_file = \"oncomine_ngs_panel.csv\"\n",
    "\n",
    "#Load OncoMine genes file\n",
    "os.chdir(input_directory)\n",
    "genes = pd.read_csv(genes_file, header=None)\n",
    "gene_list = genes[0].tolist()\n",
    "print(\"Genes import successful!\")\n",
    "\n",
    "# Load the articles file\n",
    "os.chdir(output_directory)\n",
    "if \"full_articles\" not in globals():\n",
    "    full_articles = pd.read_csv(articles_file)\n",
    "    print(f\"Loaded {len(full_articles)} articles from CSV.\")\n",
    "else:\n",
    "    print(\"Using preloaded full_articles from memory.\")\n",
    "articles = full_articles.head(100)\n",
    "print(\"Article import successful!\")\n",
    "print(f\"\\nImported {len(articles):,} articles with {len(articles.columns):,} selected columns.\")\n",
    "print(f\"Imported {len(gene_list):,} oncomine genes.\")\n",
    "\n",
    "# Get the number of rows and columns\n",
    "num_rows = articles.shape[0]\n",
    "num_columns = articles.shape[1]\n",
    "os.chdir(working_directory)\n",
    "print(\"\\nCurrent Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a1e27",
   "metadata": {},
   "source": [
    "# 2) Select and set up LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75357b29",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: OpenAI in /data/JH/miniconda3/envs/py/lib/python3.11/site-packages (1.61.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /data/JH/miniconda3/envs/py/lib/python3.11/site-packages (from OpenAI) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /data/JH/miniconda3/envs/py/lib/python3.11/site-packages (from OpenAI) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /data/JH/miniconda3/envs/py/lib/python3.11/site-packages (from OpenAI) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /data/JH/miniconda3/envs/py/lib/python3.11/site-packages (from OpenAI) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /data/JH/miniconda3/envs/py/lib/python3.11/site-packages (from OpenAI) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /data/JH/miniconda3/envs/py/lib/python3.11/site-packages (from OpenAI) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /data/JH/miniconda3/envs/py/lib/python3.11/site-packages (from OpenAI) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /data/JH/miniconda3/envs/py/lib/python3.11/site-packages (from OpenAI) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/janna/.local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->OpenAI) (3.4)\n",
      "Requirement already satisfied: certifi in /home/janna/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->OpenAI) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in /data/JH/miniconda3/envs/py/lib/python3.11/site-packages (from httpx<1,>=0.23.0->OpenAI) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /data/JH/miniconda3/envs/py/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->OpenAI) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /data/JH/miniconda3/envs/py/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->OpenAI) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /data/JH/miniconda3/envs/py/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->OpenAI) (2.27.2)\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Set up a language model to answer the questions\n",
    "!pip install OpenAI\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from openai import OpenAI\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13ccd919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the models to be tested\n",
    "models = [\"llama31-70b\", \"llama33-70b\", \"deepseek_v3\", \n",
    "          \"deepseek_r1\", \"deepseek_r1_distill_llama_70b\",\"gpt4o\"]\n",
    "\n",
    "# Mapping model names to their full Hugging Face or DeepInfra identifiers\n",
    "model_fullnames = {\n",
    "    \"llama31-70b\": \"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "    \"llama33-70b\": \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    \"deepseek_v3\": \"deepseek-ai/DeepSeek-V3\",\n",
    "    \"deepseek_r1\": \"deepseek-ai/DeepSeek-R1\",\n",
    "    \"deepseek_r1_distill_llama_70b\": \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\",\n",
    "    \"gpt4o\": \"gpt-4o\"\n",
    "}\n",
    "\n",
    "SYSTEM_MSG = \"You are a helpful medical question answering assistant. Please carefully follow the exact instructions and do not provide explanations.\"\n",
    "modelname = models[5] #in Python, list indexing starts from 0, not 1.\n",
    "\n",
    "if modelname in [ \"llama2-3b\" ]:  # Local model\n",
    "    model, tokenizer = load(model_fullnames[modelname])\n",
    "    def generateFromPrompt(prompt):\n",
    "        if hasattr(tokenizer, \"apply_chat_template\") and tokenizer.chat_template is not None:\n",
    "            messages = [{\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "                {\"role\": \"user\", \"content\": prompt}]\n",
    "            prompt = tokenizer.apply_chat_template(\n",
    "                messages, tokenize=False, add_generation_prompt=True\n",
    "            )\n",
    "            response = generate(model, tokenizer, prompt=prompt, verbose=False)\n",
    "            return response\n",
    "elif modelname in [ \"gpt35\", \"gpt4o\" ]: # OpenAI models\n",
    "    client = OpenAI(\n",
    "       api_key='API_key1'  \n",
    "    )\n",
    "    def generateFromPrompt(promptStr,maxTokens=100):\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": promptStr}\n",
    "      ]\n",
    "      completion = client.chat.completions.create(\n",
    "        model=model_fullnames[modelname],\n",
    "        messages=messages)\n",
    "      response=completion.choices[0].message.content\n",
    "      return(response)\n",
    "elif modelname in [ \"llama31-70b\" , \"llama33-70b\" , \"deepseek_v3\" , \"deepseek_r1\" , \"deepseek_r1_distill_llama_70b\"]:  # DeepInfra models\n",
    "    client = OpenAI(\n",
    "        api_key = \"API_key2\",\n",
    "        base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    "    )\n",
    "    def generateFromPrompt(promptStr,maxTokens=100):\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": promptStr}\n",
    "      ]\n",
    "      completion = client.chat.completions.create(\n",
    "        model=model_fullnames[modelname],\n",
    "        messages=messages)\n",
    "      response=completion.choices[0].message.content\n",
    "      return(response)\n",
    "    \n",
    "generateFromPrompt(\"hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8977f275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All installed models: ['llama31-70b', 'llama33-70b', 'deepseek_v3', 'deepseek_r1', 'deepseek_r1_distill_llama_70b', 'gpt4o']\n",
      "Current model in use: gpt4o\n"
     ]
    }
   ],
   "source": [
    "print(\"All installed models:\",   models)\n",
    "print(\"Current model in use:\",   modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cb678e",
   "metadata": {},
   "source": [
    "# 3) Define prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecfe876d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts for gene extraction successfully defined!\n"
     ]
    }
   ],
   "source": [
    "# Define multiple prompts in a dictionary\n",
    "# The model will extract genes and gene products, filtering against `gene_list`\n",
    "# Use prompt #1\n",
    "\n",
    "\n",
    "PROMPTS = {\n",
    "    1: lambda title, abstract: (\n",
    "        f\"Extract all gene names and their gene products (e.g., TP53 and p53) from the given title and abstract.\"\n",
    "        f\"Only return genes that are present in the following predefined list:\\n\"\n",
    "        f\"{', '.join(gene_list)}.\\n\"\n",
    "        f\"If a gene is mentioned multiple times, only list it once.\\n\"\n",
    "        f\"Return the extracted genes as a **comma-separated list** (e.g., 'CTNNB1, RET, BRCA1').\\n\"\n",
    "        f\"If no genes from the list are present, return an **empty response** (do not return 'None' or 'No genes found').\\n\"\n",
    "        f\"Strictly **no additional information, no explanations, no formatting**.\\n\\n\"\n",
    "        f\"Title: {title}\\nAbstract: {abstract}\"\n",
    "    ),\n",
    "\n",
    "    2: lambda title, abstract: (\n",
    "        f\"Identify all gene symbols and their corresponding gene products mentioned in the given title and abstract.\\n\"\n",
    "        f\"Only include genes that exist in the predefined list:\\n\"\n",
    "        f\"{', '.join(gene_list)}.\\n\"\n",
    "        f\"Return the result as a simple **comma-separated list** (e.g., 'BRCA1, TP53, EGFR').\\n\"\n",
    "        f\"If no matching genes are found, return **an empty response** (do not print anything).\\n\"\n",
    "        f\"Ensure strict compliance:\\n\"\n",
    "        f\"- Do not include extra text or explanations.\\n\"\n",
    "        f\"- No formatting, no bullet points, no sentence structure.\\n\\n\"\n",
    "        f\"Title: {title}\\nAbstract: {abstract}\"\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"Prompts for gene extraction successfully defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ca54d",
   "metadata": {},
   "source": [
    "# 4) Run genetic variant extraction with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc298f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! All necessary files and directories are set up.\n",
      "Script Start Time: 2025-03-10 12:52:58\n",
      "Defined prompt number: 2\n",
      "Defined batch size: 101\n",
      "Functions defined!\n"
     ]
    }
   ],
   "source": [
    "# ========================== CONFIGURATION ========================== #\n",
    "# Define output directory\n",
    "os.chdir(working_directory)\n",
    "\n",
    "# Ensure tqdm progress bar works with pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Define batch size for processing\n",
    "BATCH_SIZE = 101\n",
    "\n",
    "# Set model name and prompt selection\n",
    "modelname = modelname\n",
    "selected_prompt_number = 2  # Change dynamically as needed\n",
    "\n",
    "# Get today's date and current time\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "start_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')  # Includes date and time\n",
    "\n",
    "# ========================== FILE PATHS USING ============================ #\n",
    "variant_output_file_path = os.path.join(working_directory, f\"ICIMTH_LLM_variant_extraction_{modelname}_prompt{selected_prompt_number}.csv\")\n",
    "runtime_file = os.path.join(working_directory, f\"ICIMTH_runtime_summary_{modelname}_prompt{selected_prompt_number}.txt\")\n",
    "progress_log_file = os.path.join(working_directory, f\"ICIMTH_progress_log_{modelname}_prompt{selected_prompt_number}.txt\")\n",
    "\n",
    "# ========================== ENSURE FILES EXIST ========================== #\n",
    "def ensure_file_exists(file_path, header_text=None):\n",
    "    \"\"\"Creates the file if it does not exist and optionally writes a header.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        with open(file_path, \"w\") as f:\n",
    "            if header_text:\n",
    "                f.write(f\"{header_text}\\n\")\n",
    "                f.write(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "ensure_file_exists(runtime_file, f\"### Runtime Log - {today_date} ###\\nStart Time: {start_time_str}\")\n",
    "ensure_file_exists(progress_log_file, f\"### Progress Log - {today_date} ###\")\n",
    "\n",
    "if not os.path.exists(variant_output_file_path):\n",
    "    with open(variant_output_file_path, \"w\") as f:\n",
    "        f.write(\"PaperId,PaperTitle,Abstract,LLM_Prompt,LLM_Response\\n\")\n",
    "\n",
    "# ========================== LOGGING SETUP ========================== #\n",
    "logging.basicConfig(\n",
    "    filename=progress_log_file,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "print(\"Success! All necessary files and directories are set up.\")\n",
    "print(\"Script Start Time:\", start_time_str)\n",
    "print(\"Defined prompt number:\", selected_prompt_number)\n",
    "print(\"Defined batch size:\", BATCH_SIZE)\n",
    "\n",
    "# ========================== FUNCTION DEFINITIONS ========================== #\n",
    "\n",
    "def screen_publication_for_variants(row, prompt_number):\n",
    "    \"\"\"Generates a dynamic prompt based on the selected prompt number.\"\"\"\n",
    "    title = row['PaperTitle']\n",
    "    abstract = row['Abstract']\n",
    "    \n",
    "    # Validate the prompt number\n",
    "    if prompt_number not in PROMPTS:\n",
    "        raise ValueError(f\"Invalid prompt number: {prompt_number}. Choose between 0-5.\")\n",
    "\n",
    "    # Dynamically apply the correct prompt from `PROMPTS`\n",
    "    return PROMPTS[prompt_number](title, abstract)\n",
    "\n",
    "def process_with_llm(prompt):\n",
    "    \"\"\"Process the given prompt using the LLM model.\"\"\"\n",
    "    try:\n",
    "        response = generateFromPrompt(prompt)  # Replace this with actual LLM function\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        logging.error(f\"LLM processing error: {e}\")\n",
    "        return \"ERROR\"\n",
    "\n",
    "print(\"Functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "470b4e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from last processed row. 0 articles completed so far.\n",
      "Success! All necessary files and directories are set up.\n",
      "Defined prompt number: 2\n",
      "Defined batch size to run in chunks: 101\n",
      "Total unprocessed articles: 100\n"
     ]
    }
   ],
   "source": [
    "# ========================== RESUME FROM LAST CHECKPOINT ========================== #\n",
    "\n",
    "# Load cancer dataset (ensure it's already loaded in memory)\n",
    "if 'articles' not in globals():\n",
    "    raise ValueError(\"Dataset `articles` is not loaded in memory. Make sure it's defined before running the script.\")\n",
    "\n",
    "# Ensure 'PaperId' column exists for tracking progress\n",
    "if 'PaperId' not in articles.columns:\n",
    "    raise KeyError(\"Dataset must contain a 'PaperId' column to track progress.\")\n",
    "\n",
    "# Check if output file exists and count previously processed articles\n",
    "if os.path.exists(variant_output_file_path):\n",
    "    processed_df = pd.read_csv(variant_output_file_path)\n",
    "    processed_articles = set(processed_df['PaperId'])  # Track completed articles\n",
    "    total_processed_articles = len(processed_articles)  # Total processed so far\n",
    "    print(f\"Resuming from last processed row. {total_processed_articles} articles completed so far.\")\n",
    "else:\n",
    "    processed_articles = set()\n",
    "    total_processed_articles = 0\n",
    "    print(\"Starting fresh processing.\")\n",
    "\n",
    "# Calculate total batches\n",
    "total_batches = (len(articles) // BATCH_SIZE) + (1 if len(articles) % BATCH_SIZE != 0 else 0)\n",
    "\n",
    "# If all articles are processed, print a final message and stop execution\n",
    "if total_processed_articles == len(articles):\n",
    "    print(\"\\nAll batches are complete. No more articles to process.\")\n",
    "    print(\"You have successfully processed the entire dataset.\")\n",
    "    \n",
    "    try:\n",
    "        sys.exit(0)  #Exit normally\n",
    "    except SystemExit:\n",
    "        pass  #Suppress the SystemExit message in Jupyter\n",
    "\n",
    "\n",
    "# Filter only unprocessed articles\n",
    "unprocessed_df = articles[~articles['PaperId'].isin(processed_articles)]\n",
    "total_articles = len(unprocessed_df)    \n",
    "    \n",
    "print(\"Success! All necessary files and directories are set up.\")\n",
    "print(\"Defined prompt number:\", selected_prompt_number)\n",
    "print(\"Defined batch size to run in chunks:\", BATCH_SIZE)\n",
    "print(f\"Total unprocessed articles: {total_articles}\")\n",
    "\n",
    "# ========================== TRACK CUMULATIVE RUNTIME ========================== #\n",
    "# Load previous runtime if exists\n",
    "if os.path.exists(runtime_file):\n",
    "    with open(runtime_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        total_runtime_previous = sum(float(line.split(\":\")[-1].strip().split()[0])\n",
    "                                     for line in lines if \"Total runtime so far\" in line)\n",
    "else:\n",
    "    total_runtime_previous = 0.0  # Start fresh if no file exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46c72a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Batch 1/1 (1 to 100)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:07<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All articles have been successfully processed.\n",
      "No more articles remaining.\n",
      "\n",
      "### Genetic Variant Extraction Summary ###\n",
      "\n",
      "- Model used: gpt4o\n",
      "- Prompt number: 2\n",
      "- Total batches processed: 1/1\n",
      "- Total rows processed: 100\n",
      "- Cumulative runtime: 67.68 seconds (0 hr 1 min 7.68 sec)\n",
      "\n",
      "Final results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================== BATCH PROCESSING ========================== #\n",
    "start_time = time.time()\n",
    "os.chdir(working_directory)\n",
    "\n",
    "# Calculate the next batch number\n",
    "batch_number = (total_processed_articles // BATCH_SIZE) + 1\n",
    "\n",
    "for batch_start in range(0, total_articles, BATCH_SIZE):\n",
    "    batch_end = min(batch_start + BATCH_SIZE, total_articles)\n",
    "    batch = unprocessed_df.iloc[batch_start:batch_end].copy()\n",
    "\n",
    "    print(f\"\\nProcessing Batch {batch_number}/{total_batches} ({batch_start + 1} to {batch_end})...\")\n",
    "\n",
    "    batch_start_time = time.time()\n",
    "\n",
    "    # Generate prompts dynamically\n",
    "    batch['LLM_Prompt'] = batch.apply(lambda row: screen_publication_for_variants(row, selected_prompt_number), axis=1)\n",
    "\n",
    "    # Process with LLM\n",
    "    llm_response_column = f'LLM_Response_{modelname}'\n",
    "    batch[llm_response_column] = batch['LLM_Prompt'].progress_apply(process_with_llm)\n",
    "\n",
    "    batch_runtime = time.time() - batch_start_time\n",
    "\n",
    "    # Keep only required columns before saving to CSV\n",
    "    batch_to_save = batch[['PaperId', 'PaperTitle', 'Abstract', 'LLM_Prompt', llm_response_column]]\n",
    "\n",
    "    # Calculate total progress\n",
    "    def generate_progress_bar(percentage, bar_length=20):\n",
    "        filled_length = int(bar_length * percentage / 100)\n",
    "        bar = '|' * filled_length + '-' * (bar_length - filled_length)\n",
    "        return f\"[{bar}] {percentage:.2f}%\"\n",
    "\n",
    "    total_articles = batch_end + len(processed_articles)  # Updated for total count\n",
    "    total_articles_to_process = len(unprocessed_df) - batch_end  # Remaining articles\n",
    "    processed_percentage = (total_articles / len(articles)) * 100\n",
    "    to_process_percentage = (total_articles_to_process / len(articles)) * 100\n",
    "\n",
    "    # Save progress to CSV\n",
    "    if os.path.exists(variant_output_file_path):\n",
    "        batch_to_save.to_csv(variant_output_file_path, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        batch_to_save.to_csv(variant_output_file_path, mode='w', index=False)\n",
    "\n",
    "    total_runtime_so_far = total_runtime_previous + (time.time() - start_time)\n",
    "\n",
    "    with open(runtime_file, \"a\") as f:\n",
    "        f.write(f\"\\nBatch {batch_number}/{total_batches} started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Batch Runtime: {batch_runtime:.2f} sec\\n\")\n",
    "        f.write(f\"Total runtime so far (all runs combined): {total_runtime_so_far:.2f} sec\\n\")\n",
    "        f.write(f\"Total articles processed in this batch: {batch_end}\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "    logging.info(f\"Processed batch {batch_number}/{total_batches} in {batch_runtime:.2f} sec.\")\n",
    "\n",
    "    # If 100% processed, show final message\n",
    "    if processed_percentage >= 100:\n",
    "        print(\"\\nAll articles have been successfully processed.\")\n",
    "        print(\"No more articles remaining.\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"\\nPaused! {batch_end} articles processed in this batch.\")\n",
    "        print(f\"{total_articles} articles processed in total {generate_progress_bar(processed_percentage)}\")\n",
    "        print(f\"{total_articles_to_process} articles to process in total {generate_progress_bar(to_process_percentage)}\")\n",
    "        print(\"Check the CSV and runtime file. When ready, rerun the script to continue processing.\")\n",
    "        break  # Stops execution after the first batch; re-run script to continue\n",
    "\n",
    "# ========================== FINAL SUMMARY ========================== #\n",
    "total_runtime = total_runtime_so_far\n",
    "total_hours = total_runtime // 3600\n",
    "total_minutes = (total_runtime % 3600) // 60\n",
    "total_seconds = total_runtime % 60\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "### Genetic Variant Extraction Summary ###\n",
    "\n",
    "- Model used: {modelname}\n",
    "- Prompt number: {selected_prompt_number}\n",
    "- Total batches processed: {batch_number}/{total_batches}\n",
    "- Total rows processed: {total_articles}\n",
    "- Cumulative runtime: {total_runtime:.2f} seconds ({total_hours:.0f} hr {total_minutes:.0f} min {total_seconds:.2f} sec)\n",
    "\"\"\"\n",
    "\n",
    "print(summary_text)\n",
    "\n",
    "# Save final runtime summary\n",
    "with open(runtime_file, \"a\") as f:\n",
    "    f.write(\"\\n### Final runtime summary ###\\n\")\n",
    "    f.write(f\"End Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(summary_text)\n",
    "    f.write(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "print(\"Final results saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd4dd3f",
   "metadata": {},
   "source": [
    "# **RERUN \"FROM LAST CHECKPOINT**\" to continue batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6050617",
   "metadata": {},
   "source": [
    "# Make binary matrix for gene identification evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cf6eff4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final DataFrame Preview:\n",
      "       PaperId                                         PaperTitle  \\\n",
      "0   4405900941  Oncological outcomes following extreme oncopla...   \n",
      "1   4405941037  Regarding: Alpha1 antitrypsin deficiency assoc...   \n",
      "2   4405952152  Incidence and risk factors of immune checkpoin...   \n",
      "3   4405971509  Pedicle ossification following mandibular reco...   \n",
      "4   4406120665  Artificial Intelligence for Autonomous Robotic...   \n",
      "5   4406120699  The Necessity of Human Papillomavirus Vaccinat...   \n",
      "6   4393515872          Jagodinsky et al 2023 bulk RNA-seq counts   \n",
      "7   4403620280  Two cases of pancreatic tuberculosis in immuno...   \n",
      "8   4405796123  Successful repositioning of mertansine for imp...   \n",
      "9   4405900528  Tissue Prior to the Initial Hematoxylin-Eosin ...   \n",
      "10  4405900803  Detection of urine circulating tumor DNA using...   \n",
      "11  4405900916  A qualitative study of the perioperative exerc...   \n",
      "12  4405900978  In vitro characterization of some of the anti-...   \n",
      "13  4405901040  Evaluation of a Novel PLGA-HA-Based Drug Deliv...   \n",
      "14  4405901211  Lobectomia heptica parcial em cadela da raa Bo...   \n",
      "15  4405902311  The multifaceted roles of cathepsins in immune...   \n",
      "16  4405902345  adrenergic signaling blockade attenuates metas...   \n",
      "17  4405902894  Evaluation of quality measures for Colonoscopy...   \n",
      "18  4405903767  Advances on the role of stem cells in liver ca...   \n",
      "19  4405903781  A case series of VATS intrapericardial pneumon...   \n",
      "20  4405903794  Network Pharmacology and Molecular Docking Stu...   \n",
      "21  4405904339     Nanomedicine in cancer treatment - an overview   \n",
      "22  4405904853  A deep learning based smartphone application f...   \n",
      "23  4405905363  Reduced irradiation exposure areas enhanced an...   \n",
      "24  4405917763  Combination of Compound Kushen injection with ...   \n",
      "25  4405918022  Methods for synthesizing hydroxamic acids and ...   \n",
      "26  4405918062  Laparoscopic adrenalectomy in children with di...   \n",
      "27  4405918103  Impact of Neurotoxicity and Steroid Therapy on...   \n",
      "28  4405918224  Calpain 2 promotes Lenvatinib resistance and c...   \n",
      "29  4405918268  Evaluating the Impact of Immunotherapy on Long...   \n",
      "30  4405919266  Recent progress in prompt molecular detection ...   \n",
      "31  4405919315  Altered chromatin landscape and 3D interaction...   \n",
      "32  4405919316  Metabolomic profile and its association with t...   \n",
      "33  4405919741  Belzutifan as the Primary Treatment of Bilater...   \n",
      "34  4405919743  Ultra-High Dose Rate Helium Ion Beams: Minimiz...   \n",
      "35  4405919948  Gasdermin D regulates the activation of EGFR i...   \n",
      "36  4405920054  General medical comorbidities in psychotic dis...   \n",
      "37  4405920141  Diagnosis of primary meningeal natural killer/...   \n",
      "38  4405920279  Effects of Lipid Headgroups on the Mechanical ...   \n",
      "39  4405920724  Evaluation of general characteristics of adole...   \n",
      "40  4405920880  Risk of cancer and reoperation after ileorecta...   \n",
      "41  4405920991  Validation of a simplified HPV genotyping assa...   \n",
      "42  4405921012  International Cancer Burden Analysis 2020-2024...   \n",
      "43  4405921028  Comparative Analysis of Cosmetic and Functiona...   \n",
      "44  4405921118  Anamnestic and anthropometric features in chil...   \n",
      "45  4405921128  10 years of experience in providing surgical c...   \n",
      "46  4405921140  Influence of comorbidity on infectious complic...   \n",
      "47  4405921152  Radiological Assessment and Therapeutic Evalua...   \n",
      "48  4405921165  Calcitonin level in the blood of patients with...   \n",
      "49  4405921169  Possibilities of immunohistochemical markers H...   \n",
      "\n",
      "                                             Abstract  \\\n",
      "0   Locally advanced breast cancer (LABC) accounts...   \n",
      "1   Dear Editor, We would like to congratulate Kor...   \n",
      "2   Immune checkpoint inhibitors (ICIs) are effect...   \n",
      "3   Pedicle ossification is a rare but significant...   \n",
      "4   Artificial intelligence (AI) has emerged as a ...   \n",
      "5   Anogenital wart caused by human papillomavirus...   \n",
      "6   On day 3 following BT, tumors were collected a...   \n",
      "7   Mycobacterium tuberculosis (TB) disease is a m...   \n",
      "8   Mertansine (DM1), a potent tumor-killing mayta...   \n",
      "9   Small biopsies are used for histologic, immuno...   \n",
      "10  Aim: This study aims to evaluate the feasibili...   \n",
      "11  Objective: To understand the needs and charact...   \n",
      "12  Worldwide, gastric cancer is considered to be ...   \n",
      "13  Colorectal carcinoma (CRC) is a very important...   \n",
      "14  Hepatocellular carcinoma is the most common li...   \n",
      "15  The cathepsin family comprises lysosomal prote...   \n",
      "16  adrenergic signaling has been suggested to pro...   \n",
      "17  Background: In Lao PDR, colorectal cancer (CRC...   \n",
      "18  Liver cancer, especially hepatocellular carcin...   \n",
      "19  Intrapericardial pneumonectomy is a complex pr...   \n",
      "20  Strychni Semen, characterized by its bitter ta...   \n",
      "21  Cancer remains a formidable global health chal...   \n",
      "22  Nasal endoscopy is crucial for the early detec...   \n",
      "23  Partial stereotactic body radiation therapy (S...   \n",
      "24  The treatment of advanced colorectal cancer (C...   \n",
      "25  In previously published works, the antibacteri...   \n",
      "26  Objectives The aim of this study was to assess...   \n",
      "27  Background Immune effector cell-associated neu...   \n",
      "28  Lenvatinib, an approved first-line regimen, ha...   \n",
      "29  Lung cancer is a leading cause of cancer morta...   \n",
      "30  Creating fast, non-invasive, precise, and spec...   \n",
      "31  Lynch syndrome (LS), characterised by an incre...   \n",
      "32  Objective To determine the association of a me...   \n",
      "33  Purpose: To describe the efficacy of belzutifa...   \n",
      "34  Ultra-high dose rate radiotherapy with electro...   \n",
      "35  Gasdermin D (GSDMD) is a key effector molecule...   \n",
      "36  Schizophrenia (SZ), schizoaffective disorder (...   \n",
      "37  Primary central nervous system (CNS) lymphoma ...   \n",
      "38  We performed all-atom and coarse-grained simul...   \n",
      "39  Objective: To evaluate the general characteris...   \n",
      "40  Objectives: To prevent colorectal cancer (CRC)...   \n",
      "41  Human papillomavirus (HPV) genotype predicts c...   \n",
      "42  Cancer remains a leading cause of death global...   \n",
      "43  This study compares the cosmetic and functiona...   \n",
      "44  Objective to analyze the anamnestic and anthro...   \n",
      "45  Objective to study the structure of thyroid di...   \n",
      "46  Objective to assess the impact of comorbidity ...   \n",
      "47  The liver is supplied by a dual blood flow sys...   \n",
      "48  The literature data on the existence of a rela...   \n",
      "49  In clinical practice, there is a diagnostic di...   \n",
      "\n",
      "                                           LLM_Prompt  \\\n",
      "0   Extract all gene names and their gene products...   \n",
      "1   Extract all gene names and their gene products...   \n",
      "2   Extract all gene names and their gene products...   \n",
      "3   Extract all gene names and their gene products...   \n",
      "4   Extract all gene names and their gene products...   \n",
      "5   Extract all gene names and their gene products...   \n",
      "6   Extract all gene names and their gene products...   \n",
      "7   Extract all gene names and their gene products...   \n",
      "8   Extract all gene names and their gene products...   \n",
      "9   Extract all gene names and their gene products...   \n",
      "10  Extract all gene names and their gene products...   \n",
      "11  Extract all gene names and their gene products...   \n",
      "12  Extract all gene names and their gene products...   \n",
      "13  Extract all gene names and their gene products...   \n",
      "14  Extract all gene names and their gene products...   \n",
      "15  Extract all gene names and their gene products...   \n",
      "16  Extract all gene names and their gene products...   \n",
      "17  Extract all gene names and their gene products...   \n",
      "18  Extract all gene names and their gene products...   \n",
      "19  Extract all gene names and their gene products...   \n",
      "20  Extract all gene names and their gene products...   \n",
      "21  Extract all gene names and their gene products...   \n",
      "22  Extract all gene names and their gene products...   \n",
      "23  Extract all gene names and their gene products...   \n",
      "24  Extract all gene names and their gene products...   \n",
      "25  Extract all gene names and their gene products...   \n",
      "26  Extract all gene names and their gene products...   \n",
      "27  Extract all gene names and their gene products...   \n",
      "28  Extract all gene names and their gene products...   \n",
      "29  Extract all gene names and their gene products...   \n",
      "30  Extract all gene names and their gene products...   \n",
      "31  Extract all gene names and their gene products...   \n",
      "32  Extract all gene names and their gene products...   \n",
      "33  Extract all gene names and their gene products...   \n",
      "34  Extract all gene names and their gene products...   \n",
      "35  Extract all gene names and their gene products...   \n",
      "36  Extract all gene names and their gene products...   \n",
      "37  Extract all gene names and their gene products...   \n",
      "38  Extract all gene names and their gene products...   \n",
      "39  Extract all gene names and their gene products...   \n",
      "40  Extract all gene names and their gene products...   \n",
      "41  Extract all gene names and their gene products...   \n",
      "42  Extract all gene names and their gene products...   \n",
      "43  Extract all gene names and their gene products...   \n",
      "44  Extract all gene names and their gene products...   \n",
      "45  Extract all gene names and their gene products...   \n",
      "46  Extract all gene names and their gene products...   \n",
      "47  Extract all gene names and their gene products...   \n",
      "48  Extract all gene names and their gene products...   \n",
      "49  Extract all gene names and their gene products...   \n",
      "\n",
      "                LLM_Response  \n",
      "0                        NaN  \n",
      "1                        NaN  \n",
      "2                        NaN  \n",
      "3                        NaN  \n",
      "4                        NaN  \n",
      "5                        NaN  \n",
      "6                        NaN  \n",
      "7                        NaN  \n",
      "8                        NaN  \n",
      "9                       EGFR  \n",
      "10              TP53, CTNNB1  \n",
      "11                       NaN  \n",
      "12                      PTEN  \n",
      "13  TP53, PIK3CA, AKT1, MTOR  \n",
      "14                       NaN  \n",
      "15                       NaN  \n",
      "16                       NaN  \n",
      "17                       NaN  \n",
      "18                       NaN  \n",
      "19                       NaN  \n",
      "20              ESR1, PRKACA  \n",
      "21                       NaN  \n",
      "22                       NaN  \n",
      "23                       NaN  \n",
      "24                       NaN  \n",
      "25                       NaN  \n",
      "26                       NaN  \n",
      "27                       NaN  \n",
      "28                       NaN  \n",
      "29                       NaN  \n",
      "30                       NaN  \n",
      "31    MLH1, MSH2, MSH6, PMS2  \n",
      "32                       NaN  \n",
      "33                       NaN  \n",
      "34                       NaN  \n",
      "35                      EGFR  \n",
      "36                       NaN  \n",
      "37                      JAK3  \n",
      "38                       NaN  \n",
      "39                       NaN  \n",
      "40                       NaN  \n",
      "41                       NaN  \n",
      "42                       NaN  \n",
      "43                       NaN  \n",
      "44                       NaN  \n",
      "45                       NaN  \n",
      "46                       NaN  \n",
      "47                       NaN  \n",
      "48                       NaN  \n",
      "49                       NaN  \n",
      "\n",
      "Length of dataframe 100\n",
      "\n",
      "Columns in the final DataFrame:\n",
      "Index(['PaperId', 'PaperTitle', 'Abstract', 'LLM_Prompt', 'LLM_Response'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "LLM_file = \"ICIMTH_LLM_variant_extraction_gpt4o_prompt1.csv\"\n",
    "\n",
    "#Load OncoMine genes file\n",
    "os.chdir(working_directory)\n",
    "LLM_variant_df = pd.read_csv(LLM_file)\n",
    "print(\"\\nFinal DataFrame Preview:\")\n",
    "print(LLM_variant_df.head(50))\n",
    "print(\"\\nLength of dataframe\",len(LLM_variant_df))\n",
    "\n",
    "# Print all column names\n",
    "print(\"\\nColumns in the final DataFrame:\")\n",
    "print(LLM_variant_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e38eb274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded gene list contains 161 genes.\n",
      "Processing 100 articles for gene extraction. Started at 2025-03-10 14:07:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting genes from LLM responses: 100%|████████████████████████████████████████████████████| 100/100 [00:00<00:00, 216536.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating binary gene presence matrix...\n",
      "\n",
      "Gene extraction complete! Results saved as: /data/JH/marie/TrendyVariants/ICIMTH/LLM_evaluation_gpt4o.csv\n",
      "\n",
      "### Gene Extraction Summary ###\n",
      "Total gene mentions found: 31\n",
      "\n",
      "Extraction summary saved in: /data/JH/marie/TrendyVariants/ICIMTH/LLM_Gene_Extraction_Summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from fuzzywuzzy import process, fuzz\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================== CONFIGURATION ========================== #\n",
    "\n",
    "# Ensure LLM_variant_df is correctly defined\n",
    "if 'LLM_variant_df' not in globals():\n",
    "    raise ValueError(\"LLM_variant_df is not defined. Please ensure batch processing is completed.\")\n",
    "\n",
    "# Define the LLM response column\n",
    "llm_response_column = 'LLM_Response'\n",
    "\n",
    "# Ensure necessary columns exist\n",
    "required_columns = [\"PaperId\", \"PaperTitle\", \"Abstract\", llm_response_column]\n",
    "missing_columns = [col for col in required_columns if col not in LLM_variant_df.columns]\n",
    "if missing_columns:\n",
    "    raise KeyError(f\"Missing columns in dataset: {missing_columns}\")\n",
    "\n",
    "# ========================== NORMALIZATION FUNCTION ========================== #\n",
    "\n",
    "# Expand gene list dynamically\n",
    "expanded_gene_list = {gene.upper(): {gene.upper()} for gene in gene_list}\n",
    "print(f\"Expanded gene list contains {len(expanded_gene_list)} genes.\")\n",
    "\n",
    "def normalize_extracted_entities(found_terms):\n",
    "    \"\"\"Normalize extracted genes using fuzzy matching against `gene_list`.\"\"\"\n",
    "    normalized_entities = set()\n",
    "    for term in found_terms:\n",
    "        term_upper = term.upper()\n",
    "\n",
    "        if term_upper in expanded_gene_list:\n",
    "            normalized_entities.add(term_upper)\n",
    "        else:\n",
    "            match = process.extractOne(term_upper, expanded_gene_list.keys(), scorer=fuzz.ratio)\n",
    "            if match:\n",
    "                best_match, score = match[:2]\n",
    "                if score > 85:  # Fuzzy match threshold\n",
    "                    normalized_entities.add(best_match)\n",
    "\n",
    "    return normalized_entities\n",
    "\n",
    "# ========================== GENE EXTRACTION FUNCTION ========================== #\n",
    "\n",
    "def extract_genes_from_text(text):\n",
    "    \"\"\"Extract gene mentions from LLM response text.\"\"\"\n",
    "    if pd.isna(text) or len(text.strip()) == 0:\n",
    "        return set()\n",
    "\n",
    "    words = text.replace(\",\", \"\").split()  # Split text into words\n",
    "    extracted_terms = set(word.upper() for word in words if word.upper() in expanded_gene_list)\n",
    "\n",
    "    return normalize_extracted_entities(extracted_terms)\n",
    "\n",
    "# ========================== PROCESSING LLM RESPONSES ========================== #\n",
    "\n",
    "start_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "start_timestamp = time.time()\n",
    "\n",
    "print(f\"Processing {len(LLM_variant_df)} articles for gene extraction. Started at {start_time}\")\n",
    "\n",
    "# Apply extraction to the dataset\n",
    "tqdm.pandas(desc=\"Extracting genes from LLM responses\")\n",
    "LLM_variant_df[\"Extracted_Genes\"] = LLM_variant_df[llm_response_column].progress_apply(extract_genes_from_text)\n",
    "\n",
    "# Convert extracted gene sets to comma-separated strings\n",
    "LLM_variant_df[\"Extracted_Genes\"] = LLM_variant_df[\"Extracted_Genes\"].apply(lambda genes: \", \".join(genes) if genes else \"\")\n",
    "\n",
    "# ========================== CREATE BINARY MATRIX ========================== #\n",
    "\n",
    "print(\"Creating binary gene presence matrix...\")\n",
    "\n",
    "# Convert extracted genes into a list for each row\n",
    "LLM_variant_df[\"Extracted_Gene_List\"] = LLM_variant_df[\"Extracted_Genes\"].apply(lambda x: x.split(\", \") if isinstance(x, str) else [])\n",
    "\n",
    "# Generate binary columns for each gene\n",
    "binary_gene_data = {gene: LLM_variant_df[\"Extracted_Gene_List\"].apply(lambda genes: 1 if gene in genes else 0) for gene in gene_list}\n",
    "binary_gene_df = pd.DataFrame(binary_gene_data)\n",
    "\n",
    "# Merge binary matrix with original dataframe\n",
    "LLM_variant_df = pd.concat([LLM_variant_df, binary_gene_df], axis=1)\n",
    "\n",
    "# Count total gene mentions per article (Sum_Entity_Mentions)\n",
    "LLM_variant_df[\"Sum_Entity_Mentions\"] = binary_gene_df.sum(axis=1)\n",
    "\n",
    "# ========================== SAVE RESULTS ========================== #\n",
    "\n",
    "# Define output filename\n",
    "output_filename = os.path.join(working_directory, \"LLM_evaluation_gpt4o.csv\")\n",
    "\n",
    "# Drop unnecessary columns before saving\n",
    "LLM_variant_df.drop(columns=[\"Extracted_Gene_List\"], errors=\"ignore\").to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"\\nGene extraction complete! Results saved as: {output_filename}\")\n",
    "\n",
    "# ========================== GENERATE SUMMARY ========================== #\n",
    "\n",
    "summary_results = LLM_variant_df[\"Sum_Entity_Mentions\"].sum()\n",
    "\n",
    "print(\"\\n### Gene Extraction Summary ###\")\n",
    "print(f\"Total gene mentions found: {summary_results}\")\n",
    "\n",
    "# Save summary to file\n",
    "summary_file = os.path.join(working_directory, \"LLM_Gene_Extraction_Summary.txt\")\n",
    "with open(summary_file, \"w\") as f:\n",
    "    f.write(\"### Gene Extraction Summary ###\\n\")\n",
    "    f.write(f\"Total gene mentions found: {summary_results}\\n\")\n",
    "\n",
    "print(f\"\\nExtraction summary saved in: {summary_file}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py]",
   "language": "python",
   "name": "conda-env-py-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
