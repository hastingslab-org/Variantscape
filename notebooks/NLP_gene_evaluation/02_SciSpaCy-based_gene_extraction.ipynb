{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e09ddd",
   "metadata": {},
   "source": [
    "# SciSpaCy-based gene extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732021a4",
   "metadata": {},
   "source": [
    "# 1) Install libraries and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd35241",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!pip install scispacy\n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz \n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_jnlpba_md-0.5.0.tar.gz\n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2c9f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import scispacy\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from mygene import MyGeneInfo\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import process, fuzz\n",
    "print(\"Import successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory and file paths\n",
    "working_directory = \"WORKING_DIRECTORY\"\n",
    "input_directory = \"INPUT_DIRECTORY\"\n",
    "output_directory = \"OUTPUT_DIRECTORY\"\n",
    "articles_file = \"articles.csv\"\n",
    "genes_file = \"genes.csv\"\n",
    "\n",
    "# Change the working directory\n",
    "os.chdir(output_directory)\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d96bb14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load OncoMine genes file\n",
    "os.chdir(input_directory)\n",
    "genes = pd.read_csv(genes_file, header=None)\n",
    "gene_list = genes[0].tolist()\n",
    "print(\"Genes import successful!\")\n",
    "\n",
    "# Load the articles file\n",
    "os.chdir(output_directory)\n",
    "if \"full_articles\" not in globals():\n",
    "    full_articles = pd.read_csv(articles_file)\n",
    "    print(f\"Loaded {len(full_articles)} articles from CSV.\")\n",
    "else:\n",
    "    print(\"Using preloaded full_articles from memory.\")\n",
    "articles = full_articles.head(100)\n",
    "print(\"Article import successful!\")\n",
    "print(f\"\\nImported {len(articles)} articles with {len(articles.columns)} selected columns.\")\n",
    "print(f\"Imported {len(gene_list):,} oncomine genes.\")\n",
    "\n",
    "# Get the number of rows and columns\n",
    "num_rows = articles.shape[0]\n",
    "num_columns = articles.shape[1]\n",
    "os.chdir(working_directory)\n",
    "print(\"\\nCurrent Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e986f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasubset for reference!\n",
    "os.chdir(working_directory)\n",
    "ICIMTH_output = \"ICIMTH_subset_data_file_for_analysis.csv\"\n",
    "articles.to_csv(ICIMTH_output)\n",
    "print(f\"\\n Subset dataset for analysis saved as '{ICIMTH_output}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddec564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory and load SciSpaCy models\n",
    "os.chdir(working_directory)\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "models = {\n",
    "    \"bionlp13cg\": \"en_ner_bionlp13cg_md\",\n",
    "    \"jnlpba\": \"en_ner_jnlpba_md\",\n",
    "    \"craft\": \"en_ner_craft_md\"\n",
    "}\n",
    "nlp_models = {name: spacy.load(path) for name, path in models.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08beae9c",
   "metadata": {},
   "source": [
    "# 2) Run NER-based SciSpaCy gene extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11359c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(working_directory)\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "# Define entity labels to extract for each model\n",
    "MODEL_ENTITY_LABELS = {\n",
    "    \"bionlp13cg\": \"GENE_OR_GENE_PRODUCT\",\n",
    "    \"jnlpba\": \"PROTEIN\",\n",
    "    \"craft\": \"GGP\"\n",
    "}\n",
    "\n",
    "# Initialize MyGene.info API client\n",
    "mg = MyGeneInfo()\n",
    "\n",
    "# Function to fetch gene synonyms and proteins from MyGene.info API\n",
    "def get_gene_synonyms(gene_symbol):\n",
    "    \"\"\"Fetch known synonyms and protein products for a given gene.\"\"\"\n",
    "    url = f\"https://mygene.info/v3/query?q={gene_symbol}&fields=symbol,alias,other_names,protein\"\n",
    "    try:\n",
    "        response = requests.get(url).json()\n",
    "        synonyms = set()\n",
    "        for hit in response.get(\"hits\", []):\n",
    "            if \"symbol\" in hit:\n",
    "                synonyms.add(hit[\"symbol\"].upper())\n",
    "            if \"alias\" in hit:\n",
    "                synonyms.update([alias.upper() for alias in hit[\"alias\"]])\n",
    "            if \"other_names\" in hit:\n",
    "                synonyms.update([name.upper() for name in hit[\"other_names\"]])\n",
    "            if \"protein\" in hit and isinstance(hit[\"protein\"], dict) and \"name\" in hit[\"protein\"]:\n",
    "                synonyms.add(hit[\"protein\"][\"name\"].upper())\n",
    "        return synonyms\n",
    "    except:\n",
    "        return {gene_symbol.upper()}\n",
    "\n",
    "expanded_gene_list = {gene.upper(): get_gene_synonyms(gene) for gene in gene_list}\n",
    "print(f\"Expanded gene list contains {len(expanded_gene_list)} genes with synonyms.\")\n",
    "\n",
    "# Function to normalize extracted entities using MyGene.info & Fuzzy Matching\n",
    "def normalize_extracted_entities(found_terms):\n",
    "    \"\"\"Normalize extracted entities using MyGene API and fuzzy matching.\"\"\"\n",
    "    normalized_entities = set()\n",
    "\n",
    "    for term in found_terms:\n",
    "        term_upper = term.upper()\n",
    "        \n",
    "        if term_upper in expanded_gene_list:\n",
    "            normalized_entities.add(term_upper)\n",
    "            normalized_entities.update(expanded_gene_list[term_upper])\n",
    "        \n",
    "        else:\n",
    "            match = process.extractOne(term_upper, expanded_gene_list.keys(), scorer=fuzz.ratio)\n",
    "            if match:\n",
    "                best_match, score = match[:2]\n",
    "                if score > 85:\n",
    "                    normalized_entities.add(best_match)\n",
    "                    normalized_entities.update(expanded_gene_list.get(best_match, []))\n",
    "\n",
    "    return normalized_entities\n",
    "\n",
    "def extract_entities_scispacy(text, nlp, entity_labels):\n",
    "    \"\"\"Extracts entities from text using SciSpaCy, supports multiple entity labels.\"\"\"\n",
    "    if pd.isna(text) or len(text.strip()) == 0:\n",
    "        return set()\n",
    "    doc = nlp(text)\n",
    "    extracted_terms = set()\n",
    "    if isinstance(entity_labels, list):\n",
    "        extracted_terms = {ent.text.upper() for ent in doc.ents if ent.label_ in entity_labels}\n",
    "    else:\n",
    "        extracted_terms = {ent.text.upper() for ent in doc.ents if ent.label_ == entity_labels}\n",
    "\n",
    "    return extracted_terms\n",
    "\n",
    "##### Entity Extraction #####\n",
    "start_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "start_timestamp = time.time()\n",
    "\n",
    "print(f\"Processing {len(articles)} articles with SciSpaCy models. Started at {start_time}\")\n",
    "\n",
    "# Processing articles\n",
    "all_results = []\n",
    "for model_name, nlp in nlp_models.items():\n",
    "    entity_labels = MODEL_ENTITY_LABELS.get(model_name, \"GENE_OR_GENE_PRODUCT\")\n",
    "    print(f\"Using model: {model_name} (Extracting {entity_labels})\")\n",
    "    scispacy_results = []\n",
    "    for index, row in tqdm(articles.iterrows(), total=len(articles), desc=f\"Processing with {model_name}\"):\n",
    "        title = row.get(\"PaperTitle\", \"\")\n",
    "        abstract = row.get(\"Abstract\", \"\")\n",
    "\n",
    "        extracted_entities = extract_entities_scispacy(title, nlp, entity_labels) | extract_entities_scispacy(abstract, nlp, entity_labels)\n",
    "        normalized_entities = normalize_extracted_entities(extracted_entities)\n",
    "\n",
    "        scispacy_results.append(\", \".join(normalized_entities))\n",
    "    df_results = articles.copy()\n",
    "    df_results[\"Model\"] = model_name \n",
    "    df_results[model_name] = scispacy_results\n",
    "    df_results[\"Extracted_Entities\"] = df_results[model_name].apply(lambda x: x.split(\", \") if isinstance(x, str) else [])\n",
    "    binary_entity_data = {gene: df_results[\"Extracted_Entities\"].apply(lambda entities: 1 if gene in entities else 0) for gene in gene_list}\n",
    "    binary_entity_df = pd.DataFrame(binary_entity_data)\n",
    "    df_results = pd.concat([df_results, binary_entity_df], axis=1)\n",
    "    df_results[\"Sum_Entity_Mentions\"] = binary_entity_df.sum(axis=1)\n",
    "    csv_filename = f\"scispacy_evaluation_{model_name}.csv\"\n",
    "    df_results.drop(columns=[\"Extracted_Entities\", \"Model\",\"Entity_Label\"], errors=\"ignore\").to_csv(csv_filename, index=False)\n",
    "    print(f\"Model results saved as: {csv_filename}\")\n",
    "    all_results.append(df_results)\n",
    "df_all_results = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "summary_results = df_all_results.groupby(\"Model\")[\"Sum_Entity_Mentions\"].sum().reset_index()\n",
    "summary_results.columns = [\"Model\", \"Total_Entity_Mentions\"]\n",
    "\n",
    "print(\"\\n### Extraction Summary ###\")\n",
    "for index, row in summary_results.iterrows():\n",
    "    print(f\"Model: {row['Model']} | Total Entity Mentions: {row['Total_Entity_Mentions']}\")\n",
    "summary_file = \"sciscpacy_evaluation_summary.txt\"\n",
    "with open(summary_file, \"w\") as f:\n",
    "    f.write(\"### Extraction Summary ###\\n\")\n",
    "    for index, row in summary_results.iterrows():\n",
    "        f.write(f\"Model: {row['Model']} | Total Entity Mentions: {row['Total_Entity_Mentions']}\\n\")\n",
    "print(f\"\\nExtraction summary saved in: {summary_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
